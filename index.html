<meta charset="utf-8"/>
<html>
<head>
	<meta charset="utf-8">
	<meta name="description" content="欢迎来到ENNUI - 一个优雅的神经网络用户界面，让您能够轻松设计、训练和可视化神经网络。">
	<title>ENNUI ~ 优雅的神经网络用户界面 ~</title>

	<!-- MathJax cdn to render latex -->
	<script type="text/javascript" async
		src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  	</script>

	<!-- JSON-LD markup generated by Google Structured Data Markup Helper. -->
	<script type="application/ld+json">
	{
	  "@context" : "http://schema.org",
	  "@type" : "SoftwareApplication",
	  "name" : "ENNUI ~ 优雅的神经网络用户界面 ~'/8",
	  "author" : [ {
		"@type" : "Person",
		"name" : ""
	  }, {
		"@type" : "Person",
		"name" : "Zack Holbrook"
	  }, {
		"@type" : "Person",
		"name" : "Stefan Grosser"
	  }, {
		"@type" : "Person",
		"name" : "Hendrik Strobelt"
	  }, {
		"@type" : "Person",
		"name" : "Rikhav Shah"
	  } ]
	}
	</script>

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-133726432-1"></script>

	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());
		gtag('config', 'UA-133726432-1');
	</script>

	<link rel="icon" type="image/x-icon" sizes="16x16" href="favicon.ico">
	<link rel='stylesheet' href='src/ui/style.css'>
	<script src='dist/bundle.js'></script>
</head>

<body>

<h1 style="display:none">ENNUI ~ 优雅的神经网络教学平台 ~</h1>
<p style="display:none">ENNUI 通过构建、训练和在浏览器中可视化深度神经网络，帮助人们了解深度学习。它具有易于使用的拖放界面。当您准备开始编码时，可以导出网络以生成Python或Julia代码！ </p>


<h6 style="display:none">关于 ENNUI</h6>
<p style="display:none">
	ENNUI为深度学习开发的所有阶段提供多种工具。画布提供了一个拖放界面，用于设计神经网络架构。这个设计可以通过导出到链接与朋友和同事轻松分享。
	您不仅可以设计神经网络，还可以在多个数据集上训练它们：MNIST、CIFAR-10等！在训练期间，您可以在进度标签中跟踪您的网络损失和准确率，还可以查看混淆矩阵。
	一旦训练完成，ENNUI提供了一套神经网络可视化工具，以更好地理解您的架构。
	ENNUI不断更新新功能，所以请继续关注！
</p>
<div id = 'main'>

	<!-- The leftmost strip to select tabs -->
	<div id = 'tabselector'>
		<div id = 'blanktab' class='top_neighbor_tab-selected'> </div>
		<div title = '神经网络' class = 'tab-selected option tab-option' id = 'network' data-optionValue = 'network'>
			<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M11.99 18.54l-7.37-5.73L3 14.07l9 7 9-7-1.63-1.27zM12 16l7.36-5.73L21 9l-9-7-9 7 1.63 1.27L12 16zm0-11.47L17.74 9 12 13.47 6.26 9 12 4.53z"/></svg>
		</div>
		<div title = '训练过程' class = 'option tab-option bottom_neighbor_tab-selected' id = 'progress' data-optionValue = 'progress'>
			<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M13.5 13.48l-4-4L2 16.99l1.5 1.5 6-6.01 4 4L22 6.92l-1.41-1.41z"/></svg>
		</div>
		<div title = '结果可视化' class = 'option tab-option' id = 'visualization' data-optionValue = 'visualization'>
			<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M11 9h2v2h-2V9zm-2 2h2v2H9v-2zm4 0h2v2h-2v-2zm2-2h2v2h-2V9zM7 9h2v2H7V9zm12-6H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 18H7v-2h2v2zm4 0h-2v-2h2v2zm4 0h-2v-2h2v2zm2-7h-2v2h2v2h-2v-2h-2v2h-2v-2h-2v2H9v-2H7v2H5v-2h2v-2H5V5h14v6z"/></svg>
		</div>
		<div id = 'middleblanktab' > </div>

		<div title = '教学' class = 'option tab-option' id = 'education' data-optionValue = 'education'>
			<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M12 3L1 9l4 2.18v6L12 21l7-3.82v-6l2-1.09V17h2V9L12 3zm6.82 6L12 12.72 5.18 9 12 5.28 18.82 9zM17 15.99l-5 2.73-5-2.73v-3.72L12 15l5-2.73v3.72z"/></svg>
		</div>
		<div id = 'bottomblanktab' > </div>
	</div>

	<!-- The left panel (menu) -->
	<div id = 'menu'>
		<div id = 'networkMenu'>
			<!-- The task -->
			<div id="tasks" class="category">
				<div class="categoryTitle" data-expanded="true">
					<div class="expander">
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class="categoryTitleText">
						教学任务
					</div>
				</div>
				<div class="option select-option" data-optionValue="MLP">多层感知机</div>
				<div class="option select-option" data-optionValue="CNN">卷积神经网络</div>
				<div class="option select-option" data-optionValue="RNN">循环神经网络</div>
			</div>

			<div id = 'layers' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						神经网络层
					</div>

				</div>
				<div class = 'option select-option' data-optionValue = 'dense'> Dense </div>
				<div class = 'option select-option' data-optionValue = 'conv2D'> Convolution </div>
				<div class = 'option select-option' data-optionValue = 'maxPooling2D'> Max Pooling </div>


				<div class = 'option-dropdown'>
					<div style="float:left">更多</div>
					<div style="float:right">〉</div>
					<div class='dropdown-content left'>
						<div title = '在训练过程中修改一批数据，使其更相似，从而加快收敛并获得更好的结果。'
							 class = 'option select-option' data-optionValue = 'batchnorm'> Batch Normalization </div>
						<div title = '在每个批次中忽略一部分随机的权重，以获得更好的泛化能力并加快训练。'
							 class = 'option select-option' data-optionValue = 'dropout'> Dropout </div>
						<div title = '将一组二维图像展平为一维特征向量。'
							 class = 'option select-option' data-optionValue = 'flatten'> Flatten </div>
						<div title = '将两个或多个输入（它们可以是1D或2D）连接起来'
							 class = 'option select-option' data-optionValue = 'concatenate'> Concatenate </div>
						<div title = '将两个或多个输入相加。'
							 class = 'option select-option last-dropdown' data-optionValue = 'add'> Add </div>
					</div>
				</div>
			</div>

			<div id = 'activations' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						激活函数
					</div>
				</div>
				<div class = 'option select-option' data-optionValue = 'relu'> ReLU </div>
				<div class = 'option select-option' data-optionValue = 'sigmoid'> Sigmoid </div>
				<div class = 'option select-option' data-optionValue = 'tanh'> Tanh </div>
			</div>
			<div id = 'templates' class = 'bottomCategory'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						模板
					</div>
				</div>
				<div class = 'option select-option' data-optionValue = 'blank'> 清空 </div>
				<div class = 'option select-option' data-optionValue = 'default'> 默认模板 </div>
				<div class = 'option select-option' data-optionValue = 'resnet'> ResNet残差网络 </div>
			</div>
		</div>

		<div id = 'progressMenu' style="display: none">
			<div id = 'optimizers' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						优化器
					</div>
				</div>
				<div id = "defaultOptimizer" class = 'option select-option selected' id = 'sgd' data-optionValue = 'sgd'> SGD </div>
				<div id = 'rmsprop' class = 'option select-option' data-optionValue = 'rmsprop'> RMSprop </div>
				<div id = 'adagrad' class = 'option select-option' data-optionValue = 'adagrad'> Adagrad </div>
				<div id = 'adam' class = 'option select-option' data-optionValue = 'adam'> Adam </div>
			</div>
			<div id = 'losses' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						损失函数
					</div>
				</div>
				<div id = 'defaultLoss' class = 'option select-option selected' data-optionValue = 'categoricalCrossentropy'>CrossEntropy</div>
				<div id = 'hinge' class = 'option select-option' data-optionValue = 'hinge'> Hinge </div>
				<div id = 'meanSquaredError' class = 'option select-option' data-optionValue = 'meanSquaredError'> MSE </div>
				<div id = 'meanAbsoluteError' class = 'option select-option' data-optionValue = 'meanAbsoluteError'> MAE </div>
			</div>
		</div>

		<div id = 'visualizationMenu' style="display: none">
			<div id = 'classes' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						分类
					</div>
				</div>
				<div class = 'option select-option selected' data-optionValue = 'all'> ALL </div>
				<div class = 'option select-option' data-optionValue = '0'> 0 </div>
				<div class = 'option select-option' data-optionValue = '1'> 1 </div>
				<div class = 'option select-option' data-optionValue = '2'> 2 </div>
				<div class = 'option select-option' data-optionValue = '3'> 3 </div>
				<div class = 'option select-option' data-optionValue = '4'> 4 </div>
				<div class = 'option select-option' data-optionValue = '5'> 5 </div>
				<div class = 'option select-option' data-optionValue = '6'> 6 </div>
				<div class = 'option select-option' data-optionValue = '7'> 7 </div>
				<div class = 'option select-option' data-optionValue = '8'> 8 </div>
				<div class = 'option select-option' data-optionValue = '9'> 9 </div>
			</div>
		</div>

		<div id = 'educationMenu' style="display: none">
			<div id = 'educationLayers' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						相关文章
					</div>

				</div>

				<div class = 'option select-option education-option' data-optionValue = 'Overview'> 概述 </div>
				<div class = 'option select-option education-option' data-optionValue = 'Overfitting'> Overfitting</div>
				<div class = 'option select-option education-option' data-optionValue = 'ResNets'>ResNets</div>
			</div>

			<div id = 'educationStory' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						神经网络层
					</div>
				</div>

				<div class = 'option select-option education-option' data-optionValue = 'Concatenate'> Concatenate </div>
				<div class = 'option select-option education-option' data-optionValue = 'Convolution'> Convolution </div>
				<div class = 'option select-option education-option' data-optionValue = 'Dropout'> Dropout </div>
				<div class = 'option select-option education-option' data-optionValue = 'Flatten'> Flatten </div>

			</div>

		</div>

	</div>

	

	<!-- The middle canvas -->
	<div id = 'middle'>
		<div id="taskSteps">
			<div id="taskTitle" class="task-title" onclick="toggleTaskSteps()">
				<span id="taskTitleText">未选择任务</span>
				<span id="arrow" class="arrow">&#9660;</span> <!-- 初始为收起箭头 -->
			</div>
			<div id="taskContent" class="task-content" style="display: none;">
				<ul id="stepsList">
					<!-- 这里将动态显示步骤内容 -->
				</ul>
			</div>
		</div>

		<div id = 'networkTab'>
			<svg id = 'svg'> </svg>
		</div>

		<div id = 'progressTab' style="display: none">

			<div id="loss-canvas"></div>

			<div id="accuracy-canvas"></div>

			<div id="confusion-matrix-canvas"></div>
		</div>

		<div id = 'visualizationTab' style="display: none">
			<div id='visulaization'></div>
			<div id='images'></div>
		</div>

		<div id = 'informationOverlay'>
			<div id='information'>欢迎来到ENNUI
				<div id="informationBody">~ 优雅的神经网络教学平台 ~</div>
				<div class="informationRow">
					<div class="informationColumn">
						自主创建神经网络 <br></br>
						<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="30%" max-height="30%" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M11.99 18.54l-7.37-5.73L3 14.07l9 7 9-7-1.63-1.27zM12 16l7.36-5.73L21 9l-9-7-9 7 1.63 1.27L12 16zm0-11.47L17.74 9 12 13.47 6.26 9 12 4.53z"/></svg>
					</div>
					<div class="informationBlankColumn"></div>
					<div id="informationEducation" class="informationColumn">
						开始学习如何创建神经网络 <br></br>
						<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="30%" max-height="30%" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M12 3L1 9l4 2.18v6L12 21l7-3.82v-6l2-1.09V17h2V9L12 3zm6.82 6L12 12.72 5.18 9 12 5.28 18.82 9zM17 15.99l-5 2.73-5-2.73v-3.72L12 15l5-2.73v3.72z"/></svg>
					</div>
				</div>
				<div id = 'acknowledgements'>
					<br>
					袁子茜，崔雯嘉，周艺瑶，田恒钟，姜逸涵 <br>
					开源资源<a class="overlayLinks" href="https://github.com/sunyia123/bbvdle" target="_blank">GitHub</a>.
				</div>
			</div>
		</div>

		<div id = 'educationTab' style="display: none">
			<div id="educationOverview">
				<div class="educationTitle" style="padding-top: 0px"> 关于深度学习神经网络 </div>
				<div class="educationSection"> 介绍ENNUI </div>
				<div class="educationContent">
					如果你第一次进入我们的教学平台, 
					可以参考以下的快速入门教学开始自己的神经网络学习之旅：
				</div>
				<!--<iframe class="educationVideo" src="https://www.youtube.com/embed/m0YnwAtPbb8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->

				<div style="text-align: center; font-size: 25px;"><a href="https://www.youtube.com/watch?v=m0YnwAtPbb8" target="blank">ENNUI 教学</a></div>
				<div class="educationSection"> 深度学习的基本知识 </div>
				<div class="educationContent">
					如果您不熟悉机器学习，下面的讲座视频是一个很好的介绍。
				</div>
				<div style="text-align: center; font-size: 25px;"><a href="https://video.odl.mit.edu/videos/9101a72a7d994d53800d1398fd885b88/embed/?start=339" target="blank">Gilbert Strang: Deep Learning</a></div>
				<!-- <iframe class="educationVideo" src="https://video.odl.mit.edu/videos/9101a72a7d994d53800d1398fd885b88/embed/?start=339" scrolling="no" frameborder="0" allowfullscreen></iframe> -->
			</div>

			<div id="educationConvolution">
				<div class="educationTitle"> 卷积网络 </div>
				<div class="educationAuthor">作者 <i>Gilbert Strang</i></div>

				<div class="educationContent">
					<p><strong>权重共享</strong> 这一词是卷积神经网络（CNNs）的核心思想。连接一层到另一层的权重矩阵<span class="math inline">\(A\)</span>  只有少数几个独立元素。 因此，优化这些权重的速度比全连接（密集）架构更快。</p>
					<p>在一维问题中，假设输入层（第0层）由一个向量<span class="math inline">\(v = (v_1,...,v_n)\)</span>表示。 卷积层将 <span class="math inline">\(v\)</span> 与一个具有常数对角线的权重矩阵 <span class="math inline">\(A\)</span> 相乘。然后，整个层中将重复使用相同的权重集（假设是 3 个权重）： </p>
					<p><span class="math display">\[A=
					\begin{bmatrix}
						a_{-1} &amp; a_0 &amp; a_1 &amp;  &amp;  \\
						&amp; a_{-1} &amp; a_0 &amp; a_1 &amp;  \\
						&amp; &amp; a_{-1} &amp; a_0 &amp; a_1 \\
					\end{bmatrix}\]</span> 这个矩阵 <span class="math inline">\(A\)</span> 有 <span class="math inline">\(n = 5\)</span> 个输出和 <span class="math inline">\(m = 3\)</span> 个输出。 A 是<strong>平移不变</strong>的: 卷积 = 滤波器 = Toeplitz 矩阵。卷积对于有许多像素的图像尤其重要。那 <span class="math inline">\(3\)</span> 个独立的权重<span class="math inline">\(a_{-1}, a_0, a_1\)</span> 可能在二维中变成 <span class="math inline">\(3 \times 3=9\)</span> 个权重。这 9 个数是 <span class="math inline">\(a_{ij}\)</span> 其中 <span class="math inline">\(i = -1,0,1\)</span> 和 <span class="math inline">\(j = -1,0,1\)</span>。一个包含其 8 个邻居（在一个 <span class="math inline">\(3 \times 3\)</span> 的方块中的输入）将与 <span class="math inline">\(a_{00}\)</span> 及其   <span class="math inline">\(8\)</span> 个邻居相乘——这 9 项的和给出一个输出 <span class="math inline">\(Av\)</span>。像往常一样，偏置向量  <span class="math inline">\(b\)</span> 会被加到结果中，并且  <span class="math inline">\(Av + b\)</span> 的每个分量都会通过像 ReLU 这样的函数进行激活（或不激活）：新层包含 <span class="math inline">\(\textrm{ReLU}(Av + b)\)</span>.</p>
					<p>这个二维矩阵 <span class="math inline">\(A\)</span> 并不容易显示。你应该可以看到，围绕一个大小为 <span class="math inline">\(n \times n\)</span> 的输入向量 <span class="math inline">\(v\)</span> 的一个 <span class="math inline">\(3 \times 3\)</span> 方块将产生一个大小为 <span class="math inline">\((n - 2) \times (n - 2)\)</span> 的输出，就像在一维中 5 个输入产生了 3 个输出一样。注意，在二维中我们只有 <span class="math inline">\(3 \times 3 = 9\)</span>（或者也许是 <span class="math inline">\(5 \times 5 = 25\)</span>）个独立的权重，因为卷积不仅是 <strong>共享权重</strong>，而且是 <strong>局部的</strong>。</p>
				</div>
			</div>

			<div id="educationResNets">
				<div class="educationTitle"> 残差网络 (ResNets) </div>
				<div class="educationAuthor">作者 <i>Zack Holbrook</i> and <i>Jesse Michel</i></div>

				<div class="educationContent">
					<p>2015 年，微软的一个研究团队凭借 ResNet 在 <a href="http://www.image-net.org/challenges/LSVRC/">ImageNet 大规模视觉识别挑战赛</a> 中获得了创纪录的表现。自 2015 年以来，ResNet 的变种一直主导着这一竞赛，超过了人类在该任务中的表现。它们已成为图像识别任务中广泛采用的架构，并且相对容易实现和训练。</p>
					<div class="educationSection">ResNet 架构</div>
					<p>ResNet 是一种卷积神经网络（CNN），具有 <strong>恒等捷径（identity shortcuts）</strong>，这是通过跳过某些层创建的网络路径，从而在网络中创建捷径。下面我们提供一个典型的 ResNet 示例：
				
						<img class="educationImage" src="dist/resnet.png" alt="Resnet image" width="50%">
				
						<div class="modelLink">
							<a class="modelLink" target="_newtab" href="http://math.mit.edu/ennui/#%7B%22graph%22:%5B%7B%22layer_name%22:%22Input%22,%22children_ids%22:%5B5,9%5D,%22parent_ids%22:%5B%5D,%22params%22:%7B%22dataset%22:%22mnist%22%7D,%22id%22:0,%22xPosition%22:100,%22yPosition%22:377%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B6%5D,%22parent_ids%22:%5B0%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D,%22activation%22:%22relu%22%7D,%22id%22:5,%22xPosition%22:169,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Add%22,%22children_ids%22:%5B7,10%5D,%22parent_ids%22:%5B0,6%5D,%22params%22:%7B%22activation%22:%22relu%22%7D,%22id%22:9,%22xPosition%22:276,%22yPosition%22:411%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B9%5D,%22parent_ids%22:%5B5%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D%7D,%22id%22:6,%22xPosition%22:294,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B8%5D,%22parent_ids%22:%5B9%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D,%22activation%22:%22relu%22%7D,%22id%22:7,%22xPosition%22:414,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Add%22,%22children_ids%22:%5B11%5D,%22parent_ids%22:%5B9,8%5D,%22params%22:%7B%22activation%22:%22relu%22%7D,%22id%22:10,%22xPosition%22:521,%22yPosition%22:412%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B10%5D,%22parent_ids%22:%5B7%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D%7D,%22id%22:8,%22xPosition%22:541,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Flatten%22,%22children_ids%22:%5B12%5D,%22parent_ids%22:%5B10%5D,%22params%22:%7B%7D,%22id%22:11,%22xPosition%22:708,%22yPosition%22:463%7D,%7B%22layer_name%22:%22Dense%22,%22children_ids%22:%5B13%5D,%22parent_ids%22:%5B11%5D,%22params%22:%7B%22units%22:32,%22activation%22:%22relu%22%7D,%22id%22:12,%22xPosition%22:702,%22yPosition%22:434%7D,%7B%22layer_name%22:%22Dropout%22,%22children_ids%22:%5B1%5D,%22parent_ids%22:%5B12%5D,%22params%22:%7B%22rate%22:0.5%7D,%22id%22:13,%22xPosition%22:778,%22yPosition%22:365%7D,%7B%22layer_name%22:%22Output%22,%22children_ids%22:%5B%5D,%22parent_ids%22:%5B13%5D,%22params%22:%7B%7D,%22id%22:1,%22xPosition%22:900,%22yPosition%22:377%7D%5D,%22hyperparameters%22:%7B%22learningRate%22:0.01,%22batchSize%22:64,%22optimizer_id%22:%22defaultOptimizer%22,%22epochs%22:6,%22loss_id%22:%22defaultLoss%22%7D%7D">
								模型链接
							</a>
						</div>
				
						恒等捷径意味着学习到的参数是残差。数学上，如果 <span class="math inline">\(R(x)\)</span> 是一系列卷积层与 ReLU 组合，称为 <strong>残差块</strong>，例如，假设 <span class="math display">\[R(x) = \textrm{Conv}(\textrm{ReLU}(\textrm{Conv}(x))).\]</span> 那么，残差块的输出将是 <span class="math inline">\(R(x) + x\)</span>，其中 <span class="math inline">\(x\)</span> 是恒等传递。如果神经网络试图逼近某个函数 <span class="math inline">\(F(x)\)</span>，那么一个完美的残差块 <span class="math inline">\(R^*(x)\)</span> 会使得 <span class="math inline">\(R^*(x) = F(x) - x\)</span>，这正是通过减去输入图像得到的残差。</p>
					<div class="educationSection">ResNet 的优势</div>
					<p>ResNet 的一个惊人特性是它的良好扩展性，使得深层神经网络仍然能够良好地训练。当网络变得更大时，许多问题会出现。</p>
					<p>大规模网络往往训练速度较慢，但 CNN 的 <strong>权重共享</strong> 意味着每个残差块需要训练的参数相对较少。大规模网络还往往面临 <strong>梯度消失</strong> 问题——在梯度下降中，权重更新会逐渐变得微不足道，导致即使有更多的训练时间，网络也无法改进。ResNet 中的恒等捷径为梯度提供了流动路径，从而避免了梯度消失的问题。</p>
				</div>
			</div>

			<div id="educationFlatten">
				<div class="educationTitle"> 展平层（Flatten） </div>
				<div class="educationAuthor">作者 <i>Zack Holbrook</i> and <i>Jesse Michel</i></div>

				<div class="educationContent">
					<p>展平层接受一个多维输入并产生一个一维输出。例如，CIFAR 数据集是一个包含图像的集合，它是三维的，因为它由32x32像素的二维图像组成，并且有3个颜色通道（红色、绿色、蓝色）。一个展平层可以将该数据集的数据作为输入，输出一个大小为 32*32*3 = 3072 的一维向量。</p>
				</div>
				
			</div>

			<div id="educationConcatenate">
				<div class="educationTitle">拼接层（Concentrate）</div>
				<div class="educationAuthor">作者<i>Zack Holbrook</i> 和 <i>Jesse Michel</i></div>
			
				<div class="educationContent">
					<p>拼接层接受两个或更多层，并通过将输入堆叠在一起将它们的输出拼接成一个单一输出。例如，它可以将两个大小为 10 的向量拼接成一个大小为 20 的向量，方法是将一个向量堆叠在另一个向量的上面。</p>
				</div>
			</div>
			

			<div id="educationDropout">
				<div class="educationTitle">丢弃层（Dropout）</div>
				<div class="educationAuthor">作者<i>Stefan Grosser</i> 和 <i>Jesse Michel</i></div>
			
				<div class="educationContent">
					<p>丢弃层在训练期间忽略一部分输入单元。例如，如果丢弃率为 0.1，则在每次前向传播中，丢弃层会随机选择 10% 的权重并将它们设为 0。添加一个丢弃率为 0 的丢弃层不会对网络产生任何影响，而丢弃率为 1 时，丢弃层将输出 0。</p>
			
					<p>丢弃通常用于防止<strong>过拟合</strong>（有关更多信息，请参阅我们的相关文章）。可以将丢弃视为让网络学习一组弱分类器，在测试时将它们结合起来形成一个更强的分类器。对于熟悉这个术语的人来说，这类似于使用集成模型的提升方法。丢弃层还有一个方便的特点，即加速训练，因为每次前向传播时所需的权重较少。</p>
				</div>
			</div>
			

			<div id="educationOverfitting">
				<div class="educationTitle">过拟合（Overfitting）</div>
				<div class="educationAuthor">作者 <i>Stefan Grosser</i> 和 <i>Jesse Michel</i></div>
				<div class="educationContent">
			
					<p>神经网络有时会学习得过于精确。它识别出仅仅是训练数据中特定的趋势，因此无法<strong>泛化</strong>。这种过度拟合训练数据的问题称为<strong>过拟合</strong>。下图展示了决策边界——决定分类器预测的曲线——在欠拟合、拟合良好（正常）和过拟合的情况下的变化。</p>
			
					<img class="educationImage" src="dist/overfitti_ng.png" alt="可能的决策边界" />
					<div class="modelLink">
						<a class="modelLink" target="_newtab" href="http://mlwiki.org/index.php/Overfitting">
							来源: ML Wiki
						</a>
					</div>
					<p>当分类器发生过拟合时，它在训练数据上的表现远远优于测试数据。因此，训练准确度会远高于验证准确度，训练损失会远低于验证损失。我们在下方提供了这个例子的可视化。</p>
			
					<img class="educationImage" style="float: left; max-width: 50%;" src="dist/loss_overfit.png" title="图：训练过程中的过拟合可视化" alt="训练过程中过拟合的可视化" />
			
					<img class="educationImage" style="float: right; max-width: 50%;" src="dist/accuracy_overfit.png" title="图：训练过程中的过拟合可视化" alt="训练过程中过拟合的可视化" />
			
					<div style="margin-top:10px;">
						该示例所用的架构如下所示：
					</div>
			
					<div class="figure">
						<img class="educationImage" style="max-width: 50%;" src="dist/overfitting_network.png" alt="网络架构" >
			
						<div class="modelLink">
							<a class="modelLink" target="_newtab" href="https://math.mit.edu/ennui/#%7B%22graph%22:%5B%7B%22layer_name%22:%22Input%22,%22children_ids%22:%5B2%5D,%22parent_ids%22:%5B%5D,%22params%22:%7B%22dataset%22:%22cifar%22%7D,%22id%22:0,%22xPosition%22:100,%22yPosition%22:399%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B3%5D,%22parent_ids%22:%5B0%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D,%22kernelRegularizer%22:%22none%22,%22regScale%22:0.1,%22activation%22:%22relu%22%7D,%22id%22:2,%22xPosition%22:261,%22yPosition%22:453%7D,%7B%22layer_name%22:%22Flatten%22,%22children_ids%22:%5B1%5D,%22parent_ids%22:%5B2%5D,%22params%22:%7B%7D,%22id%22:3,%22xPosition%22:585,%22yPosition%22:484%7D,%7B%22layer_name%22:%22Output%22,%22children_ids%22:%5B%5D,%22parent_ids%22:%5B3%5D,%22params%22:%7B%7D,%22id%22:1,%22xPosition%22:900,%22yPosition%22:399%7D%5D,%22hyperparameters%22:%7B%22learningRate%22:0.1,%22batchSize%22:64,%22optimizer_id%22:%22defaultOptimizer%22,%22epochs%22:15,%22loss_id%22:%22defaultLoss%22%7D%7D">
								模型链接
							</a>
						</div>
					</div>
					<br/><br/>
					<p>过拟合展示了交叉验证为何如此重要；如果没有验证集，我们将无法识别模型无法泛化的问题。</p>
					<p>那么，如何应对过拟合，确保模型找到可以泛化的特征呢？</p>
					<div class="educationSection">正则化</div>
					<p>防止过拟合的一种方法是正则化，它通过加入一个新的项来引导模型走向更简单的解决方案。回想一下，在分类问题中，我们从一对对输入和它们的分类 <span class="math display">\[(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n).\]</span> 开始。我们希望找到一个函数 <span class="math inline">\(f\)</span>，它能准确预测新数据样本的类别。因此，如果我们的原始问题是 <span class="math display">\[\min_f \sum_{i=1}^{n} C(f(x_i), y_i),\]</span> 其中 <span class="math inline">\(C\)</span> 计算当预测 <span class="math inline">\(f(x_i)\)</span> 时的代价，当真实值是 <span class="math inline">\(y_i\)</span>，那么正则化损失将是 <span class="math display">\[\min_f \sum_{i=1}^{n} C(f(x_i), y_i) + \lambda R(f),\]</span> 其中 <span class="math inline">\(R(f)\)</span> 是正则化项，定义为当 <span class="math inline">\(f\)</span> 更复杂时它会变大，而 <span class="math inline"> \(\lambda>0\) </span> 是一个可调节的参数，控制正则化的程度。层的复杂性有多种定义，但在我们的案例中，我们会说，具有较低 <span class="math inline">\(L2\)</span>-范数的层较为简单。正式地，我们将 <span class="math inline">\(L2\)</span>-范数定义为 <span class="math display">\[\text{norm}(A) = \sqrt{\sum_i \sum_j a_{ij}^2}.\]</span> 例如，给定矩阵 <span class="math display">\[A =
					\begin{bmatrix}
					1 & 2 \\
					0 & -2
					\end{bmatrix},\]</span> 其 L2-范数为 <span class="math display">\[||A||_2 = \sqrt{1^2 + 2^2 + 0^2 + (-2)^2} = 3.\]</span></p>
					<p>有几个原因解释了为何惩罚增大的 <span class="math inline">\(L2\)</span>-范数是一个合理的做法。如果我们假设分类器会发生过拟合，那么加入惩罚项 <span class="math inline">\(\lambda R(f)\)</span> 将会引导决策边界远离这一状态。这可以看作是给分类器增加“摆动空间”。此外，这种高 <span class="math inline">\(L2\)</span>-范数的惩罚是鼓励丢弃无用信息的一种方式。惩罚项促使层的权重变小，而层的权重越接近零，其作为特征的影响就越小。</p>
					<p>这种复杂性的概念导致了 <span class="math inline">\(L1\)</span>-和 <span class="math inline">\(L2\)</span>-范数成为正则化的一种形式。在 <span class="math inline">\(L2\)</span>-正则化的情况下，我们可以将 <span class="math inline">\(\lambda ||W||_2\)</span> 加入到损失函数中，针对给定层 <span class="math inline">\(W.\)</span> 当然，还有其他的正则化方式，但现在我们来看看另一种方法。</p>
					<!-- TODO: 以后可能解释 L1-正则化 -->
					<div class="educationSection">Dropout</div>
					<p>防止过拟合的另一种方法是名为 dropout 的技术。Dropout 层在训练期间忽略一部分输入单元（有关更多信息，请参阅我们的 dropout 层解释）。有两种直觉可以解释为什么 dropout 有助于防止过拟合。Dropout 可以看作是一种集成学习——将一组弱（欠拟合）分类器的结果进行某种方式的组合，例如采用多数类别。在每个批次中，网络的一个新部分作为弱分类器进行训练。在验证阶段，整个网络都会被使用，从而有效地将所有分类器结合起来提供一个单一的结果。另一种看法是，经过多次运行后，dropout 强制网络架构的所有部分都被使用。因此，训练集的任何一个特征都不会过于影响网络，避免网络集中在仅对训练集特有的伪影上。</p>
					<div class="educationSection">结论</div>
					<p>过拟合会妨碍分类器在未见数据上的表现。正则化和 dropout 是两种广泛使用且容易实现的防止过拟合的方法。结合这些方法与交叉验证，使得构建更具泛化能力的模型变得更加容易。</p>
				</div>
			
			</div>
			


			<div style="height:100px;"> </div>


		</div>

		<div id = 'loadingDataTab' style="display: none">
			<div id='loadingMNIST'>
				加载中 <span id="datasetLoadingName">MNIST</span> 数据集
			</div>
		</div>

		<!-- Error popup -->
		<div id = 'error' style="display: none">
			<svg id = 'x' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
			<div id = 'errorMessage'> </div>
		</div>

	</div>


	<!-- The right panel -->
	<div id = 'paramshell'>
		<div class = 'trainbox' id = 'trainbox'>
			<div id = 'train' class = 'train' data-actionType = 'json'> 训练 </div>
		</div>

		<div class = 'category' id = 'kerasinfo'>
			<div class = 'categoryTitle' data-expanded = 'true'>
				<div class='expander'>
					<svg height="24px" width="24px">
						<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
					</svg>
				</div>
				<div class='categoryTitleText'>
					模型状态
				</div>
			</div>
			<div class = 'parambox'>
				<div id = 'ti_training' class = 'paramline'>
					<div class = 'paramname'>训练中</div>
					<div class = 'paramvalue'>否</div>
				</div>
				<div id = 'ti_acc' class = 'paramline'>
					<div class = 'paramname'>准确率：</div>
					<div class = 'paramvalue'>N/A</div>
				</div>
				<div id = 'ti_loss' class = 'paramline'>
					<div class = 'paramname'>损失率:</div>
					<div class = 'paramvalue'>N/A</div>
				</div>
				<div id = 'ti_vacc' class = 'paramline'>
					<div class = 'paramname'>验证集准确率:</div>
					<div class = 'paramvalue'>N/A</div>
				</div>
				<div id = 'ti_vloss' class = 'paramline'>
					<div class = 'paramname'>验证集损失率:</div>
					<div class = 'paramvalue'>N/A</div>
				</div>
			</div>
		</div>
		<div class="category">
			<div class = 'categoryTitle' data-expanded = 'true'>
				<div class='expander'>
					<svg height="24px" width="24px">
						<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
					</svg>
				</div>
				<div class='categoryTitleText'>
					导出代码
				</div>
			</div>
			<div id="exportPython" class="select-option right-option">导出 Python</div>
			<div id="exportJulia" class="select-option right-option">导出 Julia</div>
			<div id="copyModel" class="select-option right-option">模型链接</div>
		</div>
		<div id = 'networkParamshell'>

			<div class = 'category' id='paramtruck'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						参数
					</div>
				</div>
				<div id='defaultparambox' class = 'parambox'>点击一个层以查看和更改其参数。</div>
			</div>
		</div>

		<div id = 'progressParamshell' style="display: none">
			<div class = 'category' id='paramtruck'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						超参数
					</div>
				</div>
				<div class = 'parambox'>
					<div class = 'paramline'>
						<div class="paramname" data-name="lr">Learning Rate: </div>
						<input id="learningRate" class="paramvalue hyperparamvalue" value="0.01">
					</div>
					<div class = 'paramline'>
						<div class="paramname" data-name="epochs">Epochs: </div>
						<input id="epochs" class="paramvalue hyperparamvalue" value="6">
					</div>
					<div class = 'paramline'>
						<div class="paramname" data-name="lr">Batch Size: </div>
						<input id="batchSize" class="paramvalue hyperparamvalue" value="64">
					</div>
				</div>
			</div>
		</div>

		<div id = 'visualizationParamshell' style="display: none">
		</div>

		<div id = 'educationParamshell' style="display: none">
		</div>

	</div>

</div>
</body>
</html>
