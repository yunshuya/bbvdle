<meta charset="utf-8"/>
<html>
<head>
	<meta charset="utf-8">
	<meta name="description" content="欢迎来到BBVDLE，让您能够智能化、可视化地学习神经网络。">
	<title>BBVDLE ~ 基于可视化积木编程的深度学习教学平台 ~</title>

	<!-- MathJax cdn to render latex -->
	<script type="text/javascript" async
		src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  	</script>

	<!-- JSON-LD markup generated by Google Structured Data Markup Helper. -->
	<script type="application/ld+json">
	{
	  "@context" : "http://schema.org",
	  "@type" : "SoftwareApplication",
	  "name" : "BBVDLE ~ 基于可视化积木编程的深度学习教学平台 ~'/8",
	  "author" : [ {
		"@type" : "Person",
		"name" : ""
	  }, {
		"@type" : "Person",
		"name" : "Zack Holbrook"
	  }, {
		"@type" : "Person",
		"name" : "Stefan Grosser"
	  }, {
		"@type" : "Person",
		"name" : "Hendrik Strobelt"
	  }, {
		"@type" : "Person",
		"name" : "Rikhav Shah"
	  } ]
	}
	</script>

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-133726432-1"></script>

	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());
		gtag('config', 'UA-133726432-1');
	</script>

	<link rel="icon" type="image/x-icon" sizes="16x16" href="favicon.ico">
	<link rel='stylesheet' href='src/ui/style.css'>
	<script src='dist/bundle.js'></script>
</head>


<body>

<h1 style="display:none">ENNUI ~ 优雅的神经网络教学平台 ~</h1>
<p style="display:none">ENNUI 通过构建、训练和在浏览器中可视化深度神经网络，帮助人们了解深度学习。它具有易于使用的拖放界面。当您准备开始编码时，可以导出网络以生成Python或Julia代码！ </p>


<h6 style="display:none">关于 ENNUI</h6>
<p style="display:none">
	ENNUI为深度学习开发的所有阶段提供多种工具。画布提供了一个拖放界面，用于设计神经网络架构。这个设计可以通过导出到链接与朋友和同事轻松分享。
	您不仅可以设计神经网络，还可以在多个数据集上训练它们：MNIST、CIFAR-10等！在训练期间，您可以在进度标签中跟踪您的网络损失和准确率，还可以查看混淆矩阵。
	一旦训练完成，ENNUI提供了一套神经网络可视化工具，以更好地理解您的架构。
	ENNUI不断更新新功能，所以请继续关注！
</p>
<div id = 'main'>

	<!-- The leftmost strip to select tabs -->
	<div id = 'tabselector'>
		<div id = 'blanktab' class='top_neighbor_tab-selected'> </div>
		<div title = '神经网络' class = 'tab-selected option tab-option' id = 'network' data-optionValue = 'network'>
			<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M11.99 18.54l-7.37-5.73L3 14.07l9 7 9-7-1.63-1.27zM12 16l7.36-5.73L21 9l-9-7-9 7 1.63 1.27L12 16zm0-11.47L17.74 9 12 13.47 6.26 9 12 4.53z"/></svg>
		</div>
		<div title = '训练过程' class = 'option tab-option bottom_neighbor_tab-selected' id = 'progress' data-optionValue = 'progress'>
			<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M13.5 13.48l-4-4L2 16.99l1.5 1.5 6-6.01 4 4L22 6.92l-1.41-1.41z"/></svg>
		</div>
		<div title = '结果可视化' class = 'option tab-option' id = 'visualization' data-optionValue = 'visualization'>
			<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M11 9h2v2h-2V9zm-2 2h2v2H9v-2zm4 0h2v2h-2v-2zm2-2h2v2h-2V9zM7 9h2v2H7V9zm12-6H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 18H7v-2h2v2zm4 0h-2v-2h2v2zm4 0h-2v-2h2v2zm2-7h-2v2h2v2h-2v-2h-2v2h-2v-2h-2v2H9v-2H7v2H5v-2h2v-2H5V5h14v6z"/></svg>
		</div>
		<div id = 'middleblanktab' > </div>

		<div title = '教学' class = 'option tab-option' id = 'education' data-optionValue = 'education'>
			<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M12 3L1 9l4 2.18v6L12 21l7-3.82v-6l2-1.09V17h2V9L12 3zm6.82 6L12 12.72 5.18 9 12 5.28 18.82 9zM17 15.99l-5 2.73-5-2.73v-3.72L12 15l5-2.73v3.72z"/></svg>
		</div>
		<div id = 'bottomblanktab' > </div>
	</div>

	<!-- The left panel (menu) -->
	<div id = 'menu'>
		<div id = 'networkMenu'>
			<!-- The task -->
			<div id="tasks" class="category">
				<div class="categoryTitle" data-expanded="true">
					<div class="expander">
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class="categoryTitleText">
						教学任务
					</div>
				</div>
				<div class="option select-option" data-optionValue="MLP">多层感知机</div>
				<div class="option select-option" data-optionValue="CNN">卷积神经网络</div>
				<div class="option select-option" data-optionValue="RNN">循环神经网络</div>
			</div>

			<div id = 'layers' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						神经网络层
					</div>

				</div>
				<div class = 'option select-option' data-optionValue = 'dense'> Dense </div>
				<div class = 'option select-option' data-optionValue = 'conv2D'> Convolution </div>
				<div class = 'option select-option' data-optionValue = 'maxPooling2D'> Max Pooling </div>


				<div class = 'option-dropdown'>
					<div style="float:left">更多</div>
					<div style="float:right">〉</div>
					<div class='dropdown-content left'>
						<div title = '在训练过程中修改一批数据，使其更相似，从而加快收敛并获得更好的结果。'
							 class = 'option select-option' data-optionValue = 'batchnorm'> Batch Normalization </div>
						<div title = '在每个批次中忽略一部分随机的权重，以获得更好的泛化能力并加快训练。'
							 class = 'option select-option' data-optionValue = 'dropout'> Dropout </div>
						<div title = '将一组二维图像展平为一维特征向量。'
							 class = 'option select-option' data-optionValue = 'flatten'> Flatten </div>
						<div title = '将两个或多个输入（它们可以是1D或2D）连接起来'
							 class = 'option select-option' data-optionValue = 'concatenate'> Concatenate </div>
						<div title = '将两个或多个输入相加。'
							 class = 'option select-option last-dropdown' data-optionValue = 'add'> Add </div>
					</div>
				</div>
			</div>

			<div id = 'activations' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						激活函数
					</div>
				</div>
				<div class = 'option select-option' data-optionValue = 'relu'> ReLU </div>
				<div class = 'option select-option' data-optionValue = 'sigmoid'> Sigmoid </div>
				<div class = 'option select-option' data-optionValue = 'tanh'> Tanh </div>
			</div>
			<div id = 'templates' class = 'bottomCategory'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						模板
					</div>
				</div>
				<div class = 'option select-option' data-optionValue = 'blank'> 清空 </div>
				<div class = 'option select-option' data-optionValue = 'default'> 默认模板 </div>
				<div class = 'option select-option' data-optionValue = 'resnet'> ResNet残差网络 </div>
			</div>
		</div>

		<div id = 'progressMenu' style="display: none">
			<div id = 'optimizers' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						优化器
					</div>
				</div>
				<div id = "defaultOptimizer" class = 'option select-option selected' id = 'sgd' data-optionValue = 'sgd'> SGD </div>
				<div id = 'rmsprop' class = 'option select-option' data-optionValue = 'rmsprop'> RMSprop </div>
				<div id = 'adagrad' class = 'option select-option' data-optionValue = 'adagrad'> Adagrad </div>
				<div id = 'adam' class = 'option select-option' data-optionValue = 'adam'> Adam </div>
			</div>
			<div id = 'losses' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						损失函数
					</div>
				</div>
				<div id = 'defaultLoss' class = 'option select-option selected' data-optionValue = 'categoricalCrossentropy'>CrossEntropy</div>
				<div id = 'hinge' class = 'option select-option' data-optionValue = 'hinge'> Hinge </div>
				<div id = 'meanSquaredError' class = 'option select-option' data-optionValue = 'meanSquaredError'> MSE </div>
				<div id = 'meanAbsoluteError' class = 'option select-option' data-optionValue = 'meanAbsoluteError'> MAE </div>
			</div>
		</div>

		<div id = 'visualizationMenu' style="display: none">
			<div id = 'classes' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						分类
					</div>
				</div>
				<div class = 'option select-option selected' data-optionValue = 'all'> ALL </div>
				<div class = 'option select-option' data-optionValue = '0'> 0 </div>
				<div class = 'option select-option' data-optionValue = '1'> 1 </div>
				<div class = 'option select-option' data-optionValue = '2'> 2 </div>
				<div class = 'option select-option' data-optionValue = '3'> 3 </div>
				<div class = 'option select-option' data-optionValue = '4'> 4 </div>
				<div class = 'option select-option' data-optionValue = '5'> 5 </div>
				<div class = 'option select-option' data-optionValue = '6'> 6 </div>
				<div class = 'option select-option' data-optionValue = '7'> 7 </div>
				<div class = 'option select-option' data-optionValue = '8'> 8 </div>
				<div class = 'option select-option' data-optionValue = '9'> 9 </div>
			</div>
		</div>

		<div id = 'educationMenu' style="display: none">
			<div id = 'educationLayers' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						相关文章
					</div>

				</div>

				<div class = 'option select-option education-option' data-optionValue = 'Overview'> 概述 </div>
				<div class = 'option select-option education-option' data-optionValue = 'Overfitting'> Overfitting</div>
			</div>

			<div id = 'educationStory' class = 'category'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						神经网络层
					</div>
				</div>
                <div class = 'option select-option education-option' data-optionValue = 'ResNets'>ResNets</div>
				<div class = 'option select-option education-option' data-optionValue = 'Add'>Add</div>
				<div class = 'option select-option education-option' data-optionValue = 'BatchNorm'>Batch Norm</div>
				<div class = 'option select-option education-option' data-optionValue = 'Concatenate'> Concatenate </div>
				<div class = 'option select-option education-option' data-optionValue = 'Convolution'> Convolution </div>
				<div class = 'option select-option education-option' data-optionValue = 'MaxPooling'>Max Pooling</div>
				<div class = 'option select-option education-option' data-optionValue = 'Dropout'> Dropout </div>
				<div class = 'option select-option education-option' data-optionValue = 'Flatten'> Flatten </div>
				<div class = 'option select-option education-option' data-optionValue = 'Dense'>Dense</div>

			</div>
			<div id = 'educationModel' class = 'category'>
				<div class = 'categoryTitle data-expanded' = 'true'>
					<div class = 'expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						模型教学
					</div>
				</div>
				<div class = 'option select-option education-option' data-optionValue = 'MLP'> 感知机 </div>
				<div class = 'option select-option education-option' data-optionValue = 'CNN'> 卷积神经网络 </div>
				<div class = 'option select-option education-option' data-optionValue = 'newCNN'> 现代卷积神经网络 </div>
				<div class = 'option select-option education-option' data-optionValue = 'RNN'> 循环神经网络 </div>
				<div class = 'option select-option education-option' data-optionValue = 'newRNN'> 现代循环神经网络 </div>
				<div class = 'option select-option education-option' data-optionValue = 'Transformer'>Transformer</div>
			</div>


			<div id = 'educationAct' class = 'category'>
				<div class = 'categoryTitle data-expanded' = 'true'>
					<div class = 'expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						激活函数
					</div>
				</div>
				<div class = 'option select-option education-option' data-optionValue = 'ReLU'> 
					 <a href="#educationReLU" style="text-decoration: none; color: inherit; display: block;">
                      ReLU
                     </a>
				</div>
				<div class = 'option select-option education-option' data-optionValue = 'Sigmoid'> 
					 <a href="#educationSigmoid" style="text-decoration: none; color: inherit; display: block;">
                     Sigmoid
                     </a>
				</div>
				<div class = 'option select-option education-option' data-optionValue = 'Tanh'>
					 <a href="#educationTanh" style="text-decoration: none; color: inherit; display: block;">
                     Tanh
                    </a>
				</div>
                <div class = 'option select-option education-option' data-optionValue = 'Softmax'>
					 <a href="#educationSoftmax" style="text-decoration: none; color: inherit; display: block;">
                     Softmax
                    </a>
				</div>

				<div class = 'option select-option education-option' data-optionValue = 'empty'>
					 <a href="#educationempty" style="text-decoration: none; color: inherit; display: block;">
                         
                    </a>
				</div>
	
			</div>
		</div>
		

	</div>

	

	<!-- The middle canvas -->
	<div id = 'middle'>
		<!-- 添加 AI 助手的按钮 -->
		<div id="aiAssistantButton" class="floating-button">
			<svg width="50" height="50" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
				<circle cx="12" cy="12" r="10" fill="rgb(128,108,183)"/>
				<text x="12" y="16" text-anchor="middle" fill="white" font-size="14px" font-family="Arial" >AI</text>
			</svg>
		</div>

		<!-- 添加对话框 -->
		<div id="aiAssistantDialog" class="ai-dialog hidden">
			<div class="dialog-header">AI 助手</div>
			<div class="dialog-content" id="dialogContent"></div>
			<div id="aiContextAttachment" class="ai-context hidden">
				<div class="ai-context-main">
					<div class="ai-context-text"></div>
					<div id="aiContextActions" class="ai-context-actions hidden">
						<button class="ai-context-action" data-action="explain">解释说明</button>
						<button class="ai-context-action" data-action="summarize">概括内容</button>
						<button class="ai-context-action" data-action="quiz">出题测验</button>
					</div>
				</div>
				<button id="clearAiContext" class="ai-context-remove" title="移除附件">×</button>
			</div>
			<div class="dialog-footer">
				<input type="text" id="dialogInput" placeholder="输入消息..." />
				<button id="sendButton">发送</button>
			</div>
		</div>

		<div id="taskSteps">
			<div id="taskTitle" class="task-title" onclick="toggleTaskSteps()">
				<span id="taskTitleText">未选择任务</span>
				<span id="arrow" class="arrow">&#9660;</span> <!-- 初始为收起箭头 -->
			</div>
			<div id="taskContent" class="task-content" style="display: none;">
				<ul id="stepsList">
					<!-- 这里将动态显示步骤内容 -->
				</ul>
			</div>
		</div>

		<div id = 'networkTab'>
			<svg id = 'svg'> </svg>
		</div>

		<div id = 'progressTab' style="display: none">

			<div id="loss-canvas"></div>

			<div id="accuracy-canvas"></div>

			<div id="confusion-matrix-canvas"></div>
		</div>

		<div id = 'visualizationTab' style="display: none">
			<div id='visulaization'></div>
			<div id='images'></div>
		</div>

		<div id = 'informationOverlay'>
			<div id='information'>欢迎来到BBVDLE
				<div id="informationBody">~ 基于可视化积木编程的深度学习教学平台 ~</div>
				<div class="informationRow">
					<div class="informationColumn">
						自主创建神经网络 <br></br>
						<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="30%" max-height="30%" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M11.99 18.54l-7.37-5.73L3 14.07l9 7 9-7-1.63-1.27zM12 16l7.36-5.73L21 9l-9-7-9 7 1.63 1.27L12 16zm0-11.47L17.74 9 12 13.47 6.26 9 12 4.53z"/></svg>
					</div>
					<div class="informationBlankColumn"></div>
					<div id="informationEducation" class="informationColumn">
						开始学习如何创建神经网络 <br></br>
						<svg class = 'icon' xmlns="http://www.w3.org/2000/svg" width="30%" max-height="30%" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M12 3L1 9l4 2.18v6L12 21l7-3.82v-6l2-1.09V17h2V9L12 3zm6.82 6L12 12.72 5.18 9 12 5.28 18.82 9zM17 15.99l-5 2.73-5-2.73v-3.72L12 15l5-2.73v3.72z"/></svg>
					</div>
				</div>
				<div id = 'acknowledgements'>
					<br>
					袁子茜，崔雯嘉，周艺瑶，田桓钟，姜逸涵 <br>
					开源资源<a class="overlayLinks" href="https://github.com/sunyia123/bbvdle" target="_blank">BBVDLE</a>.
					改进自<a class="overlayLinks" href="https://github.com/martinjm97/ENNUI" target="_blank">ENNUI</a>.
				</div>
			</div>
		</div>

		<div id = 'educationTab' style="display: none">
			<div id="educationOverview">
				<div class="educationTitle" style="padding-top: 0px"> 关于深度学习神经网络 </div>
				<div class="educationContent">
					如果你第一次进入我们的教学平台, 
					可以参考以下的快速入门教学开始自己的神经网络学习之旅：
				</div>
				<!--<iframe class="educationVideo" src="https://www.youtube.com/embed/m0YnwAtPbb8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->

				<div style="text-align: center; font-size: 25px;"><a href="https://www.youtube.com/watch?v=m0YnwAtPbb8" target="blank">ENNUI 教学</a></div>
				
				<div class="educationSection"> 深度学习的基本知识 </div>
				<div class="educationContent">
					如果您不熟悉机器学习，下面的讲座视频是一个很好的介绍。
				</div>
				<div style="text-align: center; font-size: 25px;"><a href="https://video.odl.mit.edu/videos/9101a72a7d994d53800d1398fd885b88/embed/?start=339" target="blank">Gilbert Strang: Deep Learning</a></div>
				<!-- <iframe class="educationVideo" src="https://video.odl.mit.edu/videos/9101a72a7d994d53800d1398fd885b88/embed/?start=339" scrolling="no" frameborder="0" allowfullscreen></iframe> -->
                <!-- educationOverview 部分的做题链接改为 -->
                <!-- 重新设计的学习练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">📚 知识练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">完成以下练习来巩固您对深度学习基础概念的理解</p>

                    <div class="exercise-cards">
                        <!-- 概述知识练习卡片 -->
                        <div class="exercise-card" data-exercise="overview_quiz">
                            <div class="card-header">
                                <h4>📖 概述知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对深度学习基本概念的理解，包括与传统机器学习的区别、应用场景等。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                    <div class="question">
                                        <p><strong>题目1:</strong> 深度学习与传统机器学习的主要区别是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="q1" value="A"> A. 深度学习需要更多的数据</label>
                                            <label><input type="radio" name="q1" value="B"> B. 深度学习能够自动学习特征</label>
                                            <label><input type="radio" name="q1" value="C"> C. 深度学习模型更简单</label>
                                            <label><input type="radio" name="q1" value="D"> D. 深度学习不需要调参</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目2:</strong> 以下哪个不是深度学习的典型应用？</p>
                                        <div class="options">
                                            <label><input type="radio" name="q2" value="A"> A. 图像识别</label>
                                            <label><input type="radio" name="q2" value="B"> B. 语音识别</label>
                                            <label><input type="radio" name="q2" value="C"> C. 文本分类</label>
                                            <label><input type="radio" name="q2" value="D"> D. 数据库查询优化</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目3:</strong> 神经网络的基本组成单元是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="q3" value="A"> A. 节点</label>
                                            <label><input type="radio" name="q3" value="B"> B. 神经元</label>
                                            <label><input type="radio" name="q3" value="C"> C. 处理器</label>
                                            <label><input type="radio" name="q3" value="D"> D. 函数</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目4:</strong> 深度学习模型训练的核心算法是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="q4" value="A"> A. 支持向量机</label>
                                            <label><input type="radio" name="q4" value="B"> B. 决策树</label>
                                            <label><input type="radio" name="q4" value="C"> C. 梯度下降</label>
                                            <label><input type="radio" name="q4" value="D"> D. K近邻</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目5:</strong> 以下哪个框架主要用于深度学习？</p>
                                        <div class="options">
                                            <label><input type="radio" name="q5" value="A"> A. TensorFlow</label>
                                            <label><input type="radio" name="q5" value="B"> B. Scikit-learn</label>
                                            <label><input type="radio" name="q5" value="C"> C. Pandas</label>
                                            <label><input type="radio" name="q5" value="D"> D. NumPy</label>
                                        </div>
                                    </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="overview_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                                </div>
                            </div>

                        <!-- 基础概念练习卡片 -->
                        <div class="exercise-card" data-exercise="basic_concepts">
                            <div class="card-header">
                                <h4>🎯 基础概念练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>练习过拟合、偏差-方差权衡、正则化等机器学习基础概念。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                    <div class="question">
                                        <p><strong>题目1:</strong> 什么是过拟合？</p>
                                        <div class="options">
                                            <label><input type="radio" name="q6" value="A"> A. 模型在训练集上表现太好</label>
                                            <label><input type="radio" name="q6" value="B"> B. 模型在测试集上表现太好</label>
                                            <label><input type="radio" name="q6" value="C"> C. 模型无法学习</label>
                                            <label><input type="radio" name="q6" value="D"> D. 模型训练时间太长</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目2:</strong> 以下哪个是防止过拟合的方法？</p>
                                        <div class="options">
                                            <label><input type="radio" name="q7" value="A"> A. 增加模型复杂度</label>
                                            <label><input type="radio" name="q7" value="B"> B. 减少训练数据</label>
                                            <label><input type="radio" name="q7" value="C"> C. 使用Dropout</label>
                                            <label><input type="radio" name="q7" value="D"> D. 延长训练时间</label>
                                        </div>
                                    </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 什么是偏差-方差权衡？</p>
                                    <div class="options">
                                        <label><input type="radio" name="q8" value="A"> A. 模型准确率与训练时间的权衡</label>
                                        <label><input type="radio" name="q8" value="B"> B. 模型复杂度和泛化能力的权衡</label>
                                        <label><input type="radio" name="q8" value="C"> C. 数据量与模型精度的权衡</label>
                                        <label><input type="radio" name="q8" value="D"> D. 学习率与收敛速度的权衡</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 以下哪个不是正则化的方法？</p>
                                    <div class="options">
                                        <label><input type="radio" name="q9" value="A"> A. L1正则化</label>
                                        <label><input type="radio" name="q9" value="B"> B. L2正则化</label>
                                        <label><input type="radio" name="q9" value="C"> C. 数据增强</label>
                                        <label><input type="radio" name="q9" value="D"> D. 增加网络层数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 交叉验证的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="q10" value="A"> A. 加速模型训练</label>
                                        <label><input type="radio" name="q10" value="B"> B. 评估模型泛化能力</label>
                                        <label><input type="radio" name="q10" value="C"> C. 减少内存使用</label>
                                        <label><input type="radio" name="q10" value="D"> D. 简化模型结构</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="basic_concepts">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 深度学习基础练习卡片 -->
                        <div class="exercise-card" data-exercise="dl_fundamentals">
                            <div class="card-header">
                                <h4>🧠 深度学习基础</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>深入理解反向传播、梯度下降、激活函数等深度学习核心概念。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 什么是反向传播算法？</p>
                                    <div class="options">
                                        <label><input type="radio" name="q11" value="A"> A. 前向计算神经网络输出</label>
                                        <label><input type="radio" name="q11" value="B"> B. 计算损失函数的梯度</label>
                                        <label><input type="radio" name="q11" value="C"> C. 初始化网络权重</label>
                                        <label><input type="radio" name="q11" value="D"> D. 选择优化算法</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 梯度下降算法的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="q12" value="A"> A. 计算函数的导数</label>
                                        <label><input type="radio" name="q12" value="B"> B. 最小化损失函数</label>
                                        <label><input type="radio" name="q12" value="C"> C. 增加模型复杂度</label>
                                        <label><input type="radio" name="q12" value="D"> D. 评估模型性能</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 什么是激活函数？</p>
                                    <div class="options">
                                        <label><input type="radio" name="q13" value="A"> A. 网络的输入函数</label>
                                        <label><input type="radio" name="q13" value="B"> B. 网络的输出函数</label>
                                        <label><input type="radio" name="q13" value="C"> C. 引入非线性的函数</label>
                                        <label><input type="radio" name="q13" value="D"> D. 计算损失的函数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> ReLU激活函数的公式是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="q14" value="A"> A. f(x) = 1/(1+e^(-x))</label>
                                        <label><input type="radio" name="q14" value="B"> B. f(x) = max(0, x)</label>
                                        <label><input type="radio" name="q14" value="C"> C. f(x) = tanh(x)</label>
                                        <label><input type="radio" name="q14" value="D"> D. f(x) = e^x</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 什么是批量大小（batch size）？</p>
                                    <div class="options">
                                        <label><input type="radio" name="q15" value="A"> A. 网络的总参数量</label>
                                        <label><input type="radio" name="q15" value="B"> B. 每次更新的样本数量</label>
                                        <label><input type="radio" name="q15" value="C"> C. 网络的层数</label>
                                        <label><input type="radio" name="q15" value="D"> D. 训练的总轮数</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="dl_fundamentals">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>

			<div id="educationConvolution">
				<div class="educationTitle"> 卷积网络 </div>
				<div class="educationAuthor">作者 <i>Gilbert Strang</i></div>

				<div class="educationContent">
					<p><strong>权重共享</strong> 这一词是卷积神经网络（CNNs）的核心思想。连接一层到另一层的权重矩阵<span class="math inline">\(A\)</span>  只有少数几个独立元素。 因此，优化这些权重的速度比全连接（密集）架构更快。</p>
					<p>在一维问题中，假设输入层（第0层）由一个向量<span class="math inline">\(v = (v_1,...,v_n)\)</span>表示。 卷积层将 <span class="math inline">\(v\)</span> 与一个具有常数对角线的权重矩阵 <span class="math inline">\(A\)</span> 相乘。然后，整个层中将重复使用相同的权重集（假设是 3 个权重）： </p>
					<p><span class="math display">\[A=
					\begin{bmatrix}
						a_{-1} &amp; a_0 &amp; a_1 &amp;  &amp;  \\
						&amp; a_{-1} &amp; a_0 &amp; a_1 &amp;  \\
						&amp; &amp; a_{-1} &amp; a_0 &amp; a_1 \\
					\end{bmatrix}\]</span> 这个矩阵 <span class="math inline">\(A\)</span> 有 <span class="math inline">\(n = 5\)</span> 个输出和 <span class="math inline">\(m = 3\)</span> 个输出。 A 是<strong>平移不变</strong>的: 卷积 = 滤波器 = Toeplitz 矩阵。卷积对于有许多像素的图像尤其重要。那 <span class="math inline">\(3\)</span> 个独立的权重<span class="math inline">\(a_{-1}, a_0, a_1\)</span> 可能在二维中变成 <span class="math inline">\(3 \times 3=9\)</span> 个权重。这 9 个数是 <span class="math inline">\(a_{ij}\)</span> 其中 <span class="math inline">\(i = -1,0,1\)</span> 和 <span class="math inline">\(j = -1,0,1\)</span>。一个包含其 8 个邻居（在一个 <span class="math inline">\(3 \times 3\)</span> 的方块中的输入）将与 <span class="math inline">\(a_{00}\)</span> 及其   <span class="math inline">\(8\)</span> 个邻居相乘——这 9 项的和给出一个输出 <span class="math inline">\(Av\)</span>。像往常一样，偏置向量  <span class="math inline">\(b\)</span> 会被加到结果中，并且  <span class="math inline">\(Av + b\)</span> 的每个分量都会通过像 ReLU 这样的函数进行激活（或不激活）：新层包含 <span class="math inline">\(\textrm{ReLU}(Av + b)\)</span>.</p>
					<p>这个二维矩阵 <span class="math inline">\(A\)</span> 并不容易显示。你应该可以看到，围绕一个大小为 <span class="math inline">\(n \times n\)</span> 的输入向量 <span class="math inline">\(v\)</span> 的一个 <span class="math inline">\(3 \times 3\)</span> 方块将产生一个大小为 <span class="math inline">\((n - 2) \times (n - 2)\)</span> 的输出，就像在一维中 5 个输入产生了 3 个输出一样。注意，在二维中我们只有 <span class="math inline">\(3 \times 3 = 9\)</span>（或者也许是 <span class="math inline">\(5 \times 5 = 25\)</span>）个独立的权重，因为卷积不仅是 <strong>共享权重</strong>，而且是 <strong>局部的</strong>。</p>
				</div>
                    <!-- 新增的做题链接部分 -->
                <!-- 卷积网络练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">🧠 卷积网络练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">完成以下练习来巩固卷积神经网络的相关知识</p>

                    <div class="exercise-cards">
                        <!-- 卷积知识测试卡片 -->
                        <div class="exercise-card" data-exercise="convolution_quiz">
                            <div class="card-header">
                                <h4>📐 卷积知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对卷积操作、卷积核、特征提取等基本概念的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 卷积操作的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="conv_q1" value="A"> A. 降低计算复杂度</label>
                                        <label><input type="radio" name="conv_q1" value="B"> B. 提取局部特征</label>
                                        <label><input type="radio" name="conv_q1" value="C"> C. 增加模型深度</label>
                                        <label><input type="radio" name="conv_q1" value="D"> D. 防止过拟合</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 卷积核的大小通常用什么表示？</p>
                                    <div class="options">
                                        <label><input type="radio" name="conv_q2" value="A"> A. 1×1</label>
                                        <label><input type="radio" name="conv_q2" value="B"> B. 3×3</label>
                                        <label><input type="radio" name="conv_q2" value="C"> C. 5×5</label>
                                        <label><input type="radio" name="conv_q2" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 填充（padding）的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="conv_q3" value="A"> A. 增加输出特征图大小</label>
                                        <label><input type="radio" name="conv_q3" value="B"> B. 保持输出特征图大小</label>
                                        <label><input type="radio" name="conv_q3" value="C"> C. 减少输出特征图大小</label>
                                        <label><input type="radio" name="conv_q3" value="D"> D. 增加通道数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 步长（stride）的默认值是多少？</p>
                                    <div class="options">
                                        <label><input type="radio" name="conv_q4" value="A"> A. 0</label>
                                        <label><input type="radio" name="conv_q4" value="B"> B. 1</label>
                                        <label><input type="radio" name="conv_q4" value="C"> C. 2</label>
                                        <label><input type="radio" name="conv_q4" value="D"> D. 3</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 以下哪种操作可以增加特征图的深度？</p>
                                    <div class="options">
                                        <label><input type="radio" name="conv_q5" value="A"> A. 池化操作</label>
                                        <label><input type="radio" name="conv_q5" value="B"> B. 激活函数</label>
                                        <label><input type="radio" name="conv_q5" value="C"> C. 使用多个卷积核</label>
                                        <label><input type="radio" name="conv_q5" value="D"> D. 批量归一化</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="convolution_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 卷积核计算练习卡片 -->
                        <div class="exercise-card" data-exercise="kernel_calculation">
                            <div class="card-header">
                                <h4>🔢 卷积核计算练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>练习卷积核的计算过程，理解卷积运算的数学原理。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 如果输入特征图大小为4×4，卷积核大小为3×3，步长为1，无填充，输出大小是多少？</p>
                                    <div class="options">
                                        <label><input type="radio" name="kernel_q1" value="A"> A. 1×1</label>
                                        <label><input type="radio" name="kernel_q1" value="B"> B. 2×2</label>
                                        <label><input type="radio" name="kernel_q1" value="C"> C. 3×3</label>
                                        <label><input type="radio" name="kernel_q1" value="D"> D. 4×4</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 卷积计算中，输出特征图的计算公式是什么？（输入大小为W，卷积核大小为K，步长为S，填充为P）</p>
                                    <div class="options">
                                        <label><input type="radio" name="kernel_q2" value="A"> A. (W-K+2P)/S + 1</label>
                                        <label><input type="radio" name="kernel_q2" value="B"> B. (W+K+2P)/S + 1</label>
                                        <label><input type="radio" name="kernel_q2" value="C"> C. (W-K-2P)/S + 1</label>
                                        <label><input type="radio" name="kernel_q2" value="D"> D. (W*K+2P)/S + 1</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 使用3×3卷积核对5×5输入进行卷积，步长为2，填充为1，输出特征图大小是多少？</p>
                                    <div class="options">
                                        <label><input type="radio" name="kernel_q3" value="A"> A. 2×2</label>
                                        <label><input type="radio" name="kernel_q3" value="B"> B. 3×3</label>
                                        <label><input type="radio" name="kernel_q3" value="C"> C. 4×4</label>
                                        <label><input type="radio" name="kernel_q3" value="D"> D. 5×5</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 如果要保持输入和输出特征图大小相同，使用3×3卷积核需要多少填充？</p>
                                    <div class="options">
                                        <label><input type="radio" name="kernel_q4" value="A"> A. 0</label>
                                        <label><input type="radio" name="kernel_q4" value="B"> B. 1</label>
                                        <label><input type="radio" name="kernel_q4" value="C"> C. 2</label>
                                        <label><input type="radio" name="kernel_q4" value="D"> D. 3</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 转置卷积（deconvolution）通常用于什么任务？</p>
                                    <div class="options">
                                        <label><input type="radio" name="kernel_q5" value="A"> A. 图像分类</label>
                                        <label><input type="radio" name="kernel_q5" value="B"> B. 图像分割</label>
                                        <label><input type="radio" name="kernel_q5" value="C"> C. 图像生成</label>
                                        <label><input type="radio" name="kernel_q5" value="D"> D. B和C都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="kernel_calculation">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 特征提取分析卡片 -->
                        <div class="exercise-card" data-exercise="feature_extraction">
                            <div class="card-header">
                                <h4>🔍 特征提取分析</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>分析CNN如何通过多层卷积提取图像的层次化特征。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> CNN的浅层卷积核通常检测什么类型的特征？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feature_q1" value="A"> A. 复杂形状</label>
                                        <label><input type="radio" name="feature_q1" value="B"> B. 简单边缘和纹理</label>
                                        <label><input type="radio" name="feature_q1" value="C"> C. 整体轮廓</label>
                                        <label><input type="radio" name="feature_q1" value="D"> D. 颜色信息</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 随着网络深度的增加，卷积核学习的特征复杂度如何变化？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feature_q2" value="A"> A. 从复杂到简单</label>
                                        <label><input type="radio" name="feature_q2" value="B"> B. 从简单到复杂</label>
                                        <label><input type="radio" name="feature_q2" value="C"> C. 保持不变</label>
                                        <label><input type="radio" name="feature_q2" value="D"> D. 随机变化</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 感受野（receptive field）指的是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feature_q3" value="A"> A. 卷积核的大小</label>
                                        <label><input type="radio" name="feature_q3" value="B"> B. 输出像素对应的输入区域</label>
                                        <label><input type="radio" name="feature_q3" value="C"> C. 特征图尺寸</label>
                                        <label><input type="radio" name="feature_q3" value="D"> D. 通道数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 空洞卷积（dilated convolution）的主要优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feature_q4" value="A"> A. 减少参数量</label>
                                        <label><input type="radio" name="feature_q4" value="B"> B. 增加感受野而不增加参数</label>
                                        <label><input type="radio" name="feature_q4" value="C"> C. 加速计算</label>
                                        <label><input type="radio" name="feature_q4" value="D"> D. 减少过拟合</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 深度可分离卷积（depthwise separable convolution）相比标准卷积的优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feature_q5" value="A"> A. 提高准确率</label>
                                        <label><input type="radio" name="feature_q5" value="B"> B. 减少计算量和参数量</label>
                                        <label><input type="radio" name="feature_q5" value="C"> C. 增加模型深度</label>
                                        <label><input type="radio" name="feature_q5" value="D"> D. 简化训练过程</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="feature_extraction">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>

			<div id="educationResNets">
				<div class="educationTitle"> 残差网络 (ResNets) </div>
				<div class="educationAuthor">作者 <i>Zack Holbrook</i> and <i>Jesse Michel</i></div>

				<div class="educationContent">
					<p>2015 年，微软的一个研究团队凭借 ResNet 在 <a href="http://www.image-net.org/challenges/LSVRC/">ImageNet 大规模视觉识别挑战赛</a> 中获得了创纪录的表现。自 2015 年以来，ResNet 的变种一直主导着这一竞赛，超过了人类在该任务中的表现。它们已成为图像识别任务中广泛采用的架构，并且相对容易实现和训练。</p>
					<div class="educationSection">ResNet 架构</div>
					<p>ResNet 是一种卷积神经网络（CNN），具有 <strong>恒等捷径（identity shortcuts）</strong>，这是通过跳过某些层创建的网络路径，从而在网络中创建捷径。下面我们提供一个典型的 ResNet 示例：
				
						<img class="educationImage" src="dist/resnet.png" alt="Resnet image" width="50%">
				
						<div class="modelLink">
							<a class="modelLink" target="_newtab" href="http://math.mit.edu/ennui/#%7B%22graph%22:%5B%7B%22layer_name%22:%22Input%22,%22children_ids%22:%5B5,9%5D,%22parent_ids%22:%5B%5D,%22params%22:%7B%22dataset%22:%22mnist%22%7D,%22id%22:0,%22xPosition%22:100,%22yPosition%22:377%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B6%5D,%22parent_ids%22:%5B0%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D,%22activation%22:%22relu%22%7D,%22id%22:5,%22xPosition%22:169,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Add%22,%22children_ids%22:%5B7,10%5D,%22parent_ids%22:%5B0,6%5D,%22params%22:%7B%22activation%22:%22relu%22%7D,%22id%22:9,%22xPosition%22:276,%22yPosition%22:411%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B9%5D,%22parent_ids%22:%5B5%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D%7D,%22id%22:6,%22xPosition%22:294,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B8%5D,%22parent_ids%22:%5B9%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D,%22activation%22:%22relu%22%7D,%22id%22:7,%22xPosition%22:414,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Add%22,%22children_ids%22:%5B11%5D,%22parent_ids%22:%5B9,8%5D,%22params%22:%7B%22activation%22:%22relu%22%7D,%22id%22:10,%22xPosition%22:521,%22yPosition%22:412%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B10%5D,%22parent_ids%22:%5B7%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D%7D,%22id%22:8,%22xPosition%22:541,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Flatten%22,%22children_ids%22:%5B12%5D,%22parent_ids%22:%5B10%5D,%22params%22:%7B%7D,%22id%22:11,%22xPosition%22:708,%22yPosition%22:463%7D,%7B%22layer_name%22:%22Dense%22,%22children_ids%22:%5B13%5D,%22parent_ids%22:%5B11%5D,%22params%22:%7B%22units%22:32,%22activation%22:%22relu%22%7D,%22id%22:12,%22xPosition%22:702,%22yPosition%22:434%7D,%7B%22layer_name%22:%22Dropout%22,%22children_ids%22:%5B1%5D,%22parent_ids%22:%5B12%5D,%22params%22:%7B%22rate%22:0.5%7D,%22id%22:13,%22xPosition%22:778,%22yPosition%22:365%7D,%7B%22layer_name%22:%22Output%22,%22children_ids%22:%5B%5D,%22parent_ids%22:%5B13%5D,%22params%22:%7B%7D,%22id%22:1,%22xPosition%22:900,%22yPosition%22:377%7D%5D,%22hyperparameters%22:%7B%22learningRate%22:0.01,%22batchSize%22:64,%22optimizer_id%22:%22defaultOptimizer%22,%22epochs%22:6,%22loss_id%22:%22defaultLoss%22%7D%7D">
								模型链接
							</a>
						</div>
				
						恒等捷径意味着学习到的参数是残差。数学上，如果 <span class="math inline">\(R(x)\)</span> 是一系列卷积层与 ReLU 组合，称为 <strong>残差块</strong>，例如，假设 <span class="math display">\[R(x) = \textrm{Conv}(\textrm{ReLU}(\textrm{Conv}(x))).\]</span> 那么，残差块的输出将是 <span class="math inline">\(R(x) + x\)</span>，其中 <span class="math inline">\(x\)</span> 是恒等传递。如果神经网络试图逼近某个函数 <span class="math inline">\(F(x)\)</span>，那么一个完美的残差块 <span class="math inline">\(R^*(x)\)</span> 会使得 <span class="math inline">\(R^*(x) = F(x) - x\)</span>，这正是通过减去输入图像得到的残差。</p>
					<div class="educationSection">ResNet 的优势</div>
					<p>ResNet 的一个惊人特性是它的良好扩展性，使得深层神经网络仍然能够良好地训练。当网络变得更大时，许多问题会出现。</p>
					<p>大规模网络往往训练速度较慢，但 CNN 的 <strong>权重共享</strong> 意味着每个残差块需要训练的参数相对较少。大规模网络还往往面临 <strong>梯度消失</strong> 问题——在梯度下降中，权重更新会逐渐变得微不足道，导致即使有更多的训练时间，网络也无法改进。ResNet 中的恒等捷径为梯度提供了流动路径，从而避免了梯度消失的问题。</p>
				</div>
                    <!-- 新增的做题链接部分 -->
                <!-- ResNet练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">🏗️ ResNet练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">学习残差网络的核心概念和设计原理</p>

                    <div class="exercise-cards">
                        <!-- 残差网络知识测试卡片 -->
                        <div class="exercise-card" data-exercise="resnet_quiz">
                            <div class="card-header">
                                <h4>🔄 残差网络知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对残差网络基本概念和优势的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 残差网络主要解决的是什么问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="resnet_q1" value="A"> A. 梯度消失</label>
                                        <label><input type="radio" name="resnet_q1" value="B"> B. 过拟合</label>
                                        <label><input type="radio" name="resnet_q1" value="C"> C. 计算效率</label>
                                        <label><input type="radio" name="resnet_q1" value="D"> D. 数据预处理</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 残差块中的跳跃连接是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="resnet_q2" value="A"> A. 额外的卷积层</label>
                                        <label><input type="radio" name="resnet_q2" value="B"> B. 恒等映射</label>
                                        <label><input type="radio" name="resnet_q2" value="C"> C. 池化操作</label>
                                        <label><input type="radio" name="resnet_q2" value="D"> D. 激活函数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> ResNet-50中的"50"代表什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="resnet_q3" value="A"> A. 输入图像大小</label>
                                        <label><input type="radio" name="resnet_q3" value="B"> B. 网络层数</label>
                                        <label><input type="radio" name="resnet_q3" value="C"> C. 参数数量</label>
                                        <label><input type="radio" name="resnet_q3" value="D"> D. 准确率百分比</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 残差学习公式F(x) + x中的F(x)代表什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="resnet_q4" value="A"> A. 输入特征</label>
                                        <label><input type="radio" name="resnet_q4" value="B"> B. 残差函数</label>
                                        <label><input type="radio" name="resnet_q4" value="C"> C. 目标输出</label>
                                        <label><input type="radio" name="resnet_q4" value="D"> D. 损失函数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> ResNet相比普通网络的主要优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="resnet_q5" value="A"> A. 参数更少</label>
                                        <label><input type="radio" name="resnet_q5" value="B"> B. 更容易训练更深的网络</label>
                                        <label><input type="radio" name="resnet_q5" value="C"> C. 计算更快</label>
                                        <label><input type="radio" name="resnet_q5" value="D"> D. 内存占用更少</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="resnet_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 跳跃连接分析卡片 -->
                        <div class="exercise-card" data-exercise="skip_connection">
                            <div class="card-header">
                                <h4>⏭️ 跳跃连接分析</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>深入理解跳跃连接的工作原理和设计理念。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 跳跃连接允许梯度如何传播？</p>
                                    <div class="options">
                                        <label><input type="radio" name="skip_q1" value="A"> A. 只能向前传播</label>
                                        <label><input type="radio" name="skip_q1" value="B"> B. 直接跨越层传播</label>
                                        <label><input type="radio" name="skip_q1" value="C"> C. 只在最后一层传播</label>
                                        <label><input type="radio" name="skip_q1" value="D"> D. 随机传播</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 当残差块的输入输出维度不同时，如何处理跳跃连接？</p>
                                    <div class="options">
                                        <label><input type="radio" name="skip_q2" value="A"> A. 直接相加</label>
                                        <label><input type="radio" name="skip_q2" value="B"> B. 使用1×1卷积调整维度</label>
                                        <label><input type="radio" name="skip_q2" value="C"> C. 丢弃跳跃连接</label>
                                        <label><input type="radio" name="skip_q2" value="D"> D. 使用池化调整</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 瓶颈结构（bottleneck）的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="skip_q3" value="A"> A. 增加网络深度</label>
                                        <label><input type="radio" name="skip_q3" value="B"> B. 减少参数量和计算量</label>
                                        <label><input type="radio" name="skip_q3" value="C"> C. 提高准确率</label>
                                        <label><input type="radio" name="skip_q3" value="D"> D. 简化训练</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> ResNeXt的创新点是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="skip_q4" value="A"> A. 更深的网络</label>
                                        <label><input type="radio" name="skip_q4" value="B"> B. 分组卷积和基数设计</label>
                                        <label><input type="radio" name="skip_q4" value="C"> C. 新的激活函数</label>
                                        <label><input type="radio" name="skip_q4" value="D"> D. 更简单的结构</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> DenseNet与ResNet的主要区别是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="skip_q5" value="A"> A. DenseNet没有跳跃连接</label>
                                        <label><input type="radio" name="skip_q5" value="B"> B. DenseNet连接所有层</label>
                                        <label><input type="radio" name="skip_q5" value="C"> C. DenseNet更浅</label>
                                        <label><input type="radio" name="skip_q5" value="D"> D. DenseNet参数更多</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="skip_connection">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 梯度流练习卡片 -->
                        <div class="exercise-card" data-exercise="gradient_flow">
                            <div class="card-header">
                                <h4>🌊 梯度流练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>理解梯度在残差网络中的流动和反向传播机制。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 在残差网络中，梯度流是如何得到改善的？</p>
                                    <div class="options">
                                        <label><input type="radio" name="grad_q1" value="A"> A. 通过减少网络深度</label>
                                        <label><input type="radio" name="grad_q1" value="B"> B. 通过提供更短的路径</label>
                                        <label><input type="radio" name="grad_q1" value="C"> C. 通过增加学习率</label>
                                        <label><input type="radio" name="grad_q1" value="D"> D. 通过减少参数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 什么是梯度消失问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="grad_q2" value="A"> A. 梯度变为0</label>
                                        <label><input type="radio" name="grad_q2" value="B"> B. 梯度变得很大</label>
                                        <label><input type="radio" name="grad_q2" value="C"> C. 梯度随机变化</label>
                                        <label><input type="radio" name="grad_q2" value="D"> D. 梯度停止更新</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> Batch Normalization如何帮助梯度流动？</p>
                                    <div class="options">
                                        <label><input type="radio" name="grad_q3" value="A"> A. 减少内部协变量偏移</label>
                                        <label><input type="radio" name="grad_q3" value="B"> B. 增加网络深度</label>
                                        <label><input type="radio" name="grad_q3" value="C"> C. 减少过拟合</label>
                                        <label><input type="radio" name="grad_q3" value="D"> D. 改变优化算法</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 残差网络中恒等映射的导数是多少？</p>
                                    <div class="options">
                                        <label><input type="radio" name="grad_q4" value="A"> A. 0</label>
                                        <label><input type="radio" name="grad_q4" value="B"> B. 1</label>
                                        <label><input type="radio" name="grad_q4" value="C"> C. -1</label>
                                        <label><input type="radio" name="grad_q4" value="D"> D. 随机值</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 为什么深层网络训练更困难？</p>
                                    <div class="options">
                                        <label><input type="radio" name="grad_q5" value="A"> A. 参数太多</label>
                                        <label><input type="radio" name="grad_q5" value="B"> B. 梯度消失或爆炸</label>
                                        <label><input type="radio" name="grad_q5" value="C"> C. 计算太慢</label>
                                        <label><input type="radio" name="grad_q5" value="D"> D. 内存不足</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="gradient_flow">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>

			<div id="educationFlatten">
				<div class="educationTitle"> 展平层（Flatten） </div>
				<div class="educationAuthor">作者 <i>Zack Holbrook</i> and <i>Jesse Michel</i></div>

				<div class="educationContent">
					<p>展平层接受一个多维输入并产生一个一维输出。例如，CIFAR 数据集是一个包含图像的集合，它是三维的，因为它由32x32像素的二维图像组成，并且有3个颜色通道（红色、绿色、蓝色）。一个展平层可以将该数据集的数据作为输入，输出一个大小为 32*32*3 = 3072 的一维向量。</p>
				</div>
                <!-- 新增的做题链接部分 -->
                <!-- 展平层练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">📏 展平层练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">学习展平操作及其在神经网络中的应用</p>

                    <div class="exercise-cards">
                        <!-- 展平层知识测试卡片 -->
                        <div class="exercise-card" data-exercise="flatten_quiz">
                            <div class="card-header">
                                <h4>📊 展平层知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对展平层基本概念和作用的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 展平层（Flatten）的输入通常是什么形状？</p>
                                    <div class="options">
                                        <label><input type="radio" name="flat_q1" value="A"> A. 一维向量</label>
                                        <label><input type="radio" name="flat_q1" value="B"> B. 二维矩阵</label>
                                        <label><input type="radio" name="flat_q1" value="C"> C. 三维张量</label>
                                        <label><input type="radio" name="flat_q1" value="D"> D. 四维张量</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 展平层通常用于连接什么类型的层？</p>
                                    <div class="options">
                                        <label><input type="radio" name="flat_q2" value="A"> A. 卷积层到卷积层</label>
                                        <label><input type="radio" name="flat_q2" value="B"> B. 卷积层到全连接层</label>
                                        <label><input type="radio" name="flat_q2" value="C"> C. 全连接层到全连接层</label>
                                        <label><input type="radio" name="flat_q2" value="D"> D. 池化层到池化层</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 展平操作是否会丢失空间信息？</p>
                                    <div class="options">
                                        <label><input type="radio" name="flat_q3" value="A"> A. 完全丢失</label>
                                        <label><input type="radio" name="flat_q3" value="B"> B. 部分保留</label>
                                        <label><input type="radio" name="flat_q3" value="C"> C. 完全保留</label>
                                        <label><input type="radio" name="flat_q3" value="D"> D. 看情况而定</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 展平层之后的全连接层需要多少个神经元？</p>
                                    <div class="options">
                                        <label><input type="radio" name="flat_q4" value="A"> A. 输入通道数</label>
                                        <label><input type="radio" name="flat_q4" value="B"> B. 展平后的元素总数</label>
                                        <label><input type="radio" name="flat_q4" value="C"> C. 任意数量</label>
                                        <label><input type="radio" name="flat_q4" value="D"> D. 等于类别数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 在CNN中，展平层的位置通常在哪里？</p>
                                    <div class="options">
                                        <label><input type="radio" name="flat_q5" value="A"> A. 网络开始处</label>
                                        <label><input type="radio" name="flat_q5" value="B"> B. 卷积层和全连接层之间</label>
                                        <label><input type="radio" name="flat_q5" value="C"> C. 网络结尾处</label>
                                        <label><input type="radio" name="flat_q5" value="D"> D. 池化层之后</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="flatten_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 维度计算练习卡片 -->
                        <div class="exercise-card" data-exercise="dimension_calculation">
                            <div class="card-header">
                                <h4>📐 维度计算练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>练习张量维度的计算，掌握展平操作的数学原理。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 32×32×3的图像展平后变成多少维向量？</p>
                                    <div class="options">
                                        <label><input type="radio" name="dim_q1" value="A"> A. 3072</label>
                                        <label><input type="radio" name="dim_q1" value="B"> B. 1024</label>
                                        <label><input type="radio" name="dim_q1" value="C"> C. 96</label>
                                        <label><input type="radio" name="dim_q1" value="D"> D. 32</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 4×4×64的特征图展平后有多少元素？</p>
                                    <div class="options">
                                        <label><input type="radio" name="dim_q2" value="A"> A. 64</label>
                                        <label><input type="radio" name="dim_q2" value="B"> B. 256</label>
                                        <label><input type="radio" name="dim_q2" value="C"> C. 1024</label>
                                        <label><input type="radio" name="dim_q2" value="D"> D. 16384</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 展平操作如何影响批量大小？</p>
                                    <div class="options">
                                        <label><input type="radio" name="dim_q3" value="A"> A. 批量大小变为1</label>
                                        <label><input type="radio" name="dim_q3" value="B"> B. 批量大小保持不变</label>
                                        <label><input type="radio" name="dim_q3" value="C"> C. 批量大小翻倍</label>
                                        <label><input type="radio" name="dim_q3" value="D"> D. 批量大小减半</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 展平后的向量维度计算公式是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="dim_q4" value="A"> A. H × W × C</label>
                                        <label><input type="radio" name="dim_q4" value="B"> B. H + W + C</label>
                                        <label><input type="radio" name="dim_q4" value="C"> C. H × W ÷ C</label>
                                        <label><input type="radio" name="dim_q4" value="D"> D. (H × W × C) ÷ batch_size</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> Global Average Pooling可以替代展平层吗？</p>
                                    <div class="options">
                                        <label><input type="radio" name="dim_q5" value="A"> A. 不可以，完全不同</label>
                                        <label><input type="radio" name="dim_q5" value="B"> B. 可以，在某些情况下</label>
                                        <label><input type="radio" name="dim_q5" value="C"> C. 可以，效果更好</label>
                                        <label><input type="radio" name="dim_q5" value="D"> D. 可以，但更复杂</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="dimension_calculation">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 张量操作练习卡片 -->
                        <div class="exercise-card" data-exercise="tensor_operations">
                            <div class="card-header">
                                <h4>🔄 张量操作练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>练习张量操作和变换，理解深度学习中的数据流。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 张量（tensor）的维度通常如何表示？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tensor_q1" value="A"> A. (batch_size, height, width)</label>
                                        <label><input type="radio" name="tensor_q1" value="B"> B. (batch_size, channels, height, width)</label>
                                        <label><input type="radio" name="tensor_q1" value="C"> C. (height, width, channels)</label>
                                        <label><input type="radio" name="tensor_q1" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> Reshape操作和展平操作有什么区别？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tensor_q2" value="A"> A. Reshape保持元素顺序</label>
                                        <label><input type="radio" name="tensor_q2" value="B"> B. 展平只能变为一维</label>
                                        <label><input type="radio" name="tensor_q2" value="C"> C. Reshape可以改变维度</label>
                                        <label><input type="radio" name="tensor_q2" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> Transpose操作通常用于什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tensor_q3" value="A"> A. 改变数据类型</label>
                                        <label><input type="radio" name="tensor_q3" value="B"> B. 重新排列维度顺序</label>
                                        <label><input type="radio" name="tensor_q3" value="C"> C. 增加维度</label>
                                        <label><input type="radio" name="tensor_q3" value="D"> D. 减少维度</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> Squeeze操作的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tensor_q4" value="A"> A. 移除大小为1的维度</label>
                                        <label><input type="radio" name="tensor_q4" value="B"> B. 增加维度</label>
                                        <label><input type="radio" name="tensor_q4" value="C"> C. 改变元素值</label>
                                        <label><input type="radio" name="tensor_q4" value="D"> D. 复制张量</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> Concatenate操作在神经网络中最常用于？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tensor_q5" value="A"> A. 合并不同来源的特征</label>
                                        <label><input type="radio" name="tensor_q5" value="B"> B. 分割特征图</label>
                                        <label><input type="radio" name="tensor_q5" value="C"> C. 改变特征大小</label>
                                        <label><input type="radio" name="tensor_q5" value="D"> D. 减少特征维度</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="tensor_operations">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>

			<div id="educationConcatenate">
				<div class="educationTitle">拼接层（Concentrate）</div>
				<div class="educationAuthor">作者<i>Zack Holbrook</i> 和 <i>Jesse Michel</i></div>
			
				<div class="educationContent">
					<p>拼接层接受两个或更多层，并通过将输入堆叠在一起将它们的输出拼接成一个单一输出。例如，它可以将两个大小为 10 的向量拼接成一个大小为 20 的向量，方法是将一个向量堆叠在另一个向量的上面。</p>
				</div>
                    <!-- 新增的做题链接部分 -->
                <!-- 拼接层练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">🔗 拼接层练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">学习张量拼接和特征融合技术</p>

                    <div class="exercise-cards">
                        <!-- 拼接层知识测试卡片 -->
                        <div class="exercise-card" data-exercise="concatenate_quiz">
                            <div class="card-header">
                                <h4>🔗 拼接层知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对拼接层基本概念和应用场景的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> Concatenate操作是在哪个维度上拼接张量？</p>
                                    <div class="options">
                                        <label><input type="radio" name="concat_q1" value="A"> A. 最后一个维度</label>
                                        <label><input type="radio" name="concat_q1" value="B"> B. 指定的维度</label>
                                        <label><input type="radio" name="concat_q1" value="C"> C. 第一个维度</label>
                                        <label><input type="radio" name="concat_q1" value="D"> D. 随机维度</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> Inception模块中大量使用了哪种操作？</p>
                                    <div class="options">
                                        <label><input type="radio" name="concat_q2" value="A"> A. Add</label>
                                        <label><input type="radio" name="concat_q2" value="B"> B. Multiply</label>
                                        <label><input type="radio" name="concat_q2" value="C"> C. Concatenate</label>
                                        <label><input type="radio" name="concat_q2" value="D"> D. Subtract</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 拼接两个32×32×64的特征图，结果的通道数是多少？</p>
                                    <div class="options">
                                        <label><input type="radio" name="concat_q3" value="A"> A. 32</label>
                                        <label><input type="radio" name="concat_q3" value="B"> B. 64</label>
                                        <label><input type="radio" name="concat_q3" value="C"> C. 128</label>
                                        <label><input type="radio" name="concat_q3" value="D"> D. 96</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> Concatenate和Add操作的主要区别是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="concat_q4" value="A"> A. Concatenate增加通道数</label>
                                        <label><input type="radio" name="concat_q4" value="B"> B. Add保持通道数不变</label>
                                        <label><input type="radio" name="concat_q4" value="C"> C. Concatenate需要相同尺寸</label>
                                        <label><input type="radio" name="concat_q4" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> DenseNet的核心操作是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="concat_q5" value="A"> A. 残差连接</label>
                                        <label><input type="radio" name="concat_q5" value="B"> B. 密集连接</label>
                                        <label><input type="radio" name="concat_q5" value="C"> C. 跳跃连接</label>
                                        <label><input type="radio" name="concat_q5" value="D"> D. 短连接</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="concatenate_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 张量拼接练习卡片 -->
                        <div class="exercise-card" data-exercise="tensor_concatenation">
                            <div class="card-header">
                                <h4>📋 张量拼接练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>练习张量拼接的具体操作和维度计算。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 拼接两个形状为[2, 3, 4]的张量，维度为1，结果形状是？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tconcat_q1" value="A"> A. [2, 6, 4]</label>
                                        <label><input type="radio" name="tconcat_q1" value="B"> B. [4, 3, 4]</label>
                                        <label><input type="radio" name="tconcat_q1" value="C"> C. [2, 3, 8]</label>
                                        <label><input type="radio" name="tconcat_q1" value="D"> D. [2, 3, 4]</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 要拼接在通道维度上，PyTorch中的dim参数应该是？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tconcat_q2" value="A"> A. 0</label>
                                        <label><input type="radio" name="tconcat_q2" value="B"> B. 1</label>
                                        <label><input type="radio" name="tconcat_q2" value="C"> C. 2</label>
                                        <label><input type="radio" name="tconcat_q2" value="D"> D. 3</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 拼接操作要求张量在哪些维度上必须相同？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tconcat_q3" value="A"> A. 拼接维度</label>
                                        <label><input type="radio" name="tconcat_q3" value="B"> B. 除拼接维度外的所有维度</label>
                                        <label><input type="radio" name="tconcat_q3" value="C"> C. 所有维度</label>
                                        <label><input type="radio" name="tconcat_q3" value="D"> D. 没有要求</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> U-Net中上下采样特征的拼接方式是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tconcat_q4" value="A"> A. 直接相加</label>
                                        <label><input type="radio" name="tconcat_q4" value="B"> B. 通道维度拼接</label>
                                        <label><input type="radio" name="tconcat_q4" value="C"> C. 空间维度拼接</label>
                                        <label><input type="radio" name="tconcat_q4" value="D"> D. 批量维度拼接</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> Concatenate操作的输出通道数计算公式是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="tconcat_q5" value="A"> A. 输入通道数之和</label>
                                        <label><input type="radio" name="tconcat_q5" value="B"> B. 输入通道数之差</label>
                                        <label><input type="radio" name="tconcat_q5" value="C"> C. 输入通道数的最大值</label>
                                        <label><input type="radio" name="tconcat_q5" value="D"> D. 输入通道数的平均值</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="tensor_concatenation">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 特征融合分析卡片 -->
                        <div class="exercise-card" data-exercise="feature_fusion">
                            <div class="card-header">
                                <h4>🔬 特征融合分析</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>分析不同特征融合方法的特点和应用场景。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 特征融合最主要的目的是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fusion_q1" value="A"> A. 减少参数量</label>
                                        <label><input type="radio" name="fusion_q1" value="B"> B. 提高特征表示能力</label>
                                        <label><input type="radio" name="fusion_q1" value="C"> C. 加速计算</label>
                                        <label><input type="radio" name="fusion_q1" value="D"> D. 简化网络结构</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 多尺度特征融合通常用于解决什么问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fusion_q2" value="A"> A. 目标检测中的尺度变化</label>
                                        <label><input type="radio" name="fusion_q2" value="B"> B. 颜色变化</label>
                                        <label><input type="radio" name="fusion_q2" value="C"> C. 光照变化</label>
                                        <label><input type="radio" name="fusion_q2" value="D"> D. 噪声干扰</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> FPN（Feature Pyramid Network）使用什么融合方式？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fusion_q3" value="A"> A. 简单的拼接</label>
                                        <label><input type="radio" name="fusion_q3" value="B"> B. 横向连接和上采样</label>
                                        <label><input type="radio" name="fusion_q3" value="C"> C. 直接相加</label>
                                        <label><input type="radio" name="fusion_q3" value="D"> D. 注意力机制</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 早期融合和晚期融合有什么区别？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fusion_q4" value="A"> A. 早期融合在输入层</label>
                                        <label><input type="radio" name="fusion_q4" value="B"> B. 晚期融合在输出层</label>
                                        <label><input type="radio" name="fusion_q4" value="C"> C. 早期融合更简单</label>
                                        <label><input type="radio" name="fusion_q4" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 在多模态学习中，特征融合最常遇到的问题是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fusion_q5" value="A"> A. 模态异构性</label>
                                        <label><input type="radio" name="fusion_q5" value="B"> B. 计算复杂度</label>
                                        <label><input type="radio" name="fusion_q5" value="C"> C. 数据量不足</label>
                                        <label><input type="radio" name="fusion_q5" value="D"> D. 标签不一致</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="feature_fusion">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>
			

			<div id="educationDropout">
				<div class="educationTitle">丢弃层（Dropout）</div>
				<div class="educationAuthor">作者<i>Stefan Grosser</i> 和 <i>Jesse Michel</i></div>
			
				<div class="educationContent">
					<p>丢弃层在训练期间忽略一部分输入单元。例如，如果丢弃率为 0.1，则在每次前向传播中，丢弃层会随机选择 10% 的权重并将它们设为 0。添加一个丢弃率为 0 的丢弃层不会对网络产生任何影响，而丢弃率为 1 时，丢弃层将输出 0。</p>
			
					<p>丢弃通常用于防止<strong>过拟合</strong>（有关更多信息，请参阅我们的相关文章）。可以将丢弃视为让网络学习一组弱分类器，在测试时将它们结合起来形成一个更强的分类器。对于熟悉这个术语的人来说，这类似于使用集成模型的提升方法。丢弃层还有一个方便的特点，即加速训练，因为每次前向传播时所需的权重较少。</p>
				</div>
                    <!-- 新增的做题链接部分 -->
                <!-- Dropout练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">🎲 Dropout练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">学习Dropout正则化技术和防止过拟合的方法</p>

                    <div class="exercise-cards">
                        <!-- Dropout知识测试卡片 -->
                        <div class="exercise-card" data-exercise="dropout_quiz">
                            <div class="card-header">
                                <h4>🎯 Dropout知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对Dropout机制和原理的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> Dropout的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="drop_q1" value="A"> A. 加速训练</label>
                                        <label><input type="radio" name="drop_q1" value="B"> B. 防止过拟合</label>
                                        <label><input type="radio" name="drop_q1" value="C"> C. 增加准确率</label>
                                        <label><input type="radio" name="drop_q1" value="D"> D. 减少参数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> Dropout在训练和测试阶段的行为有什么不同？</p>
                                    <div class="options">
                                        <label><input type="radio" name="drop_q2" value="A"> A. 训练时随机丢弃，测试时使用全部</label>
                                        <label><input type="radio" name="drop_q2" value="B"> B. 测试时也随机丢弃</label>
                                        <label><input type="radio" name="drop_q2" value="C"> C. 训练时使用全部，测试时丢弃</label>
                                        <label><input type="radio" name="drop_q2" value="D"> D. 训练和测试行为相同</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> Dropout的默认丢弃概率是多少？</p>
                                    <div class="options">
                                        <label><input type="radio" name="drop_q3" value="A"> A. 0.1</label>
                                        <label><input type="radio" name="drop_q3" value="B"> B. 0.2</label>
                                        <label><input type="radio" name="drop_q3" value="C"> C. 0.5</label>
                                        <label><input type="radio" name="drop_q3" value="D"> D. 0.8</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> Dropout为什么能防止过拟合？</p>
                                    <div class="options">
                                        <label><input type="radio" name="drop_q4" value="A"> A. 减少模型复杂度</label>
                                        <label><input type="radio" name="drop_q4" value="B"> B. 创建多个子网络集成</label>
                                        <label><input type="radio" name="drop_q4" value="C"> C. 增加训练数据</label>
                                        <label><input type="radio" name="drop_q4" value="D"> D. 改变优化算法</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 在测试时，Dropout如何处理被丢弃的神经元？</p>
                                    <div class="options">
                                        <label><input type="radio" name="drop_q5" value="A"> A. 完全移除</label>
                                        <label><input type="radio" name="drop_q5" value="B"> B. 缩放输出权重</label>
                                        <label><input type="radio" name="drop_q5" value="C"> C. 设为零</label>
                                        <label><input type="radio" name="drop_q5" value="D"> D. 用平均值替代</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="dropout_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 过拟合防止练习卡片 -->
                        <div class="exercise-card" data-exercise="overfitting_prevention">
                            <div class="card-header">
                                <h4>🛡️ 过拟合防止练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>学习识别和防止过拟合的各种方法和技术。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 过拟合的典型表现是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="overfit_q1" value="A"> A. 训练准确率低</label>
                                        <label><input type="radio" name="overfit_q1" value="B"> B. 训练和测试准确率差距大</label>
                                        <label><input type="radio" name="overfit_q1" value="C"> C. 训练时间长</label>
                                        <label><input type="radio" name="overfit_q1" value="D"> D. 参数量少</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 数据增强的主要目的是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="overfit_q2" value="A"> A. 增加数据量</label>
                                        <label><input type="radio" name="overfit_q2" value="B"> B. 提高数据质量</label>
                                        <label><input type="radio" name="overfit_q2" value="C"> C. 减少噪声</label>
                                        <label><input type="radio" name="overfit_q2" value="D"> D. 标准化数据</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 早停（Early Stopping）是如何工作的？</p>
                                    <div class="options">
                                        <label><input type="radio" name="overfit_q3" value="A"> A. 在训练开始时停止</label>
                                        <label><input type="radio" name="overfit_q3" value="B"> B. 监控验证集性能</label>
                                        <label><input type="radio" name="overfit_q3" value="C"> C. 随机停止训练</label>
                                        <label><input type="radio" name="overfit_q3" value="D"> D. 根据训练时间停止</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> L2正则化的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="overfit_q4" value="A"> A. 增加权重值</label>
                                        <label><input type="radio" name="overfit_q4" value="B"> B. 惩罚大权重值</label>
                                        <label><input type="radio" name="overfit_q4" value="C"> C. 减少权重值</label>
                                        <label><input type="radio" name="overfit_q4" value="D"> D. 随机化权重</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 批量归一化（Batch Normalization）如何帮助防止过拟合？</p>
                                    <div class="options">
                                        <label><input type="radio" name="overfit_q5" value="A"> A. 减少内部协变量偏移</label>
                                        <label><input type="radio" name="overfit_q5" value="B"> B. 直接减少参数量</label>
                                        <label><input type="radio" name="overfit_q5" value="C"> C. 增加模型复杂度</label>
                                        <label><input type="radio" name="overfit_q5" value="D"> D. 改变损失函数</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="overfitting_prevention">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 正则化技术分析卡片 -->
                        <div class="exercise-card" data-exercise="regularization_techniques">
                            <div class="card-header">
                                <h4>📏 正则化技术分析</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>深入分析各种正则化技术的原理和应用。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> L1正则化和L2正则化的主要区别是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="reg_q1" value="A"> A. L1产生稀疏解</label>
                                        <label><input type="radio" name="reg_q1" value="B"> B. L2计算更快</label>
                                        <label><input type="radio" name="reg_q1" value="C"> A和B都是</label>
                                        <label><input type="radio" name="reg_q1" value="D"> D. 没有区别</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> Dropout可以被视为一种什么形式的正则化？</p>
                                    <div class="options">
                                        <label><input type="radio" name="reg_q2" value="A"> A. 显式正则化</label>
                                        <label><input type="radio" name="reg_q2" value="B"> B. 隐式正则化</label>
                                        <label><input type="radio" name="reg_q2" value="C"> C. 数据增强</label>
                                        <label><input type="radio" name="reg_q2" value="D"> D. 优化方法</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 标签平滑（Label Smoothing）的目的是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="reg_q3" value="A"> A. 减少过拟合</label>
                                        <label><input type="radio" name="reg_q3" value="B"> B. 提高收敛速度</label>
                                        <label><input type="radio" name="reg_q3" value="C"> C. 增加模型容量</label>
                                        <label><input type="radio" name="reg_q3" value="D"> D. 减少计算量</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 权重衰减（Weight Decay）的数学原理是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="reg_q4" value="A"> A. 在损失函数中添加权重惩罚项</label>
                                        <label><input type="radio" name="reg_q4" value="B"> B. 随机初始化权重</label>
                                        <label><input type="radio" name="reg_q4" value="C"> C. 改变学习率</label>
                                        <label><input type="radio" name="reg_q4" value="D"> D. 增加训练数据</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 集成学习为什么能提高泛化能力？</p>
                                    <div class="options">
                                        <label><input type="radio" name="reg_q5" value="A"> A. 减少方差</label>
                                        <label><input type="radio" name="reg_q5" value="B"> B. 减少偏差</label>
                                        <label><input type="radio" name="reg_q5" value="C"> C. 增加模型复杂度</label>
                                        <label><input type="radio" name="reg_q5" value="D"> D. 加速训练</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="regularization_techniques">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>
			
			<div id="educationOverfitting">
				<div class="educationTitle">过拟合（Overfitting）</div>
				<div class="educationAuthor">作者 <i>Stefan Grosser</i> 和 <i>Jesse Michel</i></div>
				<div class="educationContent">
			
					<p>神经网络有时会学习得过于精确。它识别出仅仅是训练数据中特定的趋势，因此无法<strong>泛化</strong>。这种过度拟合训练数据的问题称为<strong>过拟合</strong>。下图展示了决策边界——决定分类器预测的曲线——在欠拟合、拟合良好（正常）和过拟合的情况下的变化。</p>
			
					<img class="educationImage" src="dist/overfitti_ng.png" alt="可能的决策边界" />
					<div class="modelLink">
						<a class="modelLink" target="_newtab" href="http://mlwiki.org/index.php/Overfitting">
							来源: ML Wiki
						</a>
					</div>
					<p>当分类器发生过拟合时，它在训练数据上的表现远远优于测试数据。因此，训练准确度会远高于验证准确度，训练损失会远低于验证损失。我们在下方提供了这个例子的可视化。</p>
			
					<img class="educationImage" style="float: left; max-width: 50%;" src="dist/loss_overfit.png" title="图：训练过程中的过拟合可视化" alt="训练过程中过拟合的可视化" />
			
					<img class="educationImage" style="float: right; max-width: 50%;" src="dist/accuracy_overfit.png" title="图：训练过程中的过拟合可视化" alt="训练过程中过拟合的可视化" />
			
					<div style="margin-top:10px;">
						该示例所用的架构如下所示：
					</div>
			
					<div class="figure">
						<img class="educationImage" style="max-width: 50%;" src="dist/overfitting_network.png" alt="网络架构" >
			
						<div class="modelLink">
							<a class="modelLink" target="_newtab" href="https://math.mit.edu/ennui/#%7B%22graph%22:%5B%7B%22layer_name%22:%22Input%22,%22children_ids%22:%5B2%5D,%22parent_ids%22:%5B%5D,%22params%22:%7B%22dataset%22:%22cifar%22%7D,%22id%22:0,%22xPosition%22:100,%22yPosition%22:399%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B3%5D,%22parent_ids%22:%5B0%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D,%22kernelRegularizer%22:%22none%22,%22regScale%22:0.1,%22activation%22:%22relu%22%7D,%22id%22:2,%22xPosition%22:261,%22yPosition%22:453%7D,%7B%22layer_name%22:%22Flatten%22,%22children_ids%22:%5B1%5D,%22parent_ids%22:%5B2%5D,%22params%22:%7B%7D,%22id%22:3,%22xPosition%22:585,%22yPosition%22:484%7D,%7B%22layer_name%22:%22Output%22,%22children_ids%22:%5B%5D,%22parent_ids%22:%5B3%5D,%22params%22:%7B%7D,%22id%22:1,%22xPosition%22:900,%22yPosition%22:399%7D%5D,%22hyperparameters%22:%7B%22learningRate%22:0.1,%22batchSize%22:64,%22optimizer_id%22:%22defaultOptimizer%22,%22epochs%22:15,%22loss_id%22:%22defaultLoss%22%7D%7D">
								模型链接
							</a>
						</div>
					</div>
					<br/><br/>
					<p>过拟合展示了交叉验证为何如此重要；如果没有验证集，我们将无法识别模型无法泛化的问题。</p>
					<p>那么，如何应对过拟合，确保模型找到可以泛化的特征呢？</p>
					<div class="educationSection">正则化</div>
					<p>防止过拟合的一种方法是正则化，它通过加入一个新的项来引导模型走向更简单的解决方案。回想一下，在分类问题中，我们从一对对输入和它们的分类 <span class="math display">\[(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n).\]</span> 开始。我们希望找到一个函数 <span class="math inline">\(f\)</span>，它能准确预测新数据样本的类别。因此，如果我们的原始问题是 <span class="math display">\[\min_f \sum_{i=1}^{n} C(f(x_i), y_i),\]</span> 其中 <span class="math inline">\(C\)</span> 计算当预测 <span class="math inline">\(f(x_i)\)</span> 时的代价，当真实值是 <span class="math inline">\(y_i\)</span>，那么正则化损失将是 <span class="math display">\[\min_f \sum_{i=1}^{n} C(f(x_i), y_i) + \lambda R(f),\]</span> 其中 <span class="math inline">\(R(f)\)</span> 是正则化项，定义为当 <span class="math inline">\(f\)</span> 更复杂时它会变大，而 <span class="math inline"> \(\lambda>0\) </span> 是一个可调节的参数，控制正则化的程度。层的复杂性有多种定义，但在我们的案例中，我们会说，具有较低 <span class="math inline">\(L2\)</span>-范数的层较为简单。正式地，我们将 <span class="math inline">\(L2\)</span>-范数定义为 <span class="math display">\[\text{norm}(A) = \sqrt{\sum_i \sum_j a_{ij}^2}.\]</span> 例如，给定矩阵 <span class="math display">\[A =
					\begin{bmatrix}
					1 & 2 \\
					0 & -2
					\end{bmatrix},\]</span> 其 L2-范数为 <span class="math display">\[||A||_2 = \sqrt{1^2 + 2^2 + 0^2 + (-2)^2} = 3.\]</span></p>
					<p>有几个原因解释了为何惩罚增大的 <span class="math inline">\(L2\)</span>-范数是一个合理的做法。如果我们假设分类器会发生过拟合，那么加入惩罚项 <span class="math inline">\(\lambda R(f)\)</span> 将会引导决策边界远离这一状态。这可以看作是给分类器增加“摆动空间”。此外，这种高 <span class="math inline">\(L2\)</span>-范数的惩罚是鼓励丢弃无用信息的一种方式。惩罚项促使层的权重变小，而层的权重越接近零，其作为特征的影响就越小。</p>
					<p>这种复杂性的概念导致了 <span class="math inline">\(L1\)</span>-和 <span class="math inline">\(L2\)</span>-范数成为正则化的一种形式。在 <span class="math inline">\(L2\)</span>-正则化的情况下，我们可以将 <span class="math inline">\(\lambda ||W||_2\)</span> 加入到损失函数中，针对给定层 <span class="math inline">\(W.\)</span> 当然，还有其他的正则化方式，但现在我们来看看另一种方法。</p>
					<!-- TODO: 以后可能解释 L1-正则化 -->
					<div class="educationSection">Dropout</div>
					<p>防止过拟合的另一种方法是名为 dropout 的技术。Dropout 层在训练期间忽略一部分输入单元（有关更多信息，请参阅我们的 dropout 层解释）。有两种直觉可以解释为什么 dropout 有助于防止过拟合。Dropout 可以看作是一种集成学习——将一组弱（欠拟合）分类器的结果进行某种方式的组合，例如采用多数类别。在每个批次中，网络的一个新部分作为弱分类器进行训练。在验证阶段，整个网络都会被使用，从而有效地将所有分类器结合起来提供一个单一的结果。另一种看法是，经过多次运行后，dropout 强制网络架构的所有部分都被使用。因此，训练集的任何一个特征都不会过于影响网络，避免网络集中在仅对训练集特有的伪影上。</p>
					<div class="educationSection">结论</div>
					<p>过拟合会妨碍分类器在未见数据上的表现。正则化和 dropout 是两种广泛使用且容易实现的防止过拟合的方法。结合这些方法与交叉验证，使得构建更具泛化能力的模型变得更加容易。</p>
				</div>
                <!-- 新增的做题链接部分 -->
                <!-- 过拟合练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">⚖️ 过拟合练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">深入理解偏差-方差权衡和过拟合问题</p>

                    <div class="exercise-cards">
                        <!-- 过拟合知识测试卡片 -->
                        <div class="exercise-card" data-exercise="overfitting_quiz">
                            <div class="card-header">
                                <h4>📈 过拟合知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对过拟合概念和表现形式的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 过拟合是指模型在什么数据上的表现很好？</p>
                                    <div class="options">
                                        <label><input type="radio" name="over_q1" value="A"> A. 训练数据</label>
                                        <label><input type="radio" name="over_q1" value="B"> B. 测试数据</label>
                                        <label><input type="radio" name="over_q1" value="C"> C. 新数据</label>
                                        <label><input type="radio" name="over_q1" value="D"> D. 验证数据</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 欠拟合通常表现为？</p>
                                    <div class="options">
                                        <label><input type="radio" name="over_q2" value="A"> A. 训练准确率高，测试准确率低</label>
                                        <label><input type="radio" name="over_q2" value="B"> B. 训练和测试准确率都很高</label>
                                        <label><input type="radio" name="over_q2" value="C"> C. 训练和测试准确率都很低</label>
                                        <label><input type="radio" name="over_q2" value="D"> D. 训练准确率低，测试准确率高</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 模型复杂度过高会导致什么问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="over_q3" value="A"> A. 欠拟合</label>
                                        <label><input type="radio" name="over_q3" value="B"> B. 过拟合</label>
                                        <label><input type="radio" name="over_q3" value="C"> C. 梯度消失</label>
                                        <label><input type="radio" name="over_q3" value="D"> D. 梯度爆炸</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 什么是泛化能力？</p>
                                    <div class="options">
                                        <label><input type="radio" name="over_q4" value="A"> A. 在训练数据上的表现</label>
                                        <label><input type="radio" name="over_q4" value="B"> B. 在未知数据上的表现</label>
                                        <label><input type="radio" name="over_q4" value="C"> C. 模型的训练速度</label>
                                        <label><input type="radio" name="over_q4" value="D"> D. 模型的参数量</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 交叉验证的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="over_q5" value="A"> A. 加速训练</label>
                                        <label><input type="radio" name="over_q5" value="B"> B. 评估模型泛化能力</label>
                                        <label><input type="radio" name="over_q5" value="C"> C. 增加数据量</label>
                                        <label><input type="radio" name="over_q5" value="D"> D. 减少参数量</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="overfitting_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 偏差-方差分析卡片 -->
                        <div class="exercise-card" data-exercise="bias_variance">
                            <div class="card-header">
                                <h4>⚖️ 偏差-方差分析</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>理解偏差和方差的概念及其在模型选择中的作用。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 高偏差模型通常表现为？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bias_q1" value="A"> A. 过拟合</label>
                                        <label><input type="radio" name="bias_q1" value="B"> B. 欠拟合</label>
                                        <label><input type="radio" name="bias_q1" value="C"> C. 训练不稳定</label>
                                        <label><input type="radio" name="bias_q1" value="D"> D. 收敛慢</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 高方差模型的特点是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bias_q2" value="A"> A. 对训练数据不敏感</label>
                                        <label><input type="radio" name="bias_q2" value="B"> B. 对训练数据变化敏感</label>
                                        <label><input type="radio" name="bias_q2" value="C"> C. 总是欠拟合</label>
                                        <label><input type="radio" name="bias_q2" value="D"> D. 总是过拟合</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 偏差-方差权衡的核心思想是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bias_q3" value="A"> A. 最小化其中之一</label>
                                        <label><input type="radio" name="bias_q3" value="B"> B. 平衡两者</label>
                                        <label><input type="radio" name="bias_q3" value="C"> C. 最大化两者</label>
                                        <label><input type="radio" name="bias_q3" value="D"> D. 忽略其中之一</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 增加模型复杂度会如何影响偏差和方差？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bias_q4" value="A"> A. 偏差增加，方差减少</label>
                                        <label><input type="radio" name="bias_q4" value="B"> B. 偏差减少，方差增加</label>
                                        <label><input type="radio" name="bias_q4" value="C"> C. 两者都增加</label>
                                        <label><input type="radio" name="bias_q4" value="D"> D. 两者都减少</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 集成学习如何改善偏差-方差权衡？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bias_q5" value="A"> A. 主要减少偏差</label>
                                        <label><input type="radio" name="bias_q5" value="B"> B. 主要减少方差</label>
                                        <label><input type="radio" name="bias_q5" value="C"> C. 同时减少两者</label>
                                        <label><input type="radio" name="bias_q5" value="D"> D. 增加两者</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="bias_variance">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 正则化方法练习卡片 -->
                        <div class="exercise-card" data-exercise="regularization_methods">
                            <div class="card-header">
                                <h4>🔧 正则化方法练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>练习各种正则化方法的应用和参数调优。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> L1正则化倾向于产生什么类型的解？</p>
                                    <div class="options">
                                        <label><input type="radio" name="regm_q1" value="A"> A. 稠密解</label>
                                        <label><input type="radio" name="regm_q1" value="B"> B. 稀疏解</label>
                                        <label><input type="radio" name="regm_q1" value="C"> C. 随机解</label>
                                        <label><input type="radio" name="regm_q1" value="D"> D. 均匀解</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 在神经网络中，Dropout通常应用在哪些层？</p>
                                    <div class="options">
                                        <label><input type="radio" name="regm_q2" value="A"> A. 仅输入层</label>
                                        <label><input type="radio" name="regm_q2" value="B"> B. 仅输出层</label>
                                        <label><input type="radio" name="regm_q2" value="C"> C. 隐藏层</label>
                                        <label><input type="radio" name="regm_q2" value="D"> D. 所有层</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> Batch Normalization主要解决什么问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="regm_q3" value="A"> A. 梯度消失</label>
                                        <label><input type="radio" name="regm_q3" value="B"> B. 内部协变量偏移</label>
                                        <label><input type="radio" name="regm_q3" value="C"> C. 过拟合</label>
                                        <label><input type="radio" name="regm_q3" value="D"> D. 梯度爆炸</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 数据增强最常用于哪种类型的任务？</p>
                                    <div class="options">
                                        <label><input type="radio" name="regm_q4" value="A"> A. 自然语言处理</label>
                                        <label><input type="radio" name="regm_q4" value="B"> B. 计算机视觉</label>
                                        <label><input type="radio" name="regm_q4" value="C"> C. 语音识别</label>
                                        <label><input type="radio" name="regm_q4" value="D"> D. 时间序列预测</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 模型选择时，应该如何平衡训练误差和泛化误差？</p>
                                    <div class="options">
                                        <label><input type="radio" name="regm_q5" value="A"> A. 只关注训练误差</label>
                                        <label><input type="radio" name="regm_q5" value="B"> B. 使用验证集</label>
                                        <label><input type="radio" name="regm_q5" value="C"> C. 增加模型复杂度</label>
                                        <label><input type="radio" name="regm_q5" value="D"> D. 减少训练时间</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="regularization_methods">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 模型选择策略卡片 -->
                        <div class="exercise-card" data-exercise="model_selection">
                            <div class="card-header">
                                <h4>🎯 模型选择策略</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>学习如何选择合适的模型和超参数。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 网格搜索（Grid Search）适用于什么情况？</p>
                                    <div class="options">
                                        <label><input type="radio" name="model_q1" value="A"> A. 参数空间很大</label>
                                        <label><input type="radio" name="model_q1" value="B"> B. 参数空间小</label>
                                        <label><input type="radio" name="model_q1" value="C"> C. 参数连续</label>
                                        <label><input type="radio" name="model_q1" value="D"> D. 参数离散</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 随机搜索（Random Search）相比网格搜索的优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="model_q2" value="A"> A. 更精确</label>
                                        <label><input type="radio" name="model_q2" value="B"> B. 更高效</label>
                                        <label><input type="radio" name="model_q2" value="C"> C. 更容易实现</label>
                                        <label><input type="radio" name="model_q2" value="D"> D. 结果更稳定</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 什么是超参数？</p>
                                    <div class="options">
                                        <label><input type="radio" name="model_q3" value="A"> A. 模型学习的参数</label>
                                        <label><input type="radio" name="model_q3" value="B"> B. 训练前设置的参数</label>
                                        <label><input type="radio" name="model_q3" value="C"> C. 损失函数的参数</label>
                                        <label><input type="radio" name="model_q3" value="D"> D. 优化算法的参数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> K折交叉验证中，K通常取什么值？</p>
                                    <div class="options">
                                        <label><input type="radio" name="model_q4" value="A"> A. 2</label>
                                        <label><input type="radio" name="model_q4" value="B"> B. 5或10</label>
                                        <label><input type="radio" name="model_q4" value="C"> C. 100</label>
                                        <label><input type="radio" name="model_q4" value="D"> D. 数据集大小</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 验证集的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="model_q5" value="A"> A. 训练模型</label>
                                        <label><input type="radio" name="model_q5" value="B"> B. 调参和模型选择</label>
                                        <label><input type="radio" name="model_q5" value="C"> C. 最终评估</label>
                                        <label><input type="radio" name="model_q5" value="D"> D. 数据预处理</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="model_selection">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>

			<div id="educationResNets">
				<div class="educationTitle"> 残差网络 (ResNets) </div>
				<div class="educationAuthor">作者 <i>Zack Holbrook</i> and <i>Jesse Michel</i></div>

				<div class="educationContent">
					<p>2015 年，微软的一个研究团队凭借 ResNet 在 <a href="http://www.image-net.org/challenges/LSVRC/">ImageNet 大规模视觉识别挑战赛</a> 中获得了创纪录的表现。自 2015 年以来，ResNet 的变种一直主导着这一竞赛，超过了人类在该任务中的表现。它们已成为图像识别任务中广泛采用的架构，并且相对容易实现和训练。</p>
					<div class="educationSection">ResNet 架构</div>
					<p>ResNet 是一种卷积神经网络（CNN），具有 <strong>恒等捷径（identity shortcuts）</strong>，这是通过跳过某些层创建的网络路径，从而在网络中创建捷径。下面我们提供一个典型的 ResNet 示例：
				
						<img class="educationImage" src="dist/resnet.png" alt="Resnet image" width="50%">
				
						<div class="modelLink">
							<a class="modelLink" target="_newtab" href="http://math.mit.edu/ennui/#%7B%22graph%22:%5B%7B%22layer_name%22:%22Input%22,%22children_ids%22:%5B5,9%5D,%22parent_ids%22:%5B%5D,%22params%22:%7B%22dataset%22:%22mnist%22%7D,%22id%22:0,%22xPosition%22:100,%22yPosition%22:377%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B6%5D,%22parent_ids%22:%5B0%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D,%22activation%22:%22relu%22%7D,%22id%22:5,%22xPosition%22:169,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Add%22,%22children_ids%22:%5B7,10%5D,%22parent_ids%22:%5B0,6%5D,%22params%22:%7B%22activation%22:%22relu%22%7D,%22id%22:9,%22xPosition%22:276,%22yPosition%22:411%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B9%5D,%22parent_ids%22:%5B5%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D%7D,%22id%22:6,%22xPosition%22:294,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B8%5D,%22parent_ids%22:%5B9%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D,%22activation%22:%22relu%22%7D,%22id%22:7,%22xPosition%22:414,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Add%22,%22children_ids%22:%5B11%5D,%22parent_ids%22:%5B9,8%5D,%22params%22:%7B%22activation%22:%22relu%22%7D,%22id%22:10,%22xPosition%22:521,%22yPosition%22:412%7D,%7B%22layer_name%22:%22Conv2D%22,%22children_ids%22:%5B10%5D,%22parent_ids%22:%5B7%5D,%22params%22:%7B%22filters%22:16,%22kernelSize%22:%5B3,3%5D,%22strides%22:%5B1,1%5D%7D,%22id%22:8,%22xPosition%22:541,%22yPosition%22:280%7D,%7B%22layer_name%22:%22Flatten%22,%22children_ids%22:%5B12%5D,%22parent_ids%22:%5B10%5D,%22params%22:%7B%7D,%22id%22:11,%22xPosition%22:708,%22yPosition%22:463%7D,%7B%22layer_name%22:%22Dense%22,%22children_ids%22:%5B13%5D,%22parent_ids%22:%5B11%5D,%22params%22:%7B%22units%22:32,%22activation%22:%22relu%22%7D,%22id%22:12,%22xPosition%22:702,%22yPosition%22:434%7D,%7B%22layer_name%22:%22Dropout%22,%22children_ids%22:%5B1%5D,%22parent_ids%22:%5B12%5D,%22params%22:%7B%22rate%22:0.5%7D,%22id%22:13,%22xPosition%22:778,%22yPosition%22:365%7D,%7B%22layer_name%22:%22Output%22,%22children_ids%22:%5B%5D,%22parent_ids%22:%5B13%5D,%22params%22:%7B%7D,%22id%22:1,%22xPosition%22:900,%22yPosition%22:377%7D%5D,%22hyperparameters%22:%7B%22learningRate%22:0.01,%22batchSize%22:64,%22optimizer_id%22:%22defaultOptimizer%22,%22epochs%22:6,%22loss_id%22:%22defaultLoss%22%7D%7D">
								模型链接
							</a>
						</div>
				
						恒等捷径意味着学习到的参数是残差。数学上，如果 <span class="math inline">\(R(x)\)</span> 是一系列卷积层与 ReLU 组合，称为 <strong>残差块</strong>，例如，假设 <span class="math display">\[R(x) = \textrm{Conv}(\textrm{ReLU}(\textrm{Conv}(x))).\]</span> 那么，残差块的输出将是 <span class="math inline">\(R(x) + x\)</span>，其中 <span class="math inline">\(x\)</span> 是恒等传递。如果神经网络试图逼近某个函数 <span class="math inline">\(F(x)\)</span>，那么一个完美的残差块 <span class="math inline">\(R^*(x)\)</span> 会使得 <span class="math inline">\(R^*(x) = F(x) - x\)</span>，这正是通过减去输入图像得到的残差。</p>
					<div class="educationSection">ResNet 的优势</div>
					<p>ResNet 的一个惊人特性是它的良好扩展性，使得深层神经网络仍然能够良好地训练。当网络变得更大时，许多问题会出现。</p>
					<p>大规模网络往往训练速度较慢，但 CNN 的 <strong>权重共享</strong> 意味着每个残差块需要训练的参数相对较少。大规模网络还往往面临 <strong>梯度消失</strong> 问题——在梯度下降中，权重更新会逐渐变得微不足道，导致即使有更多的训练时间，网络也无法改进。ResNet 中的恒等捷径为梯度提供了流动路径，从而避免了梯度消失的问题。</p>
				</div>
			</div>

            <div id="educationAdd">
				<div class="educationTitle"> 相加层（Add） </div>

				<div class="educationContent">
					<p><strong>功能：</strong>将多个相同维度的输入张量进行逐元素相加。</p>
				
					<p><strong>作用：</strong>是构建残差网络（ResNets） 的关键。通过“快捷连接”将前一层的输出直接跳过多层加到后面层的输出上，有效解决了深层网络中的梯度消失和退化问题，使得训练非常深的网络成为可能。</p>
				</div>
			</div>
			
			<div id="educationBatchNorm">
				<div class="educationTitle"> 批量归一化层（Batch Normalization） </div>

				<div class="educationContent">
					<p><strong>功能：</strong>对每一批（Batch）输入数据进行标准化处理，使其均值为0，方差为1</p>
					<p><strong>作用：</strong>加速训练过程，允许使用更大的学习率。减少对参数初始化的依赖。有一定正则化效果，可以轻微减少过拟合。</p>
					<p>通常放在卷积层或全连接层之后，激活函数之前。</p>
				</div>
			</div>

			<div id="educationConcatenate">
				<div class="educationTitle">连接层（Concatenate）</div>
			
				<div class="educationContent">
					<p><strong>功能：</strong>将多个输入张量沿着指定的轴（通常是通道轴）连接在一起。</p>
					<p><strong>作用：</strong>用于构建具有多分支结构的复杂网络（如Inception模块、U-Net等），将不同分支提取的特征融合在一起。</p>
				</div>
			</div>

			<div id="educationConvolution">
				<div class="educationTitle"> 卷积层（Convolution） </div>
				
				<div class="educationContent">
					<p><strong>功能：</strong> 使用一个小的“滤波器”在输入数据（通常是图像）上滑动，计算局部区域的点积。</p>
					<p><strong>作用：</strong>卓越地提取局部特征，如边缘、角点、纹理等。通过参数共享，大大减少了模型的参数量。是卷积神经网络（CNN） 的核心。</p>
					<p><strong>主要应用：</strong>图像处理、视频分析、自然语言处理。</p>
				</div>
			</div>

			<div id="educationMaxPooling">
				<div class="educationTitle"> 最大池化层（Max Pooling） </div>
				
				<div class="educationContent">
					<p><strong>功能：</strong> 对输入数据的一个小区域（如2x2窗口）进行下采样，只输出该区域内的最大值。</p>
					<p><strong>作用：</strong>神降低数据维度，减少计算量和参数，防止过拟合。保持特征的平移不变性（即无论特征在输入中的哪个位置，都能被检测到）。</p>
					<p>通常紧随卷积层之后使用。</p>
				</div>
			</div>

			<div id="educationDropout">
				<div class="educationTitle">丢弃层（Dropout）</div>
			
				<div class="educationContent">
					<p><strong>功能：</strong>在训练过程中，随机“关闭”（将其输出置为零）网络中一部分神经元。</p>
					<p><strong>作用：</strong>一种非常有效的正则化技术，用于防止过拟合。通过随机丢弃，可以强制网络不依赖于任何单个神经元，从而学习到更鲁棒、更泛化的特征。</p>
				</div>
			</div>

			<div id="educationFlatten">
				<div class="educationTitle"> 展平层（Flatten） </div>

				<div class="educationContent">
					<p><strong>功能：</strong>将多维的输入数据“压平”成一维数据。</p>
					<p><strong>作用：</strong>作为卷积层到全连接层之间的过渡。因为全连接层需要一维输入，而卷积层的输出是二维或三维的特征图。</p>
				</div>
				
			</div>

			<div id="educationDense">
				<div class="educationTitle"> 全连接层（Dense） </div>
				
				<div class="educationContent">
					<p><strong>功能：</strong> 最基础、最常见的层。层中的每个神经元都与上一层的所有神经元相连。</p>
					<p><strong>作用：</strong>用于学习输入特征之间的全局模式。通常用在网络的最后几层进行分类或回归。</p>
					<p><strong>类比：</strong>像一个传统的“多层感知机”。</p>
				</div>
			</div>
	
			
			<div id="educationMLP">
				<div class="educationTitle">感知机</div>
				<div class="educationContent">
					<div class="educationSection">（一）概述</div>
					<p>
						多层感知机（MLP：Multi-Layer Perceptron）由感知机(PLA: Perceptron Learning Algorithm)推广而来。它最主要的特点是有多个神经元层，因此也叫深度神经网络(DNN: Deep Neural Networks)。
					</p>
					<p>
						感知机是单个神经元模型，是较大神经网络的前身。神经网络的强大之处在于它们能够学习训练数据中的表示，以及如何将其与想要预测的输出变量联系起来。从数学上讲，它们能够学习任何映射函数，并且已经被证明是一种通用的近似算法。
					</p>
					<p>
						神经网络的预测能力来自网络的分层或多层结构。而多层感知机是指具有至少三层节点（输入层，一些中间层和输出层）的神经网络。每一层中的节点与相邻层的节点完全连接。
					</p>
					<div class="educationSection">（二）各层说明</div>
					<p><strong>1．输入层：</strong> 每个输入特征对应一个神经元，输入层不涉及计算。</p>
					<p><strong>2．单个或多个隐藏层：</strong></p>
					<ul>
						<li>介绍</li>
						<p>至少有一个隐藏层，通常包含多个神经元。每一层的神经元与前一层的神经元连接。</p>
						<p>隐藏层负责对输入数据进行非线性转换。在每个神经元中，输入值会与相应的权重相乘，再加上偏置，最后通过激活函数进行变换。这样每一层都能够提取特征。</p>
						<li>神经元的计算</li>
						<ul>
							<li>对于第L层的第j个神经元，其输出为：
								<span class="math inline">\[z_j=W_j\cdot a^{(1-1)}+b_j\]</span>
								<span class="math inline">\[a_j{=}f(z_j)\]</span>
								<p>其中,<span class="math inline">\(W_j\)</span>是权重，<span class=",math inline">\(b_j\)</span>是偏置，<span class=",math inline">\(a^{(l-1)}\)</span>是前一层的输出，<span class="math inline">\(f(z_j)\)</span>是激活函数 (如ReLU) 。 假设隐藏层有3个神经元，并且我们使用 ReLU 激活函数。每个神经元的输入是输入层的输出(x1, x2),它们会被分别与权重和偏置进行加权和偏置计算。</p>
							</li>
							<li>隐藏层神经元的计算过程：
								<p>对于第一个神经元：<span class="math inline">\[z_1=W_1\cdot x+b_1=w_1\cdot x_1+w_{12}\cdot x_2+b_1\]</span></p>
								<p>激活函数(ReLU)会将计算结果输出：<span class="math inline">\[a_1{=}\mathrm{ReLU}(z_1)\]</span></p>
								<p>对于第二个和第三个神经元，同样的计算方式。</p>
							</li>
						</ul>
						<li>激活函数的选择：</li>
						<ul>
							<li>ReLU：适用于隐藏层，能够加速训练，避免梯度消失问题。</li>
							<li>Sigmoid：可以用于隐藏层，但在深层网络中容易导致梯度消失。</li>
							<li>Tanh：适用于隐藏层，能够解决一些 Sigmoid 的问题，具有对称性。</li>
						</ul>
					</ul>
					<p><strong>3．输出层：</strong> </p>

					<ul>
						<li>介绍</li>
						<p>输出层负责将隐藏层的结果转化为最终预测值。</p>
						<li>神经元计算（以 Sigmoid 为例）
							<p>输出层的计算可以表示为：</p>
							<span class="math inline">\[a^{(\mathrm{hidden})}+b_{\mathrm{out}}\]</span>
							<p>其中，<span class="math inline">\(\mathbf{a^{(hiddcn)}}\)</span>是隐藏层的输出,<span class="math inline">\(W_{\mathrm{out}}\)</span>是输出层的权重，<span class="math inline">\(\widehat{y}=\sigma(z_{\mathrm{out}})=\frac1{1+e^{-z_{\mathrm{out}}}}\)</span>
								,其中<span class="math inline">\(\widehat{y}\)</span>是模型的预测输出，代表样本属于某一类的概率。
								</p>
						</li>
					</ul>
					<div class="educationSection">（三）思考题</div>
					<ol>
						<li>
							<strong>过拟合问题：</strong> 为什么 Dropout 可以防止过拟合？除此之外还有哪些方法？
						</li>
						<li>
							<strong>可解释性问题：</strong> 为什么深度学习被称为“黑箱”模型？如何提高其可解释性？
						</li>
						<li>
							<strong>激活函数问题：</strong> 为什么需要使用非线性激活函数？
						</li>
					</ol>
				</div>
                <!-- 多层感知机练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">🧠 多层感知机练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">学习多层感知机的基本原理和前向传播机制</p>

                    <div class="exercise-cards">
                        <!-- 多层感知机测试卡片 -->
                        <div class="exercise-card" data-exercise="mlp_quiz">
                            <div class="card-header">
                                <h4>🔬 多层感知机测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对多层感知机基本结构和原理的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 多层感知机（MLP）与单层感知机的主要区别是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="mlp_q1" value="A"> A. 没有隐藏层</label>
                                        <label><input type="radio" name="mlp_q1" value="B"> B. 有多个隐藏层</label>
                                        <label><input type="radio" name="mlp_q1" value="C"> C. 只能处理线性问题</label>
                                        <label><input type="radio" name="mlp_q1" value="D"> D. 没有激活函数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 隐藏层的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="mlp_q2" value="A"> A. 接收输入数据</label>
                                        <label><input type="radio" name="mlp_q2" value="B"> B. 学习特征表示</label>
                                        <label><input type="radio" name="mlp_q2" value="C"> C. 输出最终结果</label>
                                        <label><input type="radio" name="mlp_q2" value="D"> D. 存储数据</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 全连接层意味着什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="mlp_q3" value="A"> A. 所有神经元相互连接</label>
                                        <label><input type="radio" name="mlp_q3" value="B"> B. 只有相邻层连接</label>
                                        <label><input type="radio" name="mlp_q3" value="C"> C. 随机连接</label>
                                        <label><input type="radio" name="mlp_q3" value="D"> D. 没有连接</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 多层感知机可以解决哪类问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="mlp_q4" value="A"> A. 只有线性可分问题</label>
                                        <label><input type="radio" name="mlp_q4" value="B"> B. 非线性问题</label>
                                        <label><input type="radio" name="mlp_q4" value="C"> C. 只有分类问题</label>
                                        <label><input type="radio" name="mlp_q4" value="D"> D. 只有回归问题</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 梯度消失问题通常出现在哪种网络中？</p>
                                    <div class="options">
                                        <label><input type="radio" name="mlp_q5" value="A"> A. 浅层网络</label>
                                        <label><input type="radio" name="mlp_q5" value="B"> B. 深层网络</label>
                                        <label><input type="radio" name="mlp_q5" value="C"> C. 单层网络</label>
                                        <label><input type="radio" name="mlp_q5" value="D"> D. 没有激活函数的网络</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="mlp_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 激活函数练习卡片 -->
                        <div class="exercise-card" data-exercise="activation_functions">
                            <div class="card-header">
                                <h4>⚡ 激活函数练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>学习不同激活函数的特点和应用场景。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> ReLU激活函数的公式是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="act_q1" value="A"> A. f(x) = max(0, x)</label>
                                        <label><input type="radio" name="act_q1" value="B"> B. f(x) = 1/(1+e^(-x))</label>
                                        <label><input type="radio" name="act_q1" value="C"> C. f(x) = tanh(x)</label>
                                        <label><input type="radio" name="act_q1" value="D"> D. f(x) = e^x</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> Sigmoid函数的输出范围是？</p>
                                    <div class="options">
                                        <label><input type="radio" name="act_q2" value="A"> A. (-∞, ∞)</label>
                                        <label><input type="radio" name="act_q2" value="B"> B. (-1, 1)</label>
                                        <label><input type="radio" name="act_q2" value="C"> C. (0, 1)</label>
                                        <label><input type="radio" name="act_q2" value="D"> D. (0, ∞)</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 哪种激活函数容易出现梯度消失问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="act_q3" value="A"> A. ReLU</label>
                                        <label><input type="radio" name="act_q3" value="B"> B. Sigmoid</label>
                                        <label><input type="radio" name="act_q3" value="C"> C. Tanh</label>
                                        <label><input type="radio" name="act_q3" value="D"> D. Leaky ReLU</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> Softmax函数通常用于哪一层？</p>
                                    <div class="options">
                                        <label><input type="radio" name="act_q4" value="A"> A. 隐藏层</label>
                                        <label><input type="radio" name="act_q4" value="B"> B. 输出层（多分类）</label>
                                        <label><input type="radio" name="act_q4" value="C"> C. 输入层</label>
                                        <label><input type="radio" name="act_q4" value="D"> D. 所有层</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> Leaky ReLU相比ReLU的优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="act_q5" value="A"> A. 计算更快</label>
                                        <label><input type="radio" name="act_q5" value="B"> B. 解决死亡ReLU问题</label>
                                        <label><input type="radio" name="act_q5" value="C"> C. 输出范围更大</label>
                                        <label><input type="radio" name="act_q5" value="D"> D. 参数更少</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="activation_functions">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 前向传播计算卡片 -->
                        <div class="exercise-card" data-exercise="forward_propagation">
                            <div class="card-header">
                                <h4>🔄 前向传播计算</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>练习前向传播的数学计算过程。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 前向传播是从哪一层开始计算？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fwd_q1" value="A"> A. 输出层</label>
                                        <label><input type="radio" name="fwd_q1" value="B"> B. 隐藏层</label>
                                        <label><input type="radio" name="fwd_q1" value="C"> C. 输入层</label>
                                        <label><input type="radio" name="fwd_q1" value="D"> D. 任意层</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 神经元的输出计算公式是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fwd_q2" value="A"> A. y = W·x + b</label>
                                        <label><input type="radio" name="fwd_q2" value="B"> B. y = f(W·x + b)</label>
                                        <label><input type="radio" name="fwd_q2" value="C"> C. y = W·x · b</label>
                                        <label><input type="radio" name="fwd_q2" value="D"> D. y = f(W + x + b)</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 矩阵乘法在神经网络中的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fwd_q3" value="A"> A. 增加维度</label>
                                        <label><input type="radio" name="fwd_q3" value="B"> B. 并行计算多个神经元</label>
                                        <label><input type="radio" name="fwd_q3" value="C"> C. 减少计算量</label>
                                        <label><input type="radio" name="fwd_q3" value="D"> D. 改变数据类型</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 偏置项（bias）的几何意义是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fwd_q4" value="A"> A. 移动决策边界</label>
                                        <label><input type="radio" name="fwd_q4" value="B"> B. 旋转决策边界</label>
                                        <label><input type="radio" name="fwd_q4" value="C"> C. 缩放决策边界</label>
                                        <label><input type="radio" name="fwd_q4" value="D"> D. 翻转决策边界</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 前向传播的结果是？</p>
                                    <div class="options">
                                        <label><input type="radio" name="fwd_q5" value="A"> A. 损失值</label>
                                        <label><input type="radio" name="fwd_q5" value="B"> B. 预测输出</label>
                                        <label><input type="radio" name="fwd_q5" value="C"> C. 梯度值</label>
                                        <label><input type="radio" name="fwd_q5" value="D"> D. 更新参数</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="forward_propagation">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>


			<div id="educationCNN">
				<div class="educationTitle">卷积神经网络</div>
				<div class="educationContent">
					<div class="educationSection">（一）概述</div>
					<p>卷积神经网络（Convolutional Neural Network，简称 CNN）是一种特别适合处理和分析图像的深度学习模型。CNN 的结构和原理借鉴了生物视觉系统，尤其是人类视觉皮层的工作方式，使它能够有效提取图像中的各种特征，如边缘、纹理和形状。与传统的神经网络不同，CNN 通过卷积层和池化层来提取特征，并用全连接层对提取到的特征进行分类或回归。</p>
					<div class="educationSection">（二）CNN模型提出</div>
					<ol>
						<li>CNN 发展背景与基本思想</li>
						<p>在 1980 年代，计算机视觉领域的研究者发现传统的机器学习方法在图像处理任务上表现不佳。图像中包含的大量像素信息使得简单的机器学习模型难以有效提取有用的特征，且数据维度高、参数多。这些挑战使得研究者们开始寻找新的方法来自动从图像数据中提取特征。</p>
						<p>此时，研究人员借鉴了生物视觉系统的工作原理。生物学家发现，人类视觉皮层在处理视觉信息时，会逐层提取图像中的不同层次信息，从而形成对图像内容的理解。基于这种启发，研究者们开始设计一种模拟生物视觉系统的层次化结构模型，即卷积神经网络。</p>
						<li>Yann LeCun 和 LeNet 的诞生</li>
						<p>Yann LeCun 是法国计算机科学家，被誉为“卷积神经网络之父”。他在 1989 年提出了一个简单的卷积神经网络模型，用于手写数字识别任务。LeCun 的工作受生物视觉系统启发，并基于如下两个关键原则来设计 CNN：</p>
						<ul>
							<li>局部连接：LeCun 提出的 CNN 只对图像的局部区域进行处理，而不是全图连接。这种方法不仅减少了参数数量，还能更有效地学习图像的局部特征。</li>
							<li> 权重共享：在卷积操作中，CNN 的每一个卷积核在图像的不同位置共享相同的权重，从而减少了需要学习的参数数量。这种结构可以让网络自动识别图像中重复的模式，比如边缘或特定的形状。</li>
						</ul>
						<p>这两个设计思想极大降低了模型复杂度，使得 CNN 能够在当时有限的计算资源下运行。</p>
						<li>LeNet-5 架构（1998 年）</li>
						<p>在 1998 年，Yann LeCun 等人提出了 LeNet-5，这是一个多层的卷积神经网络结构，主要用于手写数字识别（例如识别 0-9 的手写数字）。LeNet-5 的结构包括：</p>
						<ul>
							<li>卷积层：用于提取图像的局部特征。</li>
							<li>池化层：通过下采样操作减少特征的尺寸，从而降低模型的计算量。</li>
							<li>全连接层：用于将卷积和池化提取到的特征综合，用于最终的分类。</li>

						</ul>
						<p>LeNet-5 的诞生标志着 CNN 的第一次成功应用，并在手写数字识别任务上取得了令人瞩目的表现。然而，由于当时的计算能力和数据集规模有限，CNN 的进一步发展受到限制，无法应用于更大规模的任务。</p>
						<li>深度学习和计算能力的推动</li>
						<p>2000 年代，随着 GPU 的出现和计算能力的提升，深度学习的研究逐渐复兴。大规模数据集（如 ImageNet）的出现为 CNN 的训练提供了丰富的数据。AlexNet 的提出将 CNN 推向了新的高度。</p>
						<li>AlexNet 和 CNN 的重大突破（2012 年）</li>
						<p>在 2012 年，由 Alex Krizhevsky 等人设计的 AlexNet 模型参加了 ImageNet 大规模视觉识别竞赛（ILSVRC），并在分类任务上取得了巨大的成功，准确率远超其他方法。AlexNet 的结构和 LeNet-5 相似，但 AlexNet 增加了深度层数、使用了 ReLU 激活函数以及 Dropout 正则化等技术来提升性能。</p>
						<p>AlexNet 的成功证明了 CNN 的潜力，并在计算机视觉领域掀起了深度学习的热潮。此后，更多深层次的 CNN 架构被提出，如 VGG、GoogLeNet、ResNet 等，使 CNN 成为计算机视觉的核心模型。</p>
					</ol>
					<div class="educationSection">（三）CNN模型的核心</div>
					<image class="educationImage" src="resources/educationimages/CNN_1.png"  alt="CNN_1"></image>
					<ol>
						<li>输入层</li>
						<p>输入层通常接收图像数据，图像的像素值组成三维数据张量：宽度、高度和通道（如彩色图像有红、绿、蓝 3 个通道）。</p>
						<p>图像数据通过 CNN 的层次结构处理，从低层的边缘特征逐渐提取到高层的复杂形状和结构特征。</p>
						<li>卷积层（Convolutional Layer）</li>
						<ol>
							<li><strong >卷积运算：</strong>卷积层的核心操作是卷积运算。在图像处理领域中，卷积运算可以通过小矩阵（卷积核或滤波器）在图像上滑动，提取局部区域的特征。例如，一个 3×33×3 的卷积核可以在图像上移动，对每个 3×33×3 的子区域进行点积运算，生成特征图（Feature Map）。</li>
							<li><strong >特征提取：</strong>卷积核通过学习得到特定的权重，能够提取不同的特征，例如边缘、纹理或颜色。每一个卷积核代表一种特定的图像特征，多个卷积核的堆叠则可以提取图像的多种特征。</li>
							<li><strong>特征图的输出：</strong>经过卷积操作的结果会生成新的特征图，将其传递给下一层。特征图的深度等于卷积核的数量</li>
						</ol>
						<li>激活函数（Activation Function）</li>
						<ol>
							<li><strong>(Rectified Linear Unit)：</strong>在卷积操作之后，通常会对特征图应用激活函数。ReLU 是一种常用的激活函数，它将所有负值置零，保持正值不变，从而引入非线性因素。</li>
							<li><strong>非线性特征提取：</strong>激活函数的作用是提高模型的表达能力，让 CNN 可以学习复杂的非线性特征。在 CNN 中，ReLU 函数的计算效率高且可以有效防止梯度消失。</li>
						</ol>
					
						<li>池化层（Pooling Layer）</li>
						<ol>
							<li><strong>池化运算：</strong>池化层的主要作用是降低特征图的尺寸，减少计算量，并且通过特征的抽象增加模型的鲁棒性。常见的池化方法是最大池化（Max Pooling），它从特征图的每个局部区域中取最大值，以保留最显著的特征。</li>
							<li><strong>降低维度与增强平移不变性：</strong>降低维度与增强平移不变性：池化层有助于减少模型的计算需求，同时使得模型对图像中的细微平移更加不敏感。例如，一个 2×22×2 的最大池化操作可以将每 2×22×2 区域缩小为一个值，从而减少特征图的大小。</li>
						</ol>
						<li>多层卷积与池化的组合</li>
						<p>在实际 CNN 结构中，通常会堆叠多个卷积层和池化层以构建深层网络。低层卷积提取图像的基础特征，如边缘和简单形状。中层卷积提取更复杂的特征，如局部模式或图案，而高层卷积则学习全局的结构特征。每一层卷积和池化的输出特征图被传递到下一层，逐步形成更加抽象的特征表示。</p>
						<li>展平层（Flattening Layer）</li>
						<p>卷积和池化层的输出是一个三维的特征图张量。为了便于全连接层处理，需要将三维特征展平成一维向量，这个过程称为“展平”。展平后的特征向量包含了图像的高级特征，并准备传递到全连接层进行进一步处理。</p>
						<li>全连接层（Fully Connected Layer）</li>
						<ol>
							<li><strong>全连接操作：</strong>全连接层将展平的特征向量输入到一个或多个全连接的神经网络层中。这些层将每一个输入特征与输出类别进行加权组合，从而输出预测结果。</li>
							<li><strong>输出结果：</strong>最后一层全连接层通常使用 Softmax 激活函数，用于多分类任务，输出一个概率分布，代表图像属于各类别的可能性。</li>
						</ol>
						<li>损失函数与反向传播</li>
						<ol>
							<li><strong>损失函数：</strong>在训练过程中，CNN 的输出会与真实标签进行比较，计算损失值（例如交叉熵损失），表示预测结果与实际结果的差异。</li>
							<li><strong>反向传播和梯度下降：</strong>通过反向传播算法计算损失函数相对于每层参数的梯度，进而通过梯度下降算法更新卷积核和全连接层的参数，使得 CNN 逐渐优化，从而提高预测准确率。</li>
				
						</ol>
						<li>模型输出</li>
						<p>CNN 在处理一张图像后输出一个分类或预测结果。对于图像分类任务，输出层通常表示预测类别及其概率。例如，如果是手写数字识别任务，输出会是一个 0-9 的数字。</p>
					</ol>
				</div>
                    <!-- 新增的做题链接部分 -->
                <!-- CNN练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">📸 CNN练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">学习卷积神经网络的核心概念和应用</p>

                    <div class="exercise-cards">
                        <!-- CNN知识测试卡片 -->
                        <div class="exercise-card" data-exercise="cnn_quiz">
                            <div class="card-header">
                                <h4>🔍 CNN知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对CNN基本原理和架构的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> CNN相较于全连接网络的优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="cnn_q1" value="A"> A. 参数更少</label>
                                        <label><input type="radio" name="cnn_q1" value="B"> B. 更好的特征提取</label>
                                        <label><input type="radio" name="cnn_q1" value="C"> C. 平移不变性</label>
                                        <label><input type="radio" name="cnn_q1" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 卷积层的参数共享指的是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="cnn_q2" value="A"> A. 所有神经元使用相同权重</label>
                                        <label><input type="radio" name="cnn_q2" value="B"> B. 不同层共享参数</label>
                                        <label><input type="radio" name="cnn_q2" value="C"> C. 输入和输出共享参数</label>
                                        <label><input type="radio" name="cnn_q2" value="D"> D. 随机共享参数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 池化层的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="cnn_q3" value="A"> A. 增加特征图尺寸</label>
                                        <label><input type="radio" name="cnn_q3" value="B"> B. 降低空间维度</label>
                                        <label><input type="radio" name="cnn_q3" value="C"> C. 增加通道数</label>
                                        <label><input type="radio" name="cnn_q3" value="D"> D. 改变数据类型</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> CNN的局部感受野意味着什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="cnn_q4" value="A"> A. 只能看到部分输入</label>
                                        <label><input type="radio" name="cnn_q4" value="B"> B. 看到整个输入</label>
                                        <label><input type="radio" name="cnn_q4" value="C"> C. 随机选择输入区域</label>
                                        <label><input type="radio" name="cnn_q4" value="D"> D. 只能处理局部特征</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 深度学习中CNN的成功关键是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="cnn_q5" value="A"> A. 大数据集</label>
                                        <label><input type="radio" name="cnn_q5" value="B"> B. 端到端学习</label>
                                        <label><input type="radio" name="cnn_q5" value="C"> C. 层次化特征学习</label>
                                        <label><input type="radio" name="cnn_q5" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="cnn_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 池化计算卡片 -->
                        <div class="exercise-card" data-exercise="pooling_calculation">
                            <div class="card-header">
                                <h4>🌊 池化计算</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>练习池化操作的计算过程和参数选择。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 最大池化（Max Pooling）选择什么值作为输出？</p>
                                    <div class="options">
                                        <label><input type="radio" name="pool_q1" value="A"> A. 窗口内的最小值</label>
                                        <label><input type="radio" name="pool_q1" value="B"> B. 窗口内的最大值</label>
                                        <label><input type="radio" name="pool_q1" value="C"> C. 窗口内的平均值</label>
                                        <label><input type="radio" name="pool_q1" value="D"> D. 窗口内的中位数</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 平均池化（Average Pooling）相比最大池化的优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="pool_q2" value="A"> A. 保留更多信息</label>
                                        <label><input type="radio" name="pool_q2" value="B"> B. 计算更快</label>
                                        <label><input type="radio" name="pool_q2" value="C"> C. 更好的特征提取</label>
                                        <label><input type="radio" name="pool_q2" value="D"> D. 抗噪声能力更强</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 池化窗口大小通常选择什么尺寸？</p>
                                    <div class="options">
                                        <label><input type="radio" name="pool_q3" value="A"> A. 1×1</label>
                                        <label><input type="radio" name="pool_q3" value="B"> B. 2×2</label>
                                        <label><input type="radio" name="pool_q3" value="C"> C. 3×3</label>
                                        <label><input type="radio" name="pool_q3" value="D"> D. 5×5</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 池化层的步长通常设置为多少？</p>
                                    <div class="options">
                                        <label><input type="radio" name="pool_q4" value="A"> A. 等于窗口大小</label>
                                        <label><input type="radio" name="pool_q4" value="B"> B. 小于窗口大小</label>
                                        <label><input type="radio" name="pool_q4" value="C"> C. 大于窗口大小</label>
                                        <label><input type="radio" name="pool_q4" value="D"> D. 任意值</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 全局平均池化（Global Average Pooling）的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="pool_q5" value="A"> A. 进一步降低维度</label>
                                        <label><input type="radio" name="pool_q5" value="B"> B. 替代全连接层</label>
                                        <label><input type="radio" name="pool_q5" value="C"> C. 减少过拟合</label>
                                        <label><input type="radio" name="pool_q5" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="pooling_calculation">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 网络架构设计卡片 -->
                        <div class="exercise-card" data-exercise="architecture_design">
                            <div class="card-header">
                                <h4>🏗️ 网络架构设计</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>学习CNN网络架构设计的基本原则和最佳实践。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> CNN网络设计的基本模式是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="arch_q1" value="A"> A. 卷积-激活-池化</label>
                                        <label><input type="radio" name="arch_q1" value="B"> B. 池化-卷积-激活</label>
                                        <label><input type="radio" name="arch_q1" value="C"> C. 激活-池化-卷积</label>
                                        <label><input type="radio" name="arch_q1" value="D"> D. 随机排列</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 网络深度的增加会带来什么问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="arch_q2" value="A"> A. 梯度消失</label>
                                        <label><input type="radio" name="arch_q2" value="B"> B. 训练时间延长</label>
                                        <label><input type="radio" name="arch_q2" value="C"> C. 参数量增加</label>
                                        <label><input type="radio" name="arch_q2" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 1×1卷积层的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="arch_q3" value="A"> A. 降维和升维</label>
                                        <label><input type="radio" name="arch_q3" value="B"> B. 特征融合</label>
                                        <label><input type="radio" name="arch_q3" value="C"> C. 非线性变换</label>
                                        <label><input type="radio" name="arch_q3" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 瓶颈结构（bottleneck）如何减少计算量？</p>
                                    <div class="options">
                                        <label><input type="radio" name="arch_q4" value="A"> A. 先降维再升维</label>
                                        <label><input type="radio" name="arch_q4" value="B"> B. 增加网络深度</label>
                                        <label><input type="radio" name="arch_q4" value="C"> C. 减少通道数</label>
                                        <label><input type="radio" name="arch_q4" value="D"> D. 改变卷积核大小</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 现代CNN设计的核心思想是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="arch_q5" value="A"> A. 越深越好</label>
                                        <label><input type="radio" name="arch_q5" value="B"> B. 平衡深度和效率</label>
                                        <label><input type="radio" name="arch_q5" value="C"> C. 使用更大卷积核</label>
                                        <label><input type="radio" name="arch_q5" value="D"> D. 减少参数量</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="architecture_design">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 特征图分析卡片 -->
                        <div class="exercise-card" data-exercise="feature_maps">
                            <div class="card-header">
                                <h4>🗺️ 特征图分析</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>分析CNN各层特征图的特点和变化规律。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> CNN前几层卷积学习的是什么特征？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feat_q1" value="A"> A. 复杂语义特征</label>
                                        <label><input type="radio" name="feat_q1" value="B"> B. 简单边缘和纹理</label>
                                        <label><input type="radio" name="feat_q1" value="C"> C. 整体形状</label>
                                        <label><input type="radio" name="feat_q1" value="D"> D. 颜色信息</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 随着网络深度的增加，特征图的尺寸如何变化？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feat_q2" value="A"> A. 尺寸增大</label>
                                        <label><input type="radio" name="feat_q2" value="B"> B. 尺寸减小</label>
                                        <label><input type="radio" name="feat_q2" value="C"> C. 尺寸不变</label>
                                        <label><input type="radio" name="feat_q2" value="D"> D. 随机变化</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 特征图的通道数代表什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feat_q3" value="A"> A. 不同的特征类型</label>
                                        <label><input type="radio" name="feat_q3" value="B"> B. 时间维度</label>
                                        <label><input type="radio" name="feat_q3" value="C"> C. 空间位置</label>
                                        <label><input type="radio" name="feat_q3" value="D"> D. 数据类型</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 感受野（receptive field）随着深度增加如何变化？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feat_q4" value="A"> A. 减小</label>
                                        <label><input type="radio" name="feat_q4" value="B"> B. 增大</label>
                                        <label><input type="radio" name="feat_q4" value="C"> C. 不变</label>
                                        <label><input type="radio" name="feat_q4" value="D"> D. 随机变化</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 可视化CNN特征图有助于做什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="feat_q5" value="A"> A. 理解网络工作原理</label>
                                        <label><input type="radio" name="feat_q5" value="B"> B. 调试网络结构</label>
                                        <label><input type="radio" name="feat_q5" value="C"> C. 发现网络问题</label>
                                        <label><input type="radio" name="feat_q5" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="feature_maps">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- CNN应用场景卡片 -->
                        <div class="exercise-card" data-exercise="cnn_applications">
                            <div class="card-header">
                                <h4>🎬 CNN应用场景</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>探索CNN在不同领域的应用和变体。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> ImageNet是什么类型的比赛？</p>
                                    <div class="options">
                                        <label><input type="radio" name="app_q1" value="A"> A. 图像分类</label>
                                        <label><input type="radio" name="app_q1" value="B"> B. 目标检测</label>
                                        <label><input type="radio" name="app_q1" value="C"> C. 图像分割</label>
                                        <label><input type="radio" name="app_q1" value="D"> D. 图像生成</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 目标检测任务需要CNN输出什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="app_q2" value="A"> A. 类别标签</label>
                                        <label><input type="radio" name="app_q2" value="B"> B. 边界框位置</label>
                                        <label><input type="radio" name="app_q2" value="C"> C. 像素级标签</label>
                                        <label><input type="radio" name="app_q2" value="D"> D. 生成图像</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> U-Net主要用于什么任务？</p>
                                    <div class="options">
                                        <label><input type="radio" name="app_q3" value="A"> A. 图像分类</label>
                                        <label><input type="radio" name="app_q3" value="B"> B. 图像分割</label>
                                        <label><input type="radio" name="app_q3" value="C"> C. 目标检测</label>
                                        <label><input type="radio" name="app_q3" value="D"> D. 图像生成</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> GAN中的生成器网络通常使用什么架构？</p>
                                    <div class="options">
                                        <label><input type="radio" name="app_q4" value="A"> A. 全连接网络</label>
                                        <label><input type="radio" name="app_q4" value="B"> B. 转置卷积网络</label>
                                        <label><input type="radio" name="app_q4" value="C"> C. RNN网络</label>
                                        <label><input type="radio" name="app_q4" value="D"> D. Transformer</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> CNN在自然语言处理中的应用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="app_q5" value="A"> A. 文本分类</label>
                                        <label><input type="radio" name="app_q5" value="B"> B. 序列生成</label>
                                        <label><input type="radio" name="app_q5" value="C"> C. 机器翻译</label>
                                        <label><input type="radio" name="app_q5" value="D"> D. 对话系统</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="cnn_applications">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
			</div>	
			 
			<div id = "educationnewCNN">
				<div class="educationTitle">现代卷积神经网络</div>
				<div class="educationContent">
					<div class="educationSection">（一）概述</div>
					<p>虽然深度神经网络的概念非常简单——将神经网络堆叠在一起。但由于不同的网络架构和超参数选择，这些神经网络的性能会发生很大变化。本章将按照时间顺序介绍以下模型：</p>
					<ul>
						<li><strong>AlexNet。</strong>它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络；</li>
						<li><strong>使用重复块的网络（VGG）。</strong>它重复使用由卷积层和卷积层（用来代替全连接层）来构建深层网络;</li>
						<li><strong>网络中的网络（NiN）。</strong>它重复使用由卷积层和卷积层（用来代替全连接层）来构建深层网络;</li>
						<li><strong>含并行连结的网络（GoogLeNet）。</strong>它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息；</li>
						<li><strong>残差网络（ResNet）。</strong>它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构；</li>
						<li><strong>稠密连接网络（DenseNet）。</strong>它的计算成本很高，但给我们带来了更好的效果。</li>
					</ul>

					<div class="educationSection">（二）深度卷积神经网络（AlexNet）</div>
					<p>2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状。 AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。</p>
					<p>AlexNet和LeNet的设计理念非常相似，但也存在显著差异。首先，AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。其次，AlexNet使用ReLU而不是sigmoid作为其激活函数。</p>
					<image class="educationImage" src="resources/educationimages/newCNN_1.png"  alt="newCNN_1" title="从LeNet（左）到AlexNet(右)" ></image>
					<p>在AlexNet的第一层，卷积窗口的形状是11×11。由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。第二层中的卷积窗口形状被缩减为5×5，然后是3×3。此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为3×3、步幅为2的最大汇聚层。而且，AlexNet的卷积通道数目是LeNet的10倍。</p>
					<p>在最后一个卷积层后有两个全连接层，分别有4096个输出。 这两个巨大的全连接层拥有将近1GB的模型参数。由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。幸运的是，现在GPU显存相对充裕，所以现在很少需要跨GPU分解模型。</p>
					<p>此外，AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。 一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。 另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。 当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。 相反，ReLU激活函数在正区间的梯度总是1。 因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。</p>
					
					<div class ="educationSection">（三）使用块的网络（VGG）</div>
					<p>虽然AlexNet证明深层神经网络卓有成效，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络。使用块的想法首先出现在牛津大学的视觉几何组（visual geometry group）的VGG网络中。通过使用循环和子程序，可以很容易地在任何现代深度学习框架的代码中实现这些重复的架构。</p>
					<p>经典卷积神经网络的基本组成部分是下面的这个序列：（1）带填充以保持分辨率的卷积层；（2）非线性激活函数，如ReLU；（3）汇聚层，如最大汇聚层。而一个VGG块与之类似，由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层。在最初的VGG论文中 (Simonyan and Zisserman, 2014)，
						作者使用了带有3×3卷积核、填充为1（保持高度和宽度）的卷积层，和带有2×2汇聚窗口、步幅为2（每个块后的分辨率减半）的最大汇聚层 。
						与AlexNet、LeNet一样，VGG网络可以分为两部分：第一部分主要由卷积层和汇聚层组成，第二部分由全连接层组成。</p>
					<image class="educationImage" src="resources/educationimages/newCNN_2.png"  alt="newCNN_2" title = " 从AlexNet到VGG"></image>
					<p>原始VGG网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。 第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到512。由于该网络使用8个卷积层和3个全连接层，因此它通常被称为VGG-11。</p>
					
					<div class="educationSection">（四）网络中的网络（NiN）</div>
					<p>LeNet、AlexNet和VGG都有一个共同的设计模式：通过一系列的卷积层与汇聚层来提取空间结构特征；然后通过全连接层对特征的表征进行处理。 AlexNet和VGG对LeNet的改进主要在于如何扩大和加深这两个模块。 或者，可以想象在这个过程的早期使用全连接层。然而，如果使用了全连接层，可能会完全放弃表征的空间结构。 网络中的网络（NiN）提供了一个非常简单的解决方案：在每个像素的通道上分别使用多层感知机。</p>
					<p>卷积层的输入和输出由四维张量组成，张量的每个轴分别对应样本、通道、高度和宽度。 另外，全连接层的输入和输出通常是分别对应于样本和特征的二维张量。 NiN的想法是在每个像素位置（针对每个高度和宽度）应用一个全连接层。 如果我们将权重连接到每个空间位置，我们可以将其视为1×1卷积层，或作为在每个像素位置上独立作用的全连接层。 从另一个角度看，即将空间维度中的每个像素视为单个样本，将通道维度视为不同特征（feature）。 </p>
					<p> NiN块以一个普通卷积层开始，后面是两个1×1的卷积层。这两个1×1卷积层充当带有ReLU激活函数的逐像素全连接层。 第一层的卷积窗口形状通常由用户设置。 随后的卷积窗口形状固定为1×1。 </p>
					<image class="educationImage" src="resources/educationimages/newCNN_3.png"  alt="newCNN_3" title = " VGG和NiN的块之间主要的架构差异"></image>
					<p>最初的NiN网络是在AlexNet后不久提出的，显然从中得到了一些启示。 NiN使用窗口形状为11×11、5×5和3×3的卷积层，输出通道数量与AlexNet中的相同。 每个NiN块后有一个最大汇聚层，汇聚窗口形状为3×3，步幅为2。</p>
					<p>NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层。 相反，NiN使用一个NiN块，其输出通道数等于标签类别的数量。最后放一个全局平均汇聚层（global average pooling layer），生成一个对数几率 （logits）。NiN设计的一个优点是，它显著减少了模型所需参数的数量。然而，在实践中，这种设计有时会增加训练模型的时间。</p>

					<div class = "educationSection">（五）含并行连结的网络（GoogLeNet）</div>
					<p>GoogLeNet吸收了NiN中串联网络的思想，并在此基础上做了改进。 这篇论文的一个重点是解决了什么样大小的卷积核最合适的问题。 毕竟，以前流行的网络使用小到1×1，大到11×11的卷积核。 本文的一个观点是，有时使用不同大小的卷积核组合是有利的。 </p>
					<p>在GoogLeNet中，基本的卷积块被称为Inception块（Inception block），Inception块由四条并行路径组成。 前三条路径使用窗口大小为1×1、3×3和5×5的卷积层，从不同空间大小中提取信息。 中间的两条路径在输入上执行1×1卷积，以减少通道数，从而降低模型的复杂性。 第四条路径使用3×3最大汇聚层，然后使用1×1卷积层来改变通道数。 这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成Inception块的输出。在Inception块中，通常调整的超参数是每层输出通道数。 </p>
					<image class="educationImage" src="resources/educationimages/newCNN_4.png"  alt="newCNN_4" title = " Inception块的架构"></image>
					<p>GoogLeNet一共使用9个Inception块和全局平均汇聚层的堆叠来生成其估计值。Inception块之间的最大汇聚层可降低维度。 第一个模块类似于AlexNet和LeNet，Inception块的组合从VGG继承，全局平均汇聚层避免了在最后使用全连接层。</p>
					<image class="educationImage" src="resources/educationimages/newCNN_5.png"  alt="newCNN_5" title = "GoogLeNet架构"></image>

					<div class = "educationSection">（六）残差网络（ResNet）</div>
					<p>假设我们的原始输入为x，而希望训练出的理想映射为f(x)（作为 图3.6上方激活函数的输入）。 图3.6左图虚线框中的部分需要直接拟合出该映射f(x)，而右图虚线框中的部分则需要拟合出残差映射f(x)−x。 残差映射在现实中往往更容易优化。 我们只需将 图3.6中右图虚线框内上方的加权运算（如仿射）的权重和偏置参数设成0，那么f(x)即为恒等映射。 实际中，当理想映射f(x)极接近于恒等映射时，残差映射也易于捕捉恒等映射的细微波动。图3.6右图是ResNet的基础架构–残差块（residual block）。 在残差块中，输入可通过跨层数据线路更快地向前传播。 </p>
					<image class="educationImage" src="resources/educationimages/newCNN_6.png"  alt="newCNN_6" title = "正常块（左）和残差块（右）"></image>
					<p>ResNet沿用了VGG完整的3×3卷积层设计。 残差块里首先有2个有相同输出通道数的3×3卷积层。 每个卷积层后接一个批量规范化层和ReLU激活函数。 然后我们通过跨层数据通路，跳过这2个卷积运算，将输入直接加在最后的ReLU激活函数前。 这样的设计要求2个卷积层的输出与输入形状一样，从而使它们可以相加。 如果想改变通道数，就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算。 </p>
					<image class="educationImage" src="resources/educationimages/newCNN_7.png"  alt="newCNN_7" title = " 包含和不包含1×1卷积层的残差块"></image>
					<p>ResNet的前两层跟之前介绍的GoogLeNet中的一样： 在输出通道数为64、步幅为2的7×7卷积层后，接步幅为2的3×3的最大汇聚层。 不同之处在于ResNet每个卷积层后增加了批量规范化层。</p>
					<p>GoogLeNet在后面接了4个由Inception块组成的模块。 ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。 第一个模块的通道数同输入通道数一致。 由于之前已经使用了步幅为2的最大汇聚层，所以无须减小高和宽。 之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。</p>
					<image class="educationImage" src="resources/educationimages/newCNN_8.png"  alt="newCNN_8" title = " ResNet-18架构"></image>

					<div class = "educationSection">（七）稠密连接网络（DenseNet）</div>
					<p>ResNet将f分解为两个部分：一个简单的线性项和一个复杂的非线性项，根据泰勒展开式，如果向将f拓展成超过两部分信息，一种解决方案就是DenseNet。</p>
					<image class="educationImage" src="resources/educationimages/newCNN_9.png"  alt="newCNN_9" title = " ResNet&DenseNet"></image>
					<p>上图ResNet（左）和DenseNet（右）在跨层连接上的主要区别：使用相加和使用连结ResNet和DenseNet的关键区别在于，
						DenseNet输出是连接（用图中的[,]表示）而不是如ResNet的简单相加。 因此，在应用越来越复杂的函数序列后，我们执行从x到其展开式的映射：
						<span class="math inline">\[\mathbf{x}\to[\mathbf{x},f_1(\mathbf{x}),f_2([\mathbf{x},f_1(\mathbf{x})]),f_3([\mathbf{x},f_1(\mathbf{x}),f_2([\mathbf{x},f_1(\mathbf{x})])]),\ldots].\]</span>
						</p>
					<p>稠密网络主要由2部分构成：稠密块（dense block）和过渡层（transition layer）。 前者定义如何连接输入和输出，而后者则控制通道数量，使其不会太复杂。</p>
					<p>DenseNet首先使用同ResNet一样的单卷积层和最大汇聚层。接下来，类似于ResNet使用的4个残差块，DenseNet使用的是4个稠密块。 与ResNet类似，我们可以设置每个稠密块使用多少个卷积层。在每个模块之间，ResNet通过步幅为2的残差块减小高和宽，DenseNet则使用过渡层来减半高和宽，并减半通道数。与ResNet类似，最后接上全局汇聚层和全连接层来输出结果。</p>
                    <!-- 新增的做题链接部分 -->
                    <div class="exercise-section">
                        <!-- 现代CNN练习区域 - 卡片式布局 -->
                        <div class="learning-exercises">
                            <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">🚀 现代CNN练习区</h3>
                            <p style="text-align: center; color: #666; margin-bottom: 30px;">探索现代卷积神经网络的经典架构</p>

                            <div class="exercise-cards">
                                <!-- 现代CNN知识测试卡片 -->
                                <div class="exercise-card" data-exercise="modern_cnn_quiz">
                                    <div class="card-header">
                                        <h4>🧠 现代CNN知识测试</h4>
                                        <div class="progress-indicator">
                                            <span class="progress-text">未完成</span>
                                            <div class="progress-bar">
                                                <div class="progress-fill" style="width: 0%"></div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="card-content">
                                        <p>测试您对现代CNN架构发展的理解。</p>
                                        <button class="start-exercise-btn">开始练习</button>
                                    </div>
                                    <div class="card-questions" style="display: none;">
                                        <div class="question">
                                            <p><strong>题目1:</strong> AlexNet相较于LeNet的主要创新是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="modern_q1" value="A"> A. 使用ReLU激活函数</label>
                                                <label><input type="radio" name="modern_q1" value="B"> B. 使用GPU加速</label>
                                                <label><input type="radio" name="modern_q1" value="C"> C. 数据增强</label>
                                                <label><input type="radio" name="modern_q1" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目2:</strong> VGG网络的主要特点是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="modern_q2" value="A"> A. 使用3×3卷积</label>
                                                <label><input type="radio" name="modern_q2" value="B"> B. 简单的堆叠结构</label>
                                                <label><input type="radio" name="modern_q2" value="C"> C. 易于理解和实现</label>
                                                <label><input type="radio" name="modern_q2" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目3:</strong> GoogLeNet引入的核心思想是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="modern_q3" value="A"> A. 残差连接</label>
                                                <label><input type="radio" name="modern_q3" value="B"> B. Inception模块</label>
                                                <label><input type="radio" name="modern_q3" value="C"> C. 密集连接</label>
                                                <label><input type="radio" name="modern_q3" value="D"> D. 深度可分离卷积</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目4:</strong> ResNet解决的主要问题是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="modern_q4" value="A"> A. 梯度消失</label>
                                                <label><input type="radio" name="modern_q4" value="B"> B. 计算效率</label>
                                                <label><input type="radio" name="modern_q4" value="C"> C. 内存占用</label>
                                                <label><input type="radio" name="modern_q4" value="D"> D. 收敛速度</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目5:</strong> DenseNet相比ResNet的优势是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="modern_q5" value="A"> A. 参数效率更高</label>
                                                <label><input type="radio" name="modern_q5" value="B"> B. 特征复用</label>
                                                <label><input type="radio" name="modern_q5" value="C"> C. 减少过拟合</label>
                                                <label><input type="radio" name="modern_q5" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="card-actions">
                                            <button class="submit-btn" data-category="modern_cnn_quiz">提交答案</button>
                                            <button class="close-exercise-btn">收起练习</button>
                                        </div>
                                    </div>
                                </div>

                                <!-- AlexNet架构分析卡片 -->
                                <div class="exercise-card" data-exercise="alexnet_analysis">
                                    <div class="card-header">
                                        <h4>🏆 AlexNet架构分析</h4>
                                        <div class="progress-indicator">
                                            <span class="progress-text">未完成</span>
                                            <div class="progress-bar">
                                                <div class="progress-fill" style="width: 0%"></div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="card-content">
                                        <p>深入分析AlexNet的架构设计和关键技术。</p>
                                        <button class="start-exercise-btn">开始练习</button>
                                    </div>
                                    <div class="card-questions" style="display: none;">
                                        <div class="question">
                                            <p><strong>题目1:</strong> AlexNet有多少个卷积层？</p>
                                            <div class="options">
                                                <label><input type="radio" name="alex_q1" value="A"> A. 3个</label>
                                                <label><input type="radio" name="alex_q1" value="B"> B. 5个</label>
                                                <label><input type="radio" name="alex_q1" value="C"> C. 8个</label>
                                                <label><input type="radio" name="alex_q1" value="D"> D. 11个</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目2:</strong> AlexNet使用什么技术处理过拟合？</p>
                                            <div class="options">
                                                <label><input type="radio" name="alex_q2" value="A"> A. Dropout</label>
                                                <label><input type="radio" name="alex_q2" value="B"> B. 数据增强</label>
                                                <label><input type="radio" name="alex_q2" value="C"> C. L2正则化</label>
                                                <label><input type="radio" name="alex_q2" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目3:</strong> AlexNet的双GPU训练有什么优势？</p>
                                            <div class="options">
                                                <label><input type="radio" name="alex_q3" value="A"> A. 加速训练</label>
                                                <label><input type="radio" name="alex_q3" value="B"> B. 增加模型容量</label>
                                                <label><input type="radio" name="alex_q3" value="C"> C. 减少内存占用</label>
                                                <label><input type="radio" name="alex_q3" value="D"> D. 提高准确率</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目4:</strong> AlexNet的LRN层作用是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="alex_q4" value="A"> A. 局部归一化</label>
                                                <label><input type="radio" name="alex_q4" value="B"> B. 减少过拟合</label>
                                                <label><input type="radio" name="alex_q4" value="C"> C. 提高泛化能力</label>
                                                <label><input type="radio" name="alex_q4" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目5:</strong> AlexNet在ImageNet上的突破是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="alex_q5" value="A"> A. 首次使用CNN</label>
                                                <label><input type="radio" name="alex_q5" value="B"> B. 显著提高准确率</label>
                                                <label><input type="radio" name="alex_q5" value="C"> C. 证明深度学习潜力</label>
                                                <label><input type="radio" name="alex_q5" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="card-actions">
                                            <button class="submit-btn" data-category="alexnet_analysis">提交答案</button>
                                            <button class="close-exercise-btn">收起练习</button>
                                        </div>
                                    </div>
                                </div>

                                <!-- VGG网络设计卡片 -->
                                <div class="exercise-card" data-exercise="vgg_design">
                                    <div class="card-header">
                                        <h4>📚 VGG网络设计</h4>
                                        <div class="progress-indicator">
                                            <span class="progress-text">未完成</span>
                                            <div class="progress-bar">
                                                <div class="progress-fill" style="width: 0%"></div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="card-content">
                                        <p>学习VGG网络的设计理念和架构特点。</p>
                                        <button class="start-exercise-btn">开始练习</button>
                                    </div>
                                    <div class="card-questions" style="display: none;">
                                        <div class="question">
                                            <p><strong>题目1:</strong> VGG网络为什么使用3×3卷积？</p>
                                            <div class="options">
                                                <label><input type="radio" name="vgg_q1" value="A"> A. 计算效率高</label>
                                                <label><input type="radio" name="vgg_q1" value="B"> B. 非线性能力强</label>
                                                <label><input type="radio" name="vgg_q1" value="C"> C. 易于堆叠</label>
                                                <label><input type="radio" name="vgg_q1" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目2:</strong> VGG-16和VGG-19的区别是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="vgg_q2" value="A"> A. 卷积层数不同</label>
                                                <label><input type="radio" name="vgg_q2" value="B"> B. 全连接层数不同</label>
                                                <label><input type="radio" name="vgg_q2" value="C"> C. 池化层数不同</label>
                                                <label><input type="radio" name="vgg_q2" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目3:</strong> VGG网络的参数主要来自哪里？</p>
                                            <div class="options">
                                                <label><input type="radio" name="vgg_q3" value="A"> A. 卷积层</label>
                                                <label><input type="radio" name="vgg_q3" value="B"> B. 全连接层</label>
                                                <label><input type="radio" name="vgg_q3" value="C"> C. 池化层</label>
                                                <label><input type="radio" name="vgg_q3" value="D"> D. 激活层</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目4:</strong> VGG网络的缺点是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="vgg_q4" value="A"> A. 参数量太大</label>
                                                <label><input type="radio" name="vgg_q4" value="B"> B. 训练时间长</label>
                                                <label><input type="radio" name="vgg_q4" value="C"> C. 内存占用高</label>
                                                <label><input type="radio" name="vgg_q4" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目5:</strong> VGG网络对后续研究的影响是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="vgg_q5" value="A"> A. 证明小卷积核有效</label>
                                                <label><input type="radio" name="vgg_q5" value="B"> B. 简化网络设计</label>
                                                <label><input type="radio" name="vgg_q5" value="C"> C. 提供预训练模型</label>
                                                <label><input type="radio" name="vgg_q5" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="card-actions">
                                            <button class="submit-btn" data-category="vgg_design">提交答案</button>
                                            <button class="close-exercise-btn">收起练习</button>
                                        </div>
                                    </div>
                                </div>

                                <!-- Inception模块练习卡片 -->
                                <div class="exercise-card" data-exercise="inception_blocks">
                                    <div class="card-header">
                                        <h4>🌐 Inception模块练习</h4>
                                        <div class="progress-indicator">
                                            <span class="progress-text">未完成</span>
                                            <div class="progress-bar">
                                                <div class="progress-fill" style="width: 0%"></div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="card-content">
                                        <p>理解Inception模块的设计思想和计算原理。</p>
                                        <button class="start-exercise-btn">开始练习</button>
                                    </div>
                                    <div class="card-questions" style="display: none;">
                                        <div class="question">
                                            <p><strong>题目1:</strong> Inception模块的核心思想是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="incep_q1" value="A"> A. 并行计算不同尺度的特征</label>
                                                <label><input type="radio" name="incep_q1" value="B"> B. 串行处理特征</label>
                                                <label><input type="radio" name="incep_q1" value="C"> C. 只使用大卷积核</label>
                                                <label><input type="radio" name="incep_q1" value="D"> D. 减少网络深度</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目2:</strong> 1×1卷积在Inception中的作用是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="incep_q2" value="A"> A. 跨通道特征变换</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目3:</strong> GoogLeNet有多少层？</p>
                                            <div class="options">
                                                <label><input type="radio" name="incep_q3" value="A"> A. 8层</label>
                                                <label><input type="radio" name="incep_q3" value="B"> B. 22层</label>
                                                <label><input type="radio" name="incep_q3" value="C"> C. 50层</label>
                                                <label><input type="radio" name="incep_q3" value="D"> D. 152层</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目4:</strong> Inception v3的主要改进是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="incep_q4" value="A"> A. 减少参数量</label>
                                                <label><input type="radio" name="incep_q4" value="B"> B. 提高效率</label>
                                                <label><input type="radio" name="incep_q4" value="C"> C. 更好的分解</label>
                                                <label><input type="radio" name="incep_q4" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目5:</strong> Inception模块如何平衡宽度和深度？</p>
                                            <div class="options">
                                                <label><input type="radio" name="incep_q5" value="A"> A. 增加网络宽度</label>
                                                <label><input type="radio" name="incep_q5" value="B"> B. 并行分支处理</label>
                                                <label><input type="radio" name="incep_q5" value="C"> C. 减少计算成本</label>
                                                <label><input type="radio" name="incep_q5" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="card-actions">
                                            <button class="submit-btn" data-category="inception_blocks">提交答案</button>
                                            <button class="close-exercise-btn">收起练习</button>
                                        </div>
                                    </div>
                                </div>

                                <!-- DenseNet架构卡片 -->
                                <div class="exercise-card" data-exercise="densenet_architecture">
                                    <div class="card-header">
                                        <h4>🌲 DenseNet架构</h4>
                                        <div class="progress-indicator">
                                            <span class="progress-text">未完成</span>
                                            <div class="progress-bar">
                                                <div class="progress-fill" style="width: 0%"></div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="card-content">
                                        <p>学习DenseNet的密集连接思想和架构特点。</p>
                                        <button class="start-exercise-btn">开始练习</button>
                                    </div>
                                    <div class="card-questions" style="display: none;">
                                        <div class="question">
                                            <p><strong>题目1:</strong> DenseNet的核心创新是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="dense_q1" value="A"> A. 密集连接</label>
                                                <label><input type="radio" name="dense_q1" value="B"> B. 残差连接</label>
                                                <label><input type="radio" name="dense_q1" value="C"> C. 并行连接</label>
                                                <label><input type="radio" name="dense_q1" value="D"> D. 短连接</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目2:</strong> DenseNet中每个层接收什么作为输入？</p>
                                            <div class="options">
                                                <label><input type="radio" name="dense_q2" value="A"> A. 前一层的输出</label>
                                                <label><input type="radio" name="dense_q2" value="B"> B. 所有前面层的输出</label>
                                                <label><input type="radio" name="dense_q2" value="C"> C. 随机层输出</label>
                                                <label><input type="radio" name="dense_q2" value="D"> D. 最后几层输出</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目3:</strong> DenseNet的过渡层作用是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="dense_q3" value="A"> A. 压缩特征图</label>
                                                <label><input type="radio" name="dense_q3" value="B"> B. 减少通道数</label>
                                                <label><input type="radio" name="dense_q3" value="C"> C. 控制模型复杂度</label>
                                                <label><input type="radio" name="dense_q3" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目4:</strong> DenseNet相比传统网络的优势是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="dense_q4" value="A"> A. 参数效率高</label>
                                                <label><input type="radio" name="dense_q4" value="B"> B. 特征复用好</label>
                                                <label><input type="radio" name="dense_q4" value="C"> C. 减少过拟合</label>
                                                <label><input type="radio" name="dense_q4" value="D"> D. 以上都是</label>
                                            </div>
                                        </div>

                                        <div class="question">
                                            <p><strong>题目5:</strong> 密集块（dense block）内的连接方式是什么？</p>
                                            <div class="options">
                                                <label><input type="radio" name="dense_q5" value="A"> A. 顺序连接</label>
                                                <label><input type="radio" name="dense_q5" value="B"> B. 跳跃连接</label>
                                                <label><input type="radio" name="dense_q5" value="C"> C. 串联所有层</label>
                                                <label><input type="radio" name="dense_q5" value="D"> D. 拼接特征图</label>
                                            </div>
                                        </div>

                                        <div class="card-actions">
                                            <button class="submit-btn" data-category="densenet_architecture">提交答案</button>
                                            <button class="close-exercise-btn">收起练习</button>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
				</div>
            </div>
            <div id = "educationRNN">
                <div class="educationTitle">循环神经网络</div>
                <div class="educationContent">
                    <div class="educationSection">（一）概述</div>
                    <p>循环神经网络 (RNN) 是一种人工神经网络，旨在处理顺序数据，例如时间序列或自然语言。它们具有反馈连接，使它们能够保留先前时间步骤的信息，从而能够捕获时间依赖性。这使得 RNN 非常适合语言建模、语音识别和顺序数据分析等任务。苹果的Siri和谷歌的语音搜索都使用RNN。</p>
                    <image class="educationImage" src="resources/educationimages/RNN_1.png"  alt="RNN_1" ></image>
                    <p>RNN 是一种可用于对序列数据建模的神经网络。 RNN 由前馈网络组成，其行为与人脑相似。简而言之，循环神经网络可以以其他算法无法做到的方式预测顺序数据。标准神经网络中的所有输入和输出都是相互独立的，但是在某些情况下，例如在预测短语的下一个单词时，前面的单词是必要的，因此必须记住前面的单词。结果，RNN 应运而生，它使用隐藏层来克服这个问题。 RNN 最重要的组成部分是隐藏状态，它记住有关序列的特定信息。</p>
                    <p>RNN 有一个内存，用于存储有关计算的所有信息。它对每个输入采用相同的设置，因为它通过在所有输入或隐藏层上执行相同的任务来产生相同的结果。</p>
                    <image class="educationImage" src="resources/educationimages/RNN_2.png"  alt="RNN_2" title = ></image>
                    <p>循环神经网络对序列的每个元素使用相同的权重，从而减少了参数的数量，并允许模型泛化为不同长度的序列。由于其设计，RNN 泛化到序列数据以外的结构化数据，例如地理或图形数据。与许多其他深度学习技术一样，循环神经网络相对较旧。它们最初是在 20 世纪 80 年代开发的，但直到最近我们才充分认识到它们的潜力。 20 世纪 90 年代长短期记忆 (LSTM) 的出现，加上计算能力的提高和我们现在必须处理的大量数据，确实将 RNN 推到了最前沿。</p>

                    <div class ="educationSection">（二）RNN模型提出</div>
                    <ol>
                        <li><strong>基本RNN结构：</strong>为了解决普通DNN无法有效获取上下文信息的缺点，RNN最基本的改良点在于增加一个“模块”用于存储上下文信息。下图为一个典型RNN的结构示意图：</li>
                        <image class="educationImage" src="resources/educationimages/RNN_3.png"  alt="RNN_3" ></image>
                        <p>上图是一个典型的RNN结构图，初看可能会不太理解。理解首先不看右侧的矩阵，只看左侧的顺序网络，即图(b)，表示的就是一个普通的前馈神经网络。 接下来回头看图(a)，RNN相比于一般前馈网络，增加了一个保存上下文信息的权重矩阵，也即每次计算输出不仅要考虑当前输入数据，还要考虑序列数据的上下文信息。</p>
                        <li><strong>RNN展开结构：</strong>
                            我们知道了RNN模型增加了一个权重矩阵用于存储输入序列的上下文信息，接下来我们来介绍RNN结构如何进行模型计算以及上下文信息如何应用到RNN结构。为了更好地理解RNN计算方式，下图是一个序列展开的RNN示意图（即上图a的时序展开图）：
                        </li>
                        <image class="educationImage" src="resources/educationimages/RNN_4.png"  alt="RNN_4"  ></image>
                        <p>其中表示时刻的模型输入，表示对应的输入结果。RNN模型计算公式如下：
                            <span class="math inline">\[\begin{array}{l}{y_{i}=g(Vh_{i})}\\{h_{i}=f(Ux_{i}+Wh_{i-1})}\end{array}\]</span>
                            由计算公式可以看出，隐藏层的输出隐变量在RNN中既与当前时刻输入有关，又与上一时刻的隐变量有关。因此可以认为包含了影响当前输入信息的“上下文”信息，而可学习的参数矩阵决定了上下文信息对当前影响程度。 值得注意的是，在整个模型处理期间，参数矩阵是使用的同一个矩阵。
                        </p>
                        <li>
                            <strong>时间反向传播（Backpropagation Through Time, BPTT）：</strong>
                            <p>BPTT是训练RNN的核心算法，它将反向传播算法扩展到时间序列，以学习时间相关的信息。由于RNN具有循环结构，BPTT的关键在于将误差在时间维度上展开，使每个时间步都能调整相应的参数。</p>
                            <p>BPTT算法的基本思想是将RNN在时间维度上“展开”（Unroll），将一个循环结构的网络拆解为多个时序步骤的等效神经网络，这样每个时间步都可以看作一个全连接层的传播。通过这种展开，RNN在每个时间步的状态和输出变得“独立”，可以使用常规反向传播算法在时间维度上计算误差和梯度。</p>
                        </li>
                    </ol>
                    <div class ="educationSection">（三）RNN模型结构变化</div>
                    <p>根据输入长度与输出序列长度的不同，可以将RNN模型结构分为N to N，N to 1, 1 to N，及N to M四种:</p>
                    <ol>
                        <li><strong>N to N结构RNN模型</strong></li>
                        <p>第一种是常见的输入长度与输出长度相同的RNN结构，也就表示每一个输入数据都有对应的一个输出值，可以用于逐序列判断或分类任务，如序列标注、视频帧分类、NER及分词等任务。其结构图如下：</p>
                        <image class="educationImage" src="resources/educationimages/RNN_5.png"  alt="RNN_5" ></image>
                        <span class = "math inline">\[\begin{array}{l}{y_{i}=g(Vh_{i})}\\{h_{i}=f(Ux_{i}+Wh_{i-1})}\end{array}\]</span>
                        <li><strong>N to 1结构RNN模型</strong> </li>
                        <p>表示输入一个序列只生成一个输出值(通常用尾数据对应输出值)。其意义是序列的输出结果蕴含整条序列数据的语义信息及上下文信息。常见应用：文字分类、文章分类及图像分类等任务。</p>
                        <image class="educationImage" src="resources/educationimages/RNN_6.png"  alt="RNN_6" ></image>
                        <span class = "math inline">\[Y = Y_{\text{smallN}} = g(Vh_N)/h_i = f(Ux_i + Wh_{i-1})\]</span>
                        <li><strong> 1 to N结构RNN模型</strong></li>
                        <p> 表示一个输入数据对应输出一个序列的模型。其意义表示一个起始状态或者种子数据，生成一个序列的输出结果。常见应用包括由图像生成文章，由类别生成音乐、文章及代码等，由种子数据生成序列的任务。</p>
                        <image class="educationImage" src="resources/educationimages/RNN_7.png"  alt="RNN_7" ></image>
                        <image class="educationImage" src="resources/educationimages/RNN_8.png"  alt="RNN_8" ></image>
                        <p>1 to N结构RNN模型根据输入只有一个向量，输入位置的不同，可以分为只在首个时刻输入(上左图)和在每个时刻均输入(上右图)两种结构。其中第一种结构计算方法如下：</p>
                        <span class = "math inline">\[\begin{aligned}
                            y_i &= g(Vh_i) \\
                            h_i &=
                            \begin{cases}
                            f(Wh_{i-1}) & \text{where } i > 1 \\
                            f(Ux_1 + Wh_0) & \text{where } i = 1
                            \end{cases}
                            \end{aligned}\]</span>
                        <p>类似地，第二种结构计算方法如下：</p>
                        <span class = "math inline"></span>
                        <li><strong> N to M结构RNN模型</strong></li>
                        <p>即输入及输出序列不等长的结构。N和M分别为输入序列长度及输出序列长度，该结构我们采用一个N to 1结构RNN及一个1 to M结构组合来实现，详细结构如下图：</p>
                        <image class="educationImage" src="resources/educationimages/RNN_9.png"  alt="RNN_9" ></image>
                        <p> 由上图可以看出，将两个不同长度的RNN进行组合，能够控制模型的输出序列长度。在两个模型之间，增加了一个上下文向量，由第一个RNN模型的输出计算得来，向量包含着输入序列的语义信息与序列信息。在上图中是将上下文向量作为了第二个RNN模型的输入数据，并在第二个RNN模型对于初始隐藏变量进行随机初始化。通常将第一个RNN称为encoder（编码器），第二个RNN称为decoder（解码器）此外，还可以利用上下文向量对第二个RNN模型的隐藏变量进行初始化，结构如下：</p>
                        <image class="educationImage" src="resources/educationimages/RNN_10.png"  alt="RNN_10" ></image>
                        <p>通过N to M结构RNN模型，可以适应各类序列处理任务，常见的如机器翻译、语音识别、文本摘要及阅读理解等任务。由于输入输出都是序列，该模型也称为seq2seq模型。常用的上下文向量的计算方法包含如下三种：</p>
                        <span class = "math inline"></span>
                        <p> 其中，第一种计算方法为直接将encoder的输出作为上下文向量；第二种计算方法为通过变化encoder的输出计算得到；第三种计算方法为利用一个encoder的输出序列计算得到。此外，由于encoder的输出只变换成 上下文向量传入decoder进行了计算，难免造成decoder计算序列加长导致的上下文信息衰减。由此，人们引入了注意力机制（Attention）来增强数据信息，我们在attention机制部分进行详解。</p>

                    </ol>
                    <div class ="educationSection">（四）梯度爆炸和梯度消失</div>
                    <ol>
                        <li><strong>什么是梯度爆炸和梯度消失</strong></li>
                        <p>就其输入而言，梯度是偏导数，梯度量化了当输入稍微改变时函数的输出变化的程度。函数的斜率也称为梯度。斜率越陡，模型学习的速度越快，梯度就越高。另一方面，如果斜率为零，模型将停止学习。梯度用于测量所有权重相对于误差变化的变化。</p>
                        <image class="educationImage" src="resources/educationimages/RNN_11.png"  alt="RNN_11" ></image>
                        <ul>
                            <li><strong>梯度爆炸：</strong>当算法无缘无故地给权重赋予荒谬的高优先级时，就会发生梯度爆炸。幸运的是，截断或压缩梯度是解决此问题的简单方法。</li>
                            <li><strong>梯度消失：</strong>当梯度值太小时，就会发生梯度消失，导致模型停止学习或花费太长时间。这是 20 世纪 90 年代的一个大问题，而且它比梯度爆炸更难解决。</li>

                        </ul>
                        <li><strong>如何解决RNN的梯度爆炸或梯度消失</strong></li>
                        <ul>
                            <li><strong>解决梯度爆炸：</strong>梯度裁剪，即为梯度更新时的梯度设置上限，当超过阈值将强制裁剪，避免出现过高阈值。</li>
                            <li><strong>解决梯度消失：</strong>使用Relu激活函数解决梯度消失的原理是，Relu函数在自变量大于0是，因变量恒为1，由此避免梯度过小；改用变种版本的RNN结构，常见的包括LSTM模型及GRU模型。</li>

                        </ul>
                    </ol>
                    <div class ="educationSection">（五）RNN优缺点</div>
                    <ol>
                        <li><strong>RNN的优点</strong></li>
                        <ul>
                            <li>有效处理顺序数据，包括文本、语音和时间序列。</li>
                            <li>与前馈神经网络不同，处理任意长度的输入。</li>
                            <li>跨时间步共享权重，提高训练效率。</li>
                        </ul>
                        <li><strong>RNN的缺点</strong></li>
                        <ul>
                            <li>容易出现梯度消失和爆炸问题，阻碍学习。</li>
                            <li>训练可能具有挑战性，尤其是对于长序列。</li>
                            <li>计算速度比其他神经网络架构慢。</li>
                        </ul>
                    </ol>

                    <div class = "educationSection">（六）RNN实战</div>
                    <ol>
                        <li>理论实现</li>
                        <ul>
                            <li>输入层</li>
                            <ol>
                                <li><strong>当前事件输入：</strong>记为<span class ="math inline">\(\mathbf{x}_{\mathbf{t}}\)</span>，表示在时间t输入的数据。</li>
                                <li><strong>隐藏状态（记忆）：</strong>记为\(\mathbf{h}_{\mathbf{t-1}}\)，表示从前一个时间步<span class ="math inline">\(t-1\)</span>传递下来的隐藏状态，包含历史信息。</li>
                            </ol>
                            <li>隐藏层</li>
                            <p>RNN的核心是通过隐藏状态来保持之前时间步的信息，并与当前的输入结合。标准RNN隐藏层的更新公式如下：</p>
                            <span class ="math inline">\[\mathrm{h}_t=\phi(W_\mathrm{h}\mathrm{h}_{t-1}+W_xx_t+b_\mathrm{h})\]</span>
                            <p><span class ="math inline">\(W_h\)</span>:隐藏层权重矩阵，用于调整前一时间步的隐藏状态<span class ="math inline">\(h_t-1\)</span>的影响。</p>
                            <p><span class ="math inline">\(W_x\)</span>:：输入权重矩阵，用于调整当前输入<span class ="math inline">\(x_t\)</span>的影响。</p>
                            <p><span class ="math inline">\(b_h\)</span>:偏置项，用于对输出进行平移。</p>
                            <p><span class ="math inline">\(phi)</span>：激活函数，通常选择<span class ="math inline">\(\text{tanh}\)</span>的影响。或 ReLU激活函数，使得网络具有非线性表达能力。
                                该更新公式的核心是将历史隐藏状态和当前输入线性组合，再通过激活函数更新为当前时间步的隐藏状态<span class ="math inline">\(h_t\)</span>。每一时间步都会执行该更新，使得RNN可以逐步积累时间序列信息。
                            </p>
                            <li>输出层</li>
                            <p>输出层根据隐藏状态生成每个时间步的输出 <span class ="math inline">\(o_t\)</span>：<span class ="math inline">\(o_t=W_0h_t+b_0\)</span></p>
                            <p><span class ="math inline">\(W_o\)</span>：输出层权重矩阵，将隐藏状态映射到输出空间。</p>
                            <p><span class ="math inline">\(b_o\)</span>：输出层偏置项。</p>
                            <p>RNN的输出可以是每个时间步的输出（适合序列输出）或最终时间步的隐藏状态（适合序列分类）。</p>
                            <li>前向传播过程</li>
                            <p>标准RNN的前向传播过程是一个循环递归的过程。RNN层会从 t=1t=1t=1 一直传播到 TTT（时间步数），逐步计算每个时间步的隐藏状态和输出。这种递归使得RNN能够在较短的时间序列中捕捉依赖关系。</p>

                        </ul>
                        <li>代码实现</li>
                        <p>RNN及其变体是非常经典且有意义的工作，故代码实现有多种方式，总体来说分为自购建与API调用。</p>
                        <image class="educationImage" src="resources/educationimages/RNN_12.png"  alt="RNN_12" ></image>
                        <ul>
                            <li><strong>自构建</strong></li>
                            <ol>
                                <li><strong>独热编码：</strong>即NLP中的基本操作one-hot encoding，将文本预处理（string->num），并将索引映射为互补相同的单位向量，方便后续模型读入。</li>
                                <li><strong>初始化模型参数：</strong>需要定义隐藏层参数（重要）、输出层参数、附加梯度等模型参数。</li>
                                <li><strong>模型/网络定义：</strong>根据需求与RNN定义去搭建模型，包括隐状态返回（初始化时）、计算与输出，以及模型的激活与迭代。</li>
                                <li><strong>预测：</strong>定义预测函数来生成prefix（一个用户提供的包含多个字符的字符串）之后的新字符。</li>
                                <li><strong>梯度裁剪：</strong>正常的RNN反向传播会产生O（T）的矩阵乘法链，T较大时可能导致梯度爆炸或消失，故需要进行梯度裁剪。</li>
                                <li><strong>训练：</strong>将处理后数据"喂"给模型，进行迭代训练（顺序分区/随机抽样），以困惑度或epoch作为停止训练指标。</li>
                                <li><strong>输出：</strong>训练好的模型/文本预测结果</li>
                            </ol>
                            <li><strong>API调用</strong></li>
                            <p>自购建的方式可以实现不同方案/策略的RNN，但无论是代码实现难度、效率/性能都不是最优选择，由于RNN类模型是经典模型，故Tensorflow、Pytorch等主流框架中均做了定义（API）与优化，便于我们快速搭建模型并应用，通过API的代码实现非常简洁，全流程为数据集读入->模型定义/引入（通过API）->训练与预测。代码核心即模型的引入。</p>
                        </ul>

                    </ol>

                </div>
            </div>

            <div id = "educationnewRNN">
                <div class="educationTitle">现代循环神经网络</div>
                <div class="educationContent">
                    <div class="educationSection">（一）概述</div>
                    <p>在上一章中，我们介绍了如何利用循环神经网络（RNN）来建立语言模型以处理文本数据。然而，面对当今日益复杂的序列学习任务，传统RNN模型可能会遇到一些困难。一个突出的问题是数值不稳定性，特别是在长序列数据中，RNN模型的梯度很容易发生消失或爆炸，使得模型难以有效学习长时依赖。尽管我们可以通过梯度裁剪等技巧来缓解这个问题，但它们并不能完全解决问题。为此，我们需要引入一些更强大的模型设计，来让RNN更具表现力和稳定性。本章将按顺序介绍以下网络结构：</p>
                    <ol>
                        <li><strong>GRU（门控循环单元）：</strong>GRU是一种改进的RNN结构，利用更新门和重置门来控制信息流，简化了长时依赖的处理，使训练更高效。</li>
                        <li><strong>LSTM（长短期记忆网络）：</strong>LSTM通过引入遗忘门、输入门和输出门，能够更有效地捕捉长时依赖关系，适合处理长序列数据。</li>
                        <li><strong>深度RNN：</strong>深度RNN由多层隐藏层堆叠而成，使模型能够逐层捕捉更复杂的序列特征，提升模型的表达能力。</li>
                        <li><strong>双向RNN：</strong>双向RNN通过同时进行正向和反向计算，可以结合前后文信息，使得模型在处理自然语言任务时更具上下文感知能力。</li>
                        <li><strong>Transformer：</strong>Transformer采用自注意力机制，允许模型在序列的任意位置间建立直接依赖关系，从而高效处理长序列，极大提升了训练速度和并行计算能力。</li>
                    </ol>

                </div>
                <!-- 新增的做题链接部分 -->
                <div class="exercise-section">
                    <!-- RNN练习区域 - 卡片式布局 -->
                    <div class="learning-exercises">
                        <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">🔄 RNN练习区</h3>
                        <p style="text-align: center; color: #666; margin-bottom: 30px;">学习循环神经网络的原理和应用</p>

                        <div class="exercise-cards">
                            <!-- 循环神经网络测试卡片 -->
                            <div class="exercise-card" data-exercise="rnn_quiz">
                                <div class="card-header">
                                    <h4>🔁 循环神经网络测试</h4>
                                    <div class="progress-indicator">
                                        <span class="progress-text">未完成</span>
                                        <div class="progress-bar">
                                            <div class="progress-fill" style="width: 0%"></div>
                                        </div>
                                    </div>
                                </div>
                                <div class="card-content">
                                    <p>测试您对RNN基本概念和循环机制的理解。</p>
                                    <button class="start-exercise-btn">开始练习</button>
                                </div>
                                <div class="card-questions" style="display: none;">
                                    <div class="question">
                                        <p><strong>题目1:</strong> RNN与传统神经网络的主要区别是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="rnn_q1" value="A"> A. 有隐藏状态</label>
                                            <label><input type="radio" name="rnn_q1" value="B"> B. 处理序列数据</label>
                                            <label><input type="radio" name="rnn_q1" value="C"> C. 参数共享</label>
                                            <label><input type="radio" name="rnn_q1" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目2:</strong> RNN的隐藏状态包含什么信息？</p>
                                        <div class="options">
                                            <label><input type="radio" name="rnn_q2" value="A"> A. 当前输入</label>
                                            <label><input type="radio" name="rnn_q2" value="B"> B. 历史信息</label>
                                            <label><input type="radio" name="rnn_q2" value="C"> C. 未来信息</label>
                                            <label><input type="radio" name="rnn_q2" value="D"> D. 随机噪声</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目3:</strong> RNN面临的主要问题是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="rnn_q3" value="A"> A. 梯度消失</label>
                                            <label><input type="radio" name="rnn_q3" value="B"> B. 梯度爆炸</label>
                                            <label><input type="radio" name="rnn_q3" value="C"> C. 长期依赖</label>
                                            <label><input type="radio" name="rnn_q3" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目4:</strong> RNN的参数共享有什么优势？</p>
                                        <div class="options">
                                            <label><input type="radio" name="rnn_q4" value="A"> A. 减少参数量</label>
                                            <label><input type="radio" name="rnn_q4" value="B"> B. 处理变长序列</label>
                                            <label><input type="radio" name="rnn_q4" value="C"> C. 模型泛化</label>
                                            <label><input type="radio" name="rnn_q4" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目5:</strong> RNN最适合解决哪类问题？</p>
                                        <div class="options">
                                            <label><input type="radio" name="rnn_q5" value="A"> A. 图像分类</label>
                                            <label><input type="radio" name="rnn_q5" value="B"> B. 序列预测</label>
                                            <label><input type="radio" name="rnn_q5" value="C"> C. 目标检测</label>
                                            <label><input type="radio" name="rnn_q5" value="D"> D. 图像生成</label>
                                        </div>
                                    </div>

                                    <div class="card-actions">
                                        <button class="submit-btn" data-category="rnn_quiz">提交答案</button>
                                        <button class="close-exercise-btn">收起练习</button>
                                    </div>
                                </div>
                            </div>

                            <!-- 序列建模练习卡片 -->
                            <div class="exercise-card" data-exercise="sequence_modeling">
                                <div class="card-header">
                                    <h4>📈 序列建模练习</h4>
                                    <div class="progress-indicator">
                                        <span class="progress-text">未完成</span>
                                        <div class="progress-bar">
                                            <div class="progress-fill" style="width: 0%"></div>
                                        </div>
                                    </div>
                                </div>
                                <div class="card-content">
                                    <p>练习RNN在序列数据建模中的应用。</p>
                                    <button class="start-exercise-btn">开始练习</button>
                                </div>
                                <div class="card-questions" style="display: none;">
                                    <div class="question">
                                        <p><strong>题目1:</strong> 什么是Many-to-One架构？</p>
                                        <div class="options">
                                            <label><input type="radio" name="seq_q1" value="A"> A. 输入序列，输出序列</label>
                                            <label><input type="radio" name="seq_q1" value="B"> B. 输入序列，输出单个值</label>
                                            <label><input type="radio" name="seq_q1" value="C"> C. 输入单个值，输出序列</label>
                                            <label><input type="radio" name="seq_q1" value="D"> D. 输入和输出都是序列</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目2:</strong> 文本分类属于哪种序列建模任务？</p>
                                        <div class="options">
                                            <label><input type="radio" name="seq_q2" value="A"> A. Many-to-Many</label>
                                            <label><input type="radio" name="seq_q2" value="B"> B. Many-to-One</label>
                                            <label><input type="radio" name="seq_q2" value="C"> C. One-to-Many</label>
                                            <label><input type="radio" name="seq_q2" value="D"> D. One-to-One</label>
                                        </div>
                                    </div>
				    <div class="educationTitle">注意力机制（Transformer）</div>
					<div class="educationContent">
						<p>在过去几年中，Transformer 模型已经成为高级深度学习和深度神经网络领域的热门话题。自从其在 2017 年被引入以来，Transformer 深度学习模型架构已经在几乎所有可能的领域中得到了广泛应用和演进。该模型不仅在自然语言处理任务中表现出色，还对于其他领域，尤其是时间序列预测方面，也具有巨大的帮助和潜力。</p>
						<p>Transformer 模型是一种深度学习架构，自 2017 年推出以来，彻底改变了自然语言处理 (NLP) 领域。该模型由 Vaswani 等人提出，并已成为 NLP 界最具影响力的模型之一。</p>
						<p>通常而言，传统的顺序模型（例如循环神经网络 (RNN)）在捕获远程依赖性和实现并行计算方面存在局限性。为了解决这些问题，Transformer 模型引入了自注意力机制，通过广泛使用该机制，模型能够在生成输出时权衡输入序列中不同位置的重要性。</p>
			            <p>Transformer 模型通过自注意力机制和并行计算的优势，能够更好地处理长距离依赖关系，提高了模型的训练和推理效率。它在机器翻译、文本摘要、问答系统等多个 NLP 任务中取得了显著的性能提升。</p>
						<p>除此之外，Transformer 模型的突破性表现使得它成为现代 NLP 研究和应用中的重要组成部分。它能够捕捉复杂的语义关系和上下文信息，极大地推动了自然语言处理的发展。</p>
						<div class="educationSection">Transformer 模型历史发展</div>
						<p>Transformer 在神经网络中的历史可以追溯到20世纪90年代初，当时 Jürgen Schmidhuber 提出了第一个 Transformer 模型的概念。这个模型被称为"快速权重控制器"，它采用了自注意力机制来学习句子中单词之间的关系。然而，尽管这个早期的 Transformer 模型在概念上是先进的，但由于其效率较低，它并未得到广泛的应用。</p>
						<p>随着时间的推移和深度学习技术的发展，Transformer 在2017年的一篇开创性论文中被正式引入，并取得了巨大的成功。通过引入自注意力机制和位置编码层，有效地捕捉输入序列中的长距离依赖关系，并且在处理长序列时表现出色。此外，Transformer 模型的并行化计算能力也使得训练速度更快，推动了深度学习在自然语言处理领域的重大突破，如机器翻译任务中的BERT（Bidirectional Encoder Representations from Transformers）模型等。</p>
						<p>因此，尽管早期的"快速权重控制器"并未受到广泛应用，但通过 Vaswani 等人的论文，Transformer 模型得到了重新定义和改进，成为现代深度学习的前沿技术之一，并在自然语言处理等领域取得了令人瞩目的成就。</p>
			    	    <p> Transformer 之所以如此成功，是因为它能够学习句子中单词之间的长距离依赖关系，这对于许多自然语言处理（NLP）任务至关重要，因为它允许模型理解单词在句子中的上下文。Transformer 利用自注意力机制来实现这一点，该机制使得模型在解码输出标记时能够聚焦于句子中最相关的单词。</p>
						<p>Transformer 对 NLP 领域产生了重大影响。它现在被广泛应用于许多 NLP 任务，并且不断进行改进。未来，Transformer 很可能被用于解决更广泛的 NLP 任务，并且它们将变得更加高效和强大。</p>
						<p>有关神经网络 Transformer 历史上的一些关键发展事件，我们可参考如下所示：</p>
						<li>1、1990年：Jürgen Schmidhuber 提出了第一个 Transformer 模型，即"快速权重控制器"。</li>
						<li>2、2017年：Vaswani 等人发表了论文《Attention is All You Need》，介绍了 Transformer 模型的核心思想。</li>
						<li>3、2018年：Transformer 模型在各种 NLP 任务中取得了最先进的结果，包括机器翻译、文本摘要和问答等。</li>
						<li>4、2019年：Transformer 被用于创建大型语言模型（LLM），例如 BERT 和 GPT-2，这些模型在各种 NLP 任务中取得了重要突破。</li>
						<li> 5、2020年：Transformer 继续被用于创建更强大的模型，例如 GPT-3，它在自然语言生成和理解方面取得了惊人的成果。</li>
						<p>总的来说，Transformer 模型的引入对于 NLP 领域产生了革命性的影响。它的能力在于学习长距离依赖关系并理解上下文，使得它成为众多 NLP 任务的首选方法，并为未来的发展提供了广阔的可能性。</p>
						<div class="educationSection">Transformer 模型通用架构设计</div>
						<p>Transformer 架构是从 RNN（循环神经网络）的编码器-解码器架构中汲取灵感而来，其引入了注意力机制。它被广泛应用于序列到序列（seq2seq）任务，并且相比于 RNN， Transformer 摒弃了顺序处理的方式。</p>
						<p>不同于 RNN，Transformer 以并行化的方式处理数据，从而实现更大规模的并行计算和更快速的训练。这得益于 Transformer 架构中的自注意力机制，它使得模型能够同时考虑输入序列中的所有位置，而无需按顺序逐步处理。自注意力机制允许模型根据输入序列中的不同位置之间的关系，对每个位置进行加权处理，从而捕捉全局上下文信息。</p>
						<image class="educationImage" src="resources/educationimages/transformer_1.png"  alt="transformer_1" ></image>
						<p>基于如上的 Transformer 深度学习模型的整体架构参考模型图，我们可以看到：它由两个主要组件组成：</p>
						<li><strong> 1、编码器堆栈 </strong></li>
						<p>这是由 Nx 个相同的编码器层组成的堆栈（在原始论文中，Nx=6）。每个编码器层都由两个子层组成：多头自注意力机制和前馈神经网络。多头自注意力机制用于对输入序列中的不同位置之间的关系进行建模，而前馈神经网络则用于对每个位置进行非线性转换。编码器堆栈的作用是将输入序列转换为一系列高级特征表示。</p>
						<li><strong> 2、解码器堆栈 </strong></li>
						<p>这也是由 Nx 个相同的解码器层组成的堆栈（在原始论文中，Nx=6）。每个解码器层除了包含编码器层的两个子层外，还包含一个额外的多头自注意力机制子层。这个额外的自注意力机制用于对编码器堆栈的输出进行关注，并帮助解码器对输入序列中的信息进行解码和生成输出序列。</p>
						<p>在编码器和解码器堆栈之间，还有一个位置编码层。这个位置编码层的作用是利用序列的顺序信息，为输入序列中的每个位置提供一个固定的编码表示。这样，模型可以在没有递归或卷积操作的情况下，利用位置编码层来处理序列的顺序信息。</p>
						<div class="educationSection">什么是 Transformer 神经网络？</div>
						<p>众所周知，Transformer 在处理文本序列、基因组序列、声音和时间序列数据等神经网络设计中起着关键作用。其中，自然语言处理是 Transformer 神经网络最常见的应用领域。</p>
						<p>当给定一个向量序列时，Transformer 神经网络会对这些向量进行编码，并将其解码回原始形式。而 Transformer 的注意力机制则是其不可或缺的核心组成部分。注意力机制表明了在输入序列中，对于给定标记的编码，其周围其他标记的上下文信息的重要性。</p>
					    <P>打个比方，在机器翻译模型中，注意力机制使得 Transformer 能够根据所有相关单词的上下文，将英语中的"it"正确翻译为法语或西班牙语中的性别对应的词汇。 Transformers 能够利用注意力机制来确定如何翻译当前单词，同时考虑其周围单词的影响。</P>
						<p>然而，需要注意的是，Transformer 神经网络取代了早期的循环神经网络（RNN）、长短期记忆（LSTM）和门控循环单元（GRU）等模型，成为了更为先进和有效的选择。</p>
						<p>通常而言，Transformer 神经网络接受输入句子并将其编码为两个不同的序列：</p>
						<li><strong>1、词向量嵌入序列</strong></li>
						<p>词向量嵌入是文本的数字表示形式。在这种情况下，神经网络只能处理转换为嵌入表示的单词。字典中的单词在嵌入表示中表示为向量。</p>
						<li><strong>2、位置编码器序列</strong></li>
						<p>位置编码器将原始文本中单词的位置表示为向量。Transformer 将词向量嵌入和位置编码结合起来。然后，它将组合结果发送到各个编码器，然后是解码器。</p>
						<p>与 RNN 和 LSTM 按顺序提供输入不同，Transformer 同时提供输入。每个编码器将其输入转换为另一个向量序列，称为编码。</p>
						<p>解码器以相反的顺序工作。它将编码转换回概率，并根据概率生成输出单词。通过使用 softmax 函数，Transformer 可以根据输出概率生成句子。</p>
						<p>每个解码器和编码器中都有一个称为注意力机制的组件。它允许一个输入单词使用其他单词的相关信息进行处理，同时屏蔽不包含相关信息的单词。</p>
						<p>为了充分利用 GPU 提供的并行计算能力，Transformer 使用多头注意力机制进行并行实现。多头注意力机制允许同时处理多个注意力机制，从而提高计算效率。</p>
						<p>相比于 LSTM 和 RNN，Transformer 深度学习模型的优势之一是能够同时处理多个单词。这得益于 Transformer 的并行计算能力，使得它能够更高效地处理序列数据。</p>
                    </div>

				
			</div>
        
						<div class="educationTitle">激活函数</div>
                        <p>激活函数为神经网络引入了非线性，使其能够学习并模拟复杂的数据模式。没有它，神经网络就只是一堆线性回归的堆叠。</p>
			<div id="educationReLU">
				 <div class="educationTitle">ReLU-线性整流函数</div>
				 <div class="educationContent">
					    <p><strong>公式：</strong>f(x) = max(0, x)</p>
					    <p><strong>特点：</strong>目前最常用的激活函数。计算简单，能有效缓解梯度消失问题。</p>
						<p><strong>缺点：</strong>在输入为负数时，梯度为零，可能导致“神经元死亡”。</p>
				 </div>
			</div>

			<div id="educationSigmoid">
				 <div class="educationTitle">Sigmoid</div>
				 <div class="educationContent">
					<p><strong>公式：</strong>f(x) = 1 / (1 + e^(-x))</p>
					<p><strong>特点：</strong>将输入压缩到(0, 1) 区间。输出可以解释为概率。</p>
					<p><strong>用途：</strong>常用于二分类问题的输出层。</p>
					<p><strong>缺点：</strong>两端饱和区容易导致梯度消失；输出不是零中心的。</p>
				 </div>
			</div>

			<div id="educationTanh">
				 <div class="educationTitle">Tanh-双曲正切函数</div>
				 <div class="educationContent">
					<p><strong>公式：</strong>f(x) = (e^x - e^(-x)) / (e^x + e^(-x))</p>
					<p><strong>特点：</strong>将输入压缩到(-1, 1) 区间。是零中心的。</p>
					<p><strong>用途：</strong>常通常比Sigmoid表现更好，尤其在隐藏层中。</p>
					<p><strong>缺点：</strong>两端饱和区容易导致梯度消失；输出不是零中心的。</p>
				 </div>
			</div>
			<div id="educationSoftmax">
				 <div class="educationTitle">Softmax</div>
				 <div class="educationContent">
					<p><strong>核心作用:</strong></p>
					<li>1.将任意实数值的分数转换为概率分布。</li>
					<li>2.放大分数间的差异，使得最大值在概率上更加突出。</li>
					<p><strong>公式：</strong></p>
					<p>对于一个包含K个类别的向量<span class="math inline">\(Z=[z_1,z_2,...,z_K]\)</span>Softmax的计算如下：</p>
					<p><span class="math inline">\[\sigma(z_i)=e^{z_i}/{\sum_{j=1}^{K}e^{z_{j}}}\]</span></p>
					<p><strong>结果解释：</strong></p>
					<li>每个经过 Softmax处理后的输出<span class="math inline">\(\sigma(z_i)\)</span>都是一个介于0和1之间的值。</li>
					<li>所有输出的总和为1</li>
					<li>因此，输出可以被解释为每个类别的概率。</li>
				 </div>
			</div>



			<div id="educationempty">
				 <div class="educationTitle">       </div>
				 <div class="educationContent">
					<p>    </p>
					<p>    </p>
					<p>    </p>
					<p>    </p>
					<p>    </p>
					
				 </div>
			</div>

                                    <div class="question">
                                        <p><strong>题目3:</strong> 语言模型的目标是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="seq_q3" value="A"> A. 预测下一个词</label>
                                            <label><input type="radio" name="seq_q3" value="B"> B. 分类文本</label>
                                            <label><input type="radio" name="seq_q3" value="C"> C. 生成摘要</label>
                                            <label><input type="radio" name="seq_q3" value="D"> D. 翻译文本</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目4:</strong> 序列到序列模型通常用于？</p>
                                        <div class="options">
                                            <label><input type="radio" name="seq_q4" value="A"> A. 机器翻译</label>
                                            <label><input type="radio" name="seq_q4" value="B"> B. 文本分类</label>
                                            <label><input type="radio" name="seq_q4" value="C"> C. 图像分类</label>
                                            <label><input type="radio" name="seq_q4" value="D"> D. 目标检测</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目5:</strong> RNN处理变长序列的优势是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="seq_q5" value="A"> A. 固定输入大小</label>
                                            <label><input type="radio" name="seq_q5" value="B"> B. 动态处理长度</label>
                                            <label><input type="radio" name="seq_q5" value="C"> C. 减少计算量</label>
                                            <label><input type="radio" name="seq_q5" value="D"> D. 提高准确率</label>
                                        </div>
                                    </div>

                                    <div class="card-actions">
                                        <button class="submit-btn" data-category="sequence_modeling">提交答案</button>
                                        <button class="close-exercise-btn">收起练习</button>
                                    </div>
                                </div>
                            </div>

                            <!-- BPTT计算卡片 -->
                            <div class="exercise-card" data-exercise="bptt_calculation">
                                <div class="card-header">
                                    <h4>🧮 BPTT计算</h4>
                                    <div class="progress-indicator">
                                        <span class="progress-text">未完成</span>
                                        <div class="progress-bar">
                                            <div class="progress-fill" style="width: 0%"></div>
                                        </div>
                                    </div>
                                </div>
                                <div class="card-content">
                                    <p>理解通过时间反向传播的原理和计算过程。</p>
                                    <button class="start-exercise-btn">开始练习</button>
                                </div>
                                <div class="card-questions" style="display: none;">
                                    <div class="question">
                                        <p><strong>题目1:</strong> BPTT代表什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="bptt_q1" value="A"> A. Backpropagation Through Time</label>
                                            <label><input type="radio" name="bptt_q1" value="B"> B. Backpropagation Through Training</label>
                                            <label><input type="radio" name="bptt_q1" value="C"> C. Backpropagation Through Tasks</label>
                                            <label><input type="radio" name="bptt_q1" value="D"> D. Backpropagation Through Testing</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目2:</strong> BPTT如何处理梯度累积？</p>
                                    <div class="options">
                                            <label><input type="radio" name="bptt_q2" value="A"> A. 沿时间展开网络</label>
                                            <label><input type="radio" name="bptt_q2" value="B"> B. 反向传播梯度</label>
                                            <label><input type="radio" name="bptt_q2" value="C"> C. 更新所有时间步</label>
                                            <label><input type="radio" name="bptt_q2" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目3:</strong> 梯度消失在BPTT中如何表现？</p>
                                        <div class="options">
                                            <label><input type="radio" name="bptt_q3" value="A"> A. 梯度变为0</label>
                                            <label><input type="radio" name="bptt_q3" value="B"> B. 早期时间步梯度小</label>
                                            <label><input type="radio" name="bptt_q3" value="C"> C. 无法学习长期依赖</label>
                                            <label><input type="radio" name="bptt_q3" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目4:</strong> 截断BPTT的目的是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="bptt_q4" value="A"> A. 减少内存占用</label>
                                            <label><input type="radio" name="bptt_q4" value="B"> B. 防止梯度消失</label>
                                            <label><input type="radio" name="bptt_q4" value="C"> C. 加速训练</label>
                                            <label><input type="radio" name="bptt_q4" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目5:</strong> BPTT的时间复杂度是多少？</p>
                                        <div class="options">
                                            <label><input type="radio" name="bptt_q5" value="A"> A. O(T)</label>
                                            <label><input type="radio" name="bptt_q5" value="B"> B. O(T²)</label>
                                            <label><input type="radio" name="bptt_q5" value="C"> C. O(T³)</label>
                                            <label><input type="radio" name="bptt_q5" value="D"> D. O(log T)</label>
                                        </div>
                                    </div>

                                    <div class="card-actions">
                                        <button class="submit-btn" data-category="bptt_calculation">提交答案</button>
                                        <button class="close-exercise-btn">收起练习</button>
                                    </div>
                                </div>
                            </div>

                            <!-- RNN架构设计卡片 -->
                            <div class="exercise-card" data-exercise="rnn_architectures">
                                <div class="card-header">
                                    <h4>🏗️ RNN架构设计</h4>
                                    <div class="progress-indicator">
                                        <span class="progress-text">未完成</span>
                                        <div class="progress-bar">
                                            <div class="progress-fill" style="width: 0%"></div>
                                        </div>
                                    </div>
                                </div>
                                <div class="card-content">
                                    <p>学习不同RNN架构的设计理念和应用场景。</p>
                                    <button class="start-exercise-btn">开始练习</button>
                                </div>
                                <div class="card-questions" style="display: none;">
                                    <div class="question">
                                        <p><strong>题目1:</strong> 单向RNN的局限性是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="arch_rnn_q1" value="A"> A. 只能从左到右</label>
                                            <label><input type="radio" name="arch_rnn_q1" value="B"> B. 无法利用未来信息</label>
                                            <label><input type="radio" name="arch_rnn_q1" value="C"> C. 计算效率低</label>
                                            <label><input type="radio" name="arch_rnn_q1" value="D"> D. A和B都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目2:</strong> 双向RNN的优势是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="arch_rnn_q2" value="A"> A. 利用上下文信息</label>
                                            <label><input type="radio" name="arch_rnn_q2" value="B"> B. 提高预测准确率</label>
                                            <label><input type="radio" name="arch_rnn_q2" value="C"> C. 处理序列标注任务</label>
                                            <label><input type="radio" name="arch_rnn_q2" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目3:</strong> 深层RNN面临什么问题？</p>
                                        <div class="options">
                                            <label><input type="radio" name="arch_rnn_q3" value="A"> A. 梯度消失</label>
                                            <label><input type="radio" name="arch_rnn_q3" value="B"> B. 训练困难</label>
                                            <label><input type="radio" name="arch_rnn_q3" value="C"> C. 计算复杂</label>
                                            <label><input type="radio" name="arch_rnn_q3" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目4:</strong> 多层RNN如何堆叠？</p>
                                        <div class="options">
                                            <label><input type="radio" name="arch_rnn_q4" value="A"> A. 共享参数</label>
                                            <label><input type="radio" name="arch_rnn_q4" value="B"> B. 独立参数</label>
                                            <label><input type="radio" name="arch_rnn_q4" value="C"> C. 时间步内堆叠</label>
                                            <label><input type="radio" name="arch_rnn_q4" value="D"> D. 序列间堆叠</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目5:</strong> RNN的输出形式有哪些？</p>
                                        <div class="options">
                                            <label><input type="radio" name="arch_rnn_q5" value="A"> A. 每个时间步输出</label>
                                            <label><input type="radio" name="arch_rnn_q5" value="B"> B. 最后时间步输出</label>
                                            <label><input type="radio" name="arch_rnn_q5" value="C"> C. 连接所有输出</label>
                                            <label><input type="radio" name="arch_rnn_q5" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="card-actions">
                                        <button class="submit-btn" data-category="rnn_architectures">提交答案</button>
                                        <button class="close-exercise-btn">收起练习</button>
                                    </div>
                                </div>
                            </div>

                            <!-- 时间依赖分析卡片 -->
                            <div class="exercise-card" data-exercise="temporal_dependencies">
                                <div class="card-header">
                                    <h4>⏰ 时间依赖分析</h4>
                                    <div class="progress-indicator">
                                        <span class="progress-text">未完成</span>
                                        <div class="progress-bar">
                                            <div class="progress-fill" style="width: 0%"></div>
                                        </div>
                                    </div>
                                </div>
                                <div class="card-content">
                                    <p>分析RNN处理时间序列依赖关系的能力和局限性。</p>
                                    <button class="start-exercise-btn">开始练习</button>
                                </div>
                                <div class="card-questions" style="display: none;">
                                    <div class="question">
                                        <p><strong>题目1:</strong> 什么是长期依赖问题？</p>
                                        <div class="options">
                                            <label><input type="radio" name="temp_q1" value="A"> A. 无法记住远距离信息</label>
                                            <label><input type="radio" name="temp_q1" value="B"> B. 处理长序列困难</label>
                                            <label><input type="radio" name="temp_q1" value="C"> C. 梯度消失或爆炸</label>
                                            <label><input type="radio" name="temp_q1" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目2:</strong> RNN为什么适合处理序列数据？</p>
                                        <div class="options">
                                            <label><input type="radio" name="temp_q2" value="A"> A. 有记忆能力</label>
                                            <label><input type="radio" name="temp_q2" value="B"> B. 参数共享</label>
                                            <label><input type="radio" name="temp_q2" value="C"> C. 处理变长输入</label>
                                            <label><input type="radio" name="temp_q2" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目3:</strong> 在语言模型中，RNN如何预测下一个词？</p>
                                        <div class="options">
                                            <label><input type="radio" name="temp_q3" value="A"> A. 只用当前词</label>
                                            <label><input type="radio" name="temp_q3" value="B"> B. 利用上下文</label>
                                            <label><input type="radio" name="temp_q3" value="C"> C. 随机选择</label>
                                            <label><input type="radio" name="temp_q3" value="D"> D. 使用词频</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目4:</strong> 时间序列预测中，RNN的优势是什么？</p>
                                        <div class="options">
                                            <label><input type="radio" name="temp_q4" value="A"> A. 捕捉时间模式</label>
                                            <label><input type="radio" name="temp_q4" value="B"> B. 处理非线性关系</label>
                                            <label><input type="radio" name="temp_q4" value="C"> C. 适应序列长度变化</label>
                                            <label><input type="radio" name="temp_q4" value="D"> D. 以上都是</label>
                                        </div>
                                    </div>

                                    <div class="question">
                                        <p><strong>题目5:</strong> RNN在处理什么类型的数据时表现最好？</p>
                                        <div class="options">
                                            <label><input type="radio" name="temp_q5" value="A"> A. 有序序列</label>
                                            <label><input type="radio" name="temp_q5" value="B"> B. 无序集合</label>
                                            <label><input type="radio" name="temp_q5" value="C"> C. 固定长度数据</label>
                                            <label><input type="radio" name="temp_q5" value="D"> D. 静态图像</label>
                                        </div>
                                    </div>

                                    <div class="card-actions">
                                        <button class="submit-btn" data-category="temporal_dependencies">提交答案</button>
                                        <button class="close-exercise-btn">收起练习</button>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div id = "educationnewRNN">
                <div class="educationTitle">现代循环神经网络</div>
                <div class="educationContent">
                    <div class="educationSection">（一）概述</div>
                    <p>在上一章中，我们介绍了如何利用循环神经网络（RNN）来建立语言模型以处理文本数据。然而，面对当今日益复杂的序列学习任务，传统RNN模型可能会遇到一些困难。一个突出的问题是数值不稳定性，特别是在长序列数据中，RNN模型的梯度很容易发生消失或爆炸，使得模型难以有效学习长时依赖。尽管我们可以通过梯度裁剪等技巧来缓解这个问题，但它们并不能完全解决问题。为此，我们需要引入一些更强大的模型设计，来让RNN更具表现力和稳定性。本章将按顺序介绍以下网络结构：</p>
                    <ol>
                        <li><strong>GRU（门控循环单元）：</strong>GRU是一种改进的RNN结构，利用更新门和重置门来控制信息流，简化了长时依赖的处理，使训练更高效。</li>
                        <li><strong>LSTM（长短期记忆网络）：</strong>LSTM通过引入遗忘门、输入门和输出门，能够更有效地捕捉长时依赖关系，适合处理长序列数据。</li>
                        <li><strong>深度RNN：</strong>深度RNN由多层隐藏层堆叠而成，使模型能够逐层捕捉更复杂的序列特征，提升模型的表达能力。</li>
                        <li><strong>双向RNN：</strong>双向RNN通过同时进行正向和反向计算，可以结合前后文信息，使得模型在处理自然语言任务时更具上下文感知能力。</li>
                        <li><strong>Transformer：</strong>Transformer采用自注意力机制，允许模型在序列的任意位置间建立直接依赖关系，从而高效处理长序列，极大提升了训练速度和并行计算能力。</li>

                    </ol>
                    <div class="educationSection">（二）门控循环单元（GRU）</div>
                    <p>GRU（门控循环单元）和LSTM（长短期记忆网络）是两种广泛应用的改进型RNN架构。它们通过引入“门”结构，允许模型更有效地控制信息流，选择性地保留或忘记特定信息。GRU和LSTM能缓解梯度消失问题，更好地捕捉长程依赖。GRU结构相对简单，计算速度快；而LSTM在处理更复杂的依赖关系时更具优势，因此这两种结构都成为序列建模中的重要工具，本节中讲介绍GRU单元。</p>
                    <p>GRU单元的工作方式类似一条“智能传送带”，它能根据需要对输入信息和隐藏状态进行“放行”或“拦截”操作，来过滤掉不重要的信息并保存旧的隐藏状态。具体来说，它通过重置门（reset gate）和更新门（update gate）来控制信息的流动，其中门机制都是带有激活函数的全连接层。</p>
                    <ol>
                        <li><strong>重置门</strong></li>
                        <p>重置门可以看作是一个“拦截”开关，它会根据当前输入内容来选择性地忘记部分旧隐藏状态的信息。如果重置门检测到某些过时的信息（比如过早的背景信息）可以忽略，它就会“清除”这些内容，削弱过去的影响，这样模型就可以更专注于新输入的数据。</p>
                        <span class = "math inline">\[\mathbf{R}_t=\sigma(\mathbf{X}_t\mathbf{W}_{xr}+\mathbf{H}_{t-1}\mathbf{W}_{hr}+\mathbf{b}_r)\]</span>
                        <ul>
                            <li><span class = "math inline">\(R_t\)</span>是重置门在时间步t的输出。</li>
                            <li>σ一般是Sigmoid激活函数，其输出范围在0到1之间。</li>
                            <li><span class = "math inline">\(\mathbf{W}_{xr}\)</span>和<span class = "math inline">\(\mathbf{W}_{hr}\)</span>分别是重置门的输入和递归权重矩阵。</li>
                            <li><span class = "math inline">\(H_t-1\)</span>是前一时刻的隐藏状态。</li>
                            <li><span class = "math inline">\(X_t\)</span>是当前时刻的输入。</li>
                        </ul>
                        <li><strong>更新门</strong></li>
                        <p>更新门负责决定当前时刻的输入信息和之前记忆中的隐藏状态信息，哪一部分应该被“放行”到下一步。换句话说，更新门会选择保留多少旧信息，以及吸收多少新信息，从而帮助GRU在新旧信息之间找到平衡。</p>
                        <span class = "math inline">\[\mathbf{Z}_t=\sigma(\mathbf{X}_t\mathbf{W}_{xz}+\mathbf{H}_{t-1}\mathbf{W}_{hz}+\mathbf{b}_z)\]</span>
                        <ul>
                            <li><span class = "math inline">\(Z_t\)</span>是更新门在时间步<span class = "math inline">\(t\)</span>的输出。</li>
                            <li><span class = "math inline">\(\mathbf{W}_{xz}\)</span>和<span class = "math inline">\(\mathbf{W}_{hz}\)</span>分别是更新门的输入和递归权重矩阵。</li>

                        </ul>
                        <li><strong>候选隐状态</strong></li>
                        <p>当输入一个新的数据时，GRU单元会让更新门和重置门协同工作，首先通过重置门基于当前输入和前一时刻隐藏状态计算得到候选隐藏状态， 每当重置门中的值接近1时，网络倾向于结合更多前面的记忆，效果更接近RNN。对于重置门中的值接近0，任何预先存在的隐状态都会被重置为默认值，效果更接近多层感知机。</p>
                        <span class = "math inline">\[\tilde{\mathcal{H}}_t=\tanh(\mathbf{X}_t\mathbf{W}_{x\mathbf{h}}+(\mathbf{R}_t\odot\mathbf{H}_{t-1})\mathbf{W}_{h\mathbf{h}}+\mathbf{b}_h)\]</span>
                        <ul>
                            <li><span class = "math inline">\(\tilde{\mathcal{H}}_t\)</span>是候选隐状态。</li>
                            <li><span class = "math inline">\(\tanh\)</span>是双曲正切激活函数，其输出范围在-1到1之间。</li>
                            <li><span class = "math inline">\(\mathbf{W}_{xh}\)</span>和<span class = "math inline">\(\mathbf{W}_{hh}\)</span>分别是候选隐状态的输入和递归权重矩阵。</li>
                            <li><span class = "math inline">\(\odot\)</span>表示逐元素乘法（Hadamard乘积）。</li>
                        </ul>
                        <li><strong>更新隐状态<span class = "math inline">\(H_t\)</span></strong></li>
                        <p>在最后一步，网络需要计算<span class = "math inline">\(H_t\)</span>，该向量将根据更新门<span class = "math inline">\(Z_t\)</span>决定当前隐藏状态
                            <span class = "math inline">\(H_t\)</span>的更新比例，即要更新多少新的隐藏状态，并传递到下一个单元中。在这个过程中，我们需要使用更新门，
                            它决定了当前记忆内容<span class = "math inline">\(\tilde{\mathcal{H}}_t\)</span>和前一时间步<span class = "math inline">\(H_t-1\)</span>中需要保留和收集的信息是什么。这一过程可以表示为：</p>
                            <span class = "math inline">\[\mathcal{H}_t=\mathbf{Z}_t\odot\mathbf{H}_{t-1}+(1-\mathbf{Z}_t)\odot\tilde{\mathbf{H}}_t\]</span>
                            <p>这个公式表明，当前时刻的隐藏状态是前一时刻的隐藏状态（通过更新门调整）和候选隐状态的线性组合。如果更新门
                                <span class = "math inline">\(Z_t\)</span>接近1，那么<span class = "math inline">\(H_t\)</span>将接近 <span class = "math inline">\(H_t-1\)</span>，
                                即前一时刻的隐藏状态将几乎不变地传递到当前时刻，完全忽略<span class = "math inline">\(X_t\)</span>的影响。如果更新门
                                <span class = "math inline">\(Z_t\)</span>接近0，那么 <span class = "math inline">\(H_t\)</span>将接近
                                <span class = "math inline">\(\tilde{\mathcal{H}}_t\)</span>，即当前时刻的隐藏状态将主要由候选隐状态决定。</p>
                                <image class="educationImage" src="resources/educationimages/newRNN_1.png"  alt="newRNN_1" ></image>

                    </ol>
                    <div class="educationSection">（三）长短期记忆网络（LSTM）</div>
                    <p>GRU（门控循环单元）和LSTM（长短期记忆网络）是两种广泛应用的改进型RNN架构。它们通过引入“门”结构，允许模型更有效地控制信息流，选择性地保留或忘记特定信息。GRU和LSTM能缓解梯度消失问题，更好地捕捉长程依赖。GRU结构相对简单，计算速度快；而LSTM在处理更复杂的依赖关系时更具优势，因此这两种结构都成为序列建模中的重要工具，本节中讲介绍LSTM网络。</p>
                    <p>LSTM（长短期记忆网络）单元的工作方式与GRU类似，但实现方式是通过三个关键的门机制：遗忘门（forget gate）、输入门（input gate）和输出门（output gate），并引入记忆元（memory cell）来实现信息的流动和记忆管理，其中门机制都是带有激活函数的全连接层。</p>
                    <ol>
                        <li><strong>门机制</strong></li>
                        <p>遗忘门决定了哪些旧的记忆信息可以被“遗忘”。它会根据当前输入和上一个时刻的隐藏状态来选择性地保留或忘记部分记忆。比如，当遗忘门检测到某些过时的背景信息时，就会让这些信息在记忆中被“清除”，这样可以减轻旧信息的干扰。</p>
                        <p>输入门控制哪些新信息可以被“储存”到记忆中，并决定当前时刻的输入内容将如何影响记忆单元。输入门的输出会与候选记忆相乘，从而筛选出当前要存入的有效信息。输出门则会在最终决定使用多少更新的记忆元信息。</p>
                        <span class= "math inline">\[F_t=\sigma(X_tW_{xf}+H_{t-1}W_{hf}+b_f)\]</span>
                        <span class= "math inline">\[I_t=\sigma(X_tW_{xi}+H_{t-1}W_{hi}+b_i)\]</span>
                        <span class= "math inline">\[O_t=\sigma(X_tW_{xo}+H_{t-1}W_{ho}+b_o)\]</span>

                        <li><strong>候选记忆内容<span class = "math inline">\(\tilde{\mathcal{C}}_t\)</span></strong></li>
                        <p>候选记忆元<span class = "math inline">\(\tilde{\mathcal{C}}_t\)</span>用于生成潜在的新的记忆内容，根据输入数据
                            <span class = "math inline">\(X_t\)</span>和前一隐藏状态
                            <span class = "math inline">\(\tilde{\mathcal{H}}_t-1\)</span>生成候选记忆元，然后通过输入门将有效信息添加到记忆单元中。它决定了新的信息进入记忆的程度，其本质等同于RNN中的隐状态
                            <span class = "math inline">\(\tilde{\mathcal{H}}_t\)</span>。</p>
                            <span class = "math inline">\[\tilde{C}_t=\tanh(X_tW_{xc}+H_{t-1}W_{hc}+b_c)\]</span>

                        <li><strong>记忆元</strong></li>
                        <p>记忆元<span class = "math inline">\(\tilde{\mathcal{C}}_t\)</span>是LSTM的核心，结合了前一时刻的记忆（经过遗忘门筛选）和当前时刻的候选记忆（经过输入门筛选），从而产生更新后的记忆。对比GRU的隐状态不同的是：1.
                            <span class = "math inline">\(\tilde{\mathcal{C}}_t\)</span>的值没有范围限制；2.控制过去记忆的参数与候选记忆的参数相互独立，而GRU的是此消彼长的关系；3.
                            <span class = "math inline">\(\tilde{\mathcal{C}}_t\)</span>独立于
                            <span class = "math inline">\(\tilde{\mathcal{H}}_t\)</span>进行传递，即LSTM有
                            <span class = "math inline">\(\tilde{\mathcal{C}}_t\)</span>作为长期记忆不断累积，
                            <span class = "math inline">\(\tilde{\mathcal{H}}_t\)</span>负责短期更新，而GRU只不断选择性更新
                            <span class = "math inline">\(\tilde{\mathcal{H}}_t\)</span>。</p>
                            <span class = "math inline">\[C_t=F_t\odot C_{t-1}+I_t\odot\tilde{C}_t\]</span>

                        <li><strong>隐藏状态<span class = "math inline">\(H_t\)</span></strong></li>
                        <p>最后，输出门决定当前时刻要输出多少隐藏状态。输出门的值会控制隐藏状态的输出比例，让模型可以更灵活地选择输出多少信息。同时，当前隐藏状态
                            <span class = "math inline">\(\tilde{\mathcal{H}}_t\)</span>是经过过滤的记忆内容，用于传递给下一个单元。</p>
                        <span class = "math inline">\[H_t=0_t\odot\tanh(C_t)\]</span>
                        <p>公式中的tanh函数确保<span class = "math inline">\(H_t\)</span>始终在（-1,1）之间。</p>
                        <p>过这些机制，LSTM可以对每一时刻的输入进行灵活处理，决定哪些信息该记住、哪些该忘记，并将重要信息传递到后续的时刻，因而能够更有效地捕捉长时依赖关系，其图形化演示如下：</p>
                        <image class="educationImage" src="resources/educationimages/newRNN_2.png"  alt="newRNN_2" ></image>
                        <image class="educationImage" src="resources/educationimages/newRNN_3.png"  alt="newRNN_3" ></image>
                    </ol>

                    <div class="educationSection">（四）深度循环神经网络</div>
                    <p>单层RNN在建模复杂的序列关系时可能不够灵活。通过增加RNN的层数，我们可以构建“深度”RNN，逐层捕捉数据中不同层次的模式。这种深层架构可以提取出更复杂的序列特征，显著提升模型的表达能力，适应更多类型的任务需求，但由于深度结构引入了更多的参数，训练过程更容易出现梯度消失或梯度爆炸问题，因此通常需要配合梯度裁剪、正则化等技术。</p>
                    <p>深度RNN包含多层RNN单元，每一层的输出作为下一层的输入，从而形成更深的网络结构。随着层数的增加，模型的容量也会增加，使其能够更好地表示复杂的时序模式和长时依赖关系。底层RNN层通常捕捉较低级的特征（例如基本的时序模式），而随着网络层次的加深，逐层的高层RNN可以学习更加复杂的模式或长时依赖关系，其图形化显示如下：</p>
                    <image class="educationImage" src="resources/educationimages/newRNN_4.png"  alt="newRNN_4" ></image>
                    <p>形象地说，<span class = "math inline">\(H_t^{(l)}\)</span>同时受到<span class = "math inline">\(H_t-1^{(l)}\)</span>和<span class = "math inline">\(H_t^{(l-1)}\)</span>的影响。</p>
                    <p>在深度RNN中，每一时刻t的输入不仅通过第一层RNN进行处理，得到的隐藏状态还会传递到下一层。假设深度RNN包含L层，记第l层的计算公式为：</p>
                    <span class = "math inline">\[H_t^{(1)}=\sigma\left(W_{xh}^{(1)}\cdot H_t^{(1-1)}+W\ln h^{(1)}\cdot H_{t-1}^{(1)}+b^{(1)}\right)\]</span>

                    <div class="educationSection">（五）双向循环神经网络</div>
                    <p>在很多序列任务中，不仅需要考虑过去的信息，有时还需考虑未来的上下文。例如，在命名实体识别等任务中，一个词的含义可能受到前后文的影响。双向RNN通过正向和反向传播同时处理序列，可以更全面地捕捉上下文信息，提高模型的整体表现。</p>
                    <p>在双向RNN中，每一时刻的隐藏状态包括前向隐藏状态和后向隐藏状态，两者的输出会被合并，作为该时刻的输出，其图形化显示如下：</p>
                    <image class="educationImage" src="resources/educationimages/newRNN_5.png"  alt="newRNN_5" ></image>
                    <p>假设输入序列为<span class = "math inline">\(\mathbf{X=\{x1,x2,\cdots,xT\}}\)</span>，则双向RNN的计算过程如下：</p>
                    <ol>
                        <li><strong>前向隐藏状态：</strong>沿正序方向，从前到后计算隐藏状态。</li>
                        <span class = "math inline">\[\overrightarrow{\mathrm{h}_t}=f\left(W^{(f)}x_t+U^{(f)}\overrightarrow{\mathrm{h}_{t-1}}+b^{(f)}\right)\]</span>
                        <li><strong>后向隐藏状态：</strong>沿反向方向，从后到前计算隐藏状态。</li>
                        <span class = "math inline">\[\overset{\leftarrow}{\operatorname*{h}_{t}}=f\left(W^{(b)}x_{t}+U^{(b)}\overset{\leftarrow}{\operatorname*{h}_{t+1}}+b^{(b)}\right)\]</span>

                        <li><strong>合并前向和后向隐藏状态：</strong>将前向和后向的隐藏状态合并，通常是将它们连接起来作为最终的输出。</li>
                        <span class = "math inline">\[\mathbf{h}_t=\begin{bmatrix}\to\leftarrow\\\mathbf{h}_t;\mathbf{h}_t\end{bmatrix}\]</span>

                        <li><strong>其中：</strong></li>
                        <p><span class = "math inline">\(\mathrm{W(f)}\)</span>和<span class = "math inline">\(\mathrm{W(b)}\)</span>分别是前向和后向的输入权重矩阵。</p>

                        <p><span class = "math inline">\(\mathrm{U(f)}\)</span>和<span class = "math inline">\(\mathrm{U(b)}\)</span>分别是前向和后向的递归权重矩阵。</p>
                        <p><span class = "math inline">\(\mathrm{b(f)}\)</span>和<span class = "math inline">\(\mathrm{b(b)}\)</span>是偏置项。</p>
                        <p>f是激活函数，通常为tanh或ReLU。</p>

                    </ol>
                    <div class="educationSection">（六）注意力机制（Transformer模型）</div>
                    <p>尽管改进后的RNN模型能够更好地解决长序列依赖和数值不稳定性问题，但在处理非常长的序列时仍会面临计算效率和依赖距离的挑战。Transformer模型引入了自注意力机制，允许模型在一个序列的任意两个位置之间建立直接的依赖关系，极大地提高了并行计算效率，并有效解决了远距离依赖问题。正因如此，Transformer成为当下序列建模和自然语言处理领域的核心架构。</p>
                </div>
            </div>
            <!-- 新增的做题链接部分 -->
            <div class="exercise-section">
                <!-- 现代RNN练习区域 - 卡片式布局 -->
                <div class="learning-exercises">
                    <h3 style="color: #2c3e50; margin-bottom: 20px; text-align: center;">🚀 现代RNN练习区</h3>
                    <p style="text-align: center; color: #666; margin-bottom: 30px;">探索现代循环神经网络和注意力机制</p>

                    <div class="exercise-cards">
                        <!-- 现代RNN知识测试卡片 -->
                        <div class="exercise-card" data-exercise="modern_rnn_quiz">
                            <div class="card-header">
                                <h4>🧠 现代RNN知识测试</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>测试您对现代RNN架构发展历程的理解。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> LSTM相较于传统RNN的最大改进是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="modern_rnn_q1" value="A"> A. 门控机制</label>
                                        <label><input type="radio" name="modern_rnn_q1" value="B"> B. 多层堆叠</label>
                                        <label><input type="radio" name="modern_rnn_q1" value="C"> C. 双向结构</label>
                                        <label><input type="radio" name="modern_rnn_q1" value="D"> D. 注意力机制</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> GRU相较于LSTM的优点是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="modern_rnn_q2" value="A"> A. 参数更少</label>
                                        <label><input type="radio" name="modern_rnn_q2" value="B"> B. 计算更快</label>
                                        <label><input type="radio" name="modern_rnn_q2" value="C"> C. 性能相当</label>
                                        <label><input type="radio" name="modern_rnn_q2" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 什么是序列到序列模型？</p>
                                    <div class="options">
                                        <label><input type="radio" name="modern_rnn_q3" value="A"> A. 输入输出都是序列</label>
                                        <label><input type="radio" name="modern_rnn_q3" value="B"> B. 输入序列输出单个值</label>
                                        <label><input type="radio" name="modern_rnn_q3" value="C"> C. 输入单个值输出序列</label>
                                        <label><input type="radio" name="modern_rnn_q3" value="D"> D. 只处理固定长度</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 注意力机制的主要作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="modern_rnn_q4" value="A"> A. 选择重要信息</label>
                                        <label><input type="radio" name="modern_rnn_q4" value="B"> B. 加速计算</label>
                                        <label><input type="radio" name="modern_rnn_q4" value="C"> C. 减少参数</label>
                                        <label><input type="radio" name="modern_rnn_q4" value="D"> D. 防止过拟合</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> Transformer相较于RNN的优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="modern_rnn_q5" value="A"> A. 并行计算</label>
                                        <label><input type="radio" name="modern_rnn_q5" value="B"> B. 长距离建模</label>
                                        <label><input type="radio" name="modern_rnn_q5" value="C"> C. 全局感受野</label>
                                        <label><input type="radio" name="modern_rnn_q5" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="modern_rnn_quiz">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- GRU门控机制卡片 -->
                        <div class="exercise-card" data-exercise="gru_mechanisms">
                            <div class="card-header">
                                <h4>🚪 GRU门控机制</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>深入理解GRU的更新门和重置门的机制。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> GRU有多少个门控？</p>
                                    <div class="options">
                                        <label><input type="radio" name="gru_q1" value="A"> A. 1个</label>
                                        <label><input type="radio" name="gru_q1" value="B"> B. 2个</label>
                                        <label><input type="radio" name="gru_q1" value="C"> C. 3个</label>
                                        <label><input type="radio" name="gru_q1" value="D"> D. 4个</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 更新门的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="gru_q2" value="A"> A. 控制信息更新</label>
                                        <label><input type="radio" name="gru_q2" value="B"> B. 控制信息遗忘</label>
                                        <label><input type="radio" name="gru_q2" value="C"> C. 控制信息保留</label>
                                        <label><input type="radio" name="gru_q2" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 重置门如何影响候选状态？</p>
                                    <div class="options">
                                        <label><input type="radio" name="gru_q3" value="A"> A. 完全重置</label>
                                        <label><input type="radio" name="gru_q3" value="B"> B. 部分重置</label>
                                        <label><input type="radio" name="gru_q3" value="C"> C. 控制重置程度</label>
                                        <label><input type="radio" name="gru_q3" value="D"> D. 不影响</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> GRU的候选隐藏状态计算公式是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="gru_q4" value="A"> A. ĥ = tanh(W·x + U·(r⊙h))</label>
                                        <label><input type="radio" name="gru_q4" value="B"> B. ĥ = tanh(W·x + U·h)</label>
                                        <label><input type="radio" name="gru_q4" value="C"> C. ĥ = relu(W·x + U·h)</label>
                                        <label><input type="radio" name="gru_q4" value="D"> D. ĥ = sigmoid(W·x + U·h)</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> GRU相较于LSTM的计算优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="gru_q5" value="A"> A. 门控更少</label>
                                        <label><input type="radio" name="gru_q5" value="B"> B. 矩阵运算更少</label>
                                        <label><input type="radio" name="gru_q5" value="C"> C. 训练更快</label>
                                        <label><input type="radio" name="gru_q5" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="gru_mechanisms">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- LSTM架构分析卡片 -->
                        <div class="exercise-card" data-exercise="lstm_architecture">
                            <div class="card-header">
                                <h4>🏗️ LSTM架构分析</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>分析LSTM的三个门控和记忆细胞的工作原理。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> LSTM有多少个门控？</p>
                                    <div class="options">
                                        <label><input type="radio" name="lstm_q1" value="A"> A. 1个</label>
                                        <label><input type="radio" name="lstm_q1" value="B"> B. 2个</label>
                                        <label><input type="radio" name="lstm_q1" value="C"> C. 3个</label>
                                        <label><input type="radio" name="lstm_q1" value="D"> D. 4个</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 遗忘门的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="lstm_q2" value="A"> A. 控制记忆保留</label>
                                        <label><input type="radio" name="lstm_q2" value="B"> B. 控制信息输入</label>
                                        <label><input type="radio" name="lstm_q2" value="C"> C. 控制信息输出</label>
                                        <label><input type="radio" name="lstm_q2" value="D"> D. 控制梯度流</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 记忆细胞存储什么信息？</p>
                                    <div class="options">
                                        <label><input type="radio" name="lstm_q3" value="A"> A. 短期记忆</label>
                                        <label><input type="radio" name="lstm_q3" value="B"> B. 长期记忆</label>
                                        <label><input type="radio" name="lstm_q3" value="C"> C. 重要信息</label>
                                        <label><input type="radio" name="lstm_q3" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 输出门如何控制信息流？</p>
                                    <div class="options">
                                        <label><input type="radio" name="lstm_q4" value="A"> A. 控制输出到隐藏状态</label>
                                        <label><input type="radio" name="lstm_q4" value="B"> B. 控制输入到细胞状态</label>
                                        <label><input type="radio" name="lstm_q4" value="C"> C. 控制遗忘细胞状态</label>
                                        <label><input type="radio" name="lstm_q4" value="D"> D. 控制候选值生成</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> LSTM如何解决梯度消失问题？</p>
                                    <div class="options">
                                        <label><input type="radio" name="lstm_q5" value="A"> A. 门控机制</label>
                                        <label><input type="radio" name="lstm_q5" value="B"> B. 常数误差雕像</label>
                                        <label><input type="radio" name="lstm_q5" value="C"> C. 残差连接</label>
                                        <label><input type="radio" name="lstm_q5" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="lstm_architecture">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 双向RNN练习卡片 -->
                        <div class="exercise-card" data-exercise="bidirectional_rnn">
                            <div class="card-header">
                                <h4>↔️ 双向RNN练习</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>学习双向RNN如何利用上下文信息提升性能。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 双向RNN包含哪两个方向的RNN？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bidir_q1" value="A"> A. 前向和后向</label>
                                        <label><input type="radio" name="bidir_q1" value="B"> B. 左向和右向</label>
                                        <label><input type="radio" name="bidir_q1" value="C"> C. 上向和下向</label>
                                        <label><input type="radio" name="bidir_q1" value="D"> D. 顺时针和逆时针</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 双向RNN的输出如何计算？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bidir_q2" value="A"> A. 前向输出+后向输出</label>
                                        <label><input type="radio" name="bidir_q2" value="B"> B. 前向输出×后向输出</label>
                                        <label><input type="radio" name="bidir_q2" value="C"> C. 拼接两个方向输出</label>
                                        <label><input type="radio" name="bidir_q2" value="D"> D. 取两个方向平均</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 双向RNN适用于什么任务？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bidir_q3" value="A"> A. 序列标注</label>
                                        <label><input type="radio" name="bidir_q3" value="B"> B. 命名实体识别</label>
                                        <label><input type="radio" name="bidir_q3" value="C"> C. 语音识别</label>
                                        <label><input type="radio" name="bidir_q3" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 双向RNN的缺点是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bidir_q4" value="A"> A. 无法并行计算</label>
                                        <label><input type="radio" name="bidir_q4" value="B"> B. 训练时间长</label>
                                        <label><input type="radio" name="bidir_q4" value="C"> C. 参数量翻倍</label>
                                        <label><input type="radio" name="bidir_q4" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 在什么情况下不需要双向RNN？</p>
                                    <div class="options">
                                        <label><input type="radio" name="bidir_q5" value="A"> A. 序列生成</label>
                                        <label><input type="radio" name="bidir_q5" value="B"> B. 实时预测</label>
                                        <label><input type="radio" name="bidir_q5" value="C"> C. 在线学习</label>
                                        <label><input type="radio" name="bidir_q5" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="bidirectional_rnn">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- 注意力机制卡片 -->
                        <div class="exercise-card" data-exercise="attention_mechanism">
                            <div class="card-header">
                                <h4>👀 注意力机制</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>理解注意力机制如何选择和聚焦重要信息。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> 注意力机制的核心思想是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="attn_q1" value="A"> A. 给不同部分分配权重</label>
                                        <label><input type="radio" name="attn_q1" value="B"> B. 忽略不重要信息</label>
                                        <label><input type="radio" name="attn_q1" value="C"> C. 聚焦关键特征</label>
                                        <label><input type="radio" name="attn_q1" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 注意力权重的计算基于什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="attn_q2" value="A"> A. 相似度</label>
                                        <label><input type="radio" name="attn_q2" value="B"> B. 距离远近</label>
                                        <label><input type="radio" name="attn_q2" value="C"> C. 随机分配</label>
                                        <label><input type="radio" name="attn_q2" value="D"> D. 固定权重</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> Softmax在注意力中的作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="attn_q3" value="A"> A. 归一化权重</label>
                                        <label><input type="radio" name="attn_q3" value="B"> B. 计算相似度</label>
                                        <label><input type="radio" name="attn_q3" value="C"> C. 生成查询</label>
                                        <label><input type="radio" name="attn_q3" value="D"> D. 产生键值</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> 自注意力机制的特点是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="attn_q4" value="A"> A. 查询键值相同</label>
                                        <label><input type="radio" name="attn_q4" value="B"> B. 计算自身关系</label>
                                        <label><input type="radio" name="attn_q4" value="C"> C. 捕捉内部依赖</label>
                                        <label><input type="radio" name="attn_q4" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> 注意力机制如何改善序列模型？</p>
                                    <div class="options">
                                        <label><input type="radio" name="attn_q5" value="A"> A. 处理长距离依赖</label>
                                        <label><input type="radio" name="attn_q5" value="B"> B. 并行计算</label>
                                        <label><input type="radio" name="attn_q5" value="C"> C. 减少参数量</label>
                                        <label><input type="radio" name="attn_q5" value="D"> D. A和B都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="attention_mechanism">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>

                        <!-- Transformer架构卡片 -->
                        <div class="exercise-card" data-exercise="transformer_architecture">
                            <div class="card-header">
                                <h4>⚡ Transformer架构</h4>
                                <div class="progress-indicator">
                                    <span class="progress-text">未完成</span>
                                    <div class="progress-bar">
                                        <div class="progress-fill" style="width: 0%"></div>
                                    </div>
                                </div>
                            </div>
                            <div class="card-content">
                                <p>探索Transformer的架构组成和工作原理。</p>
                                <button class="start-exercise-btn">开始练习</button>
                            </div>
                            <div class="card-questions" style="display: none;">
                                <div class="question">
                                    <p><strong>题目1:</strong> Transformer的核心组件是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="trans_q1" value="A"> A. 自注意力机制</label>
                                        <label><input type="radio" name="trans_q1" value="B"> B. 位置编码</label>
                                        <label><input type="radio" name="trans_q1" value="C"> C. 前馈网络</label>
                                        <label><input type="radio" name="trans_q1" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目2:</strong> 多头注意力有多少个注意力头？</p>
                                    <div class="options">
                                        <label><input type="radio" name="trans_q2" value="A"> A. 1个</label>
                                        <label><input type="radio" name="trans_q2" value="B"> B. 8个</label>
                                        <label><input type="radio" name="trans_q2" value="C"> C. 12个</label>
                                        <label><input type="radio" name="trans_q2" value="D"> D. 可配置</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目3:</strong> 位置编码的目的是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="trans_q3" value="A"> A. 提供位置信息</label>
                                        <label><input type="radio" name="trans_q3" value="B"> B. 打破对称性</label>
                                        <label><input type="radio" name="trans_q3" value="C"> C. 保持序列顺序</label>
                                        <label><input type="radio" name="trans_q3" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目4:</strong> Transformer的编码器作用是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="trans_q4" value="A"> A. 生成输入表示</label>
                                        <label><input type="radio" name="trans_q4" value="B"> B. 学习序列特征</label>
                                        <label><input type="radio" name="trans_q4" value="C"> C. 提取上下文信息</label>
                                        <label><input type="radio" name="trans_q4" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="question">
                                    <p><strong>题目5:</strong> Transformer相较于RNN的优势是什么？</p>
                                    <div class="options">
                                        <label><input type="radio" name="trans_q5" value="A"> A. 并行处理</label>
                                        <label><input type="radio" name="trans_q5" value="B"> B. 长程建模</label>
                                        <label><input type="radio" name="trans_q5" value="C"> C. 全局感受野</label>
                                        <label><input type="radio" name="trans_q5" value="D"> D. 以上都是</label>
                                    </div>
                                </div>

                                <div class="card-actions">
                                    <button class="submit-btn" data-category="transformer_architecture">提交答案</button>
                                    <button class="close-exercise-btn">收起练习</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

			<div id="educationTransformer">
			    <div class="educationTitle">注意力机制（Transformer）</div>
				<div class="educationContent">
					<p>在过去几年中，Transformer 模型已经成为高级深度学习和深度神经网络领域的热门话题。自从其在 2017 年被引入以来，Transformer 深度学习模型架构已经在几乎所有可能的领域中得到了广泛应用和演进。该模型不仅在自然语言处理任务中表现出色，还对于其他领域，尤其是时间序列预测方面，也具有巨大的帮助和潜力。</p>
					<p>Transformer 模型是一种深度学习架构，自 2017 年推出以来，彻底改变了自然语言处理 (NLP) 领域。该模型由 Vaswani 等人提出，并已成为 NLP 界最具影响力的模型之一。</p>
					<p>通常而言，传统的顺序模型（例如循环神经网络 (RNN)）在捕获远程依赖性和实现并行计算方面存在局限性。为了解决这些问题，Transformer 模型引入了自注意力机制，通过广泛使用该机制，模型能够在生成输出时权衡输入序列中不同位置的重要性。</p>
		            <p>Transformer 模型通过自注意力机制和并行计算的优势，能够更好地处理长距离依赖关系，提高了模型的训练和推理效率。它在机器翻译、文本摘要、问答系统等多个 NLP 任务中取得了显著的性能提升。</p>
					<p>除此之外，Transformer 模型的突破性表现使得它成为现代 NLP 研究和应用中的重要组成部分。它能够捕捉复杂的语义关系和上下文信息，极大地推动了自然语言处理的发展。</p>
					<div class="educationSection">Transformer 模型历史发展</div>
					<p>Transformer 在神经网络中的历史可以追溯到20世纪90年代初，当时 Jürgen Schmidhuber 提出了第一个 Transformer 模型的概念。这个模型被称为"快速权重控制器"，它采用了自注意力机制来学习句子中单词之间的关系。然而，尽管这个早期的 Transformer 模型在概念上是先进的，但由于其效率较低，它并未得到广泛的应用。</p>
					<p>随着时间的推移和深度学习技术的发展，Transformer 在2017年的一篇开创性论文中被正式引入，并取得了巨大的成功。通过引入自注意力机制和位置编码层，有效地捕捉输入序列中的长距离依赖关系，并且在处理长序列时表现出色。此外，Transformer 模型的并行化计算能力也使得训练速度更快，推动了深度学习在自然语言处理领域的重大突破，如机器翻译任务中的BERT（Bidirectional Encoder Representations from Transformers）模型等。</p>
					<p>因此，尽管早期的"快速权重控制器"并未受到广泛应用，但通过 Vaswani 等人的论文，Transformer 模型得到了重新定义和改进，成为现代深度学习的前沿技术之一，并在自然语言处理等领域取得了令人瞩目的成就。</p>
			    	<p> Transformer 之所以如此成功，是因为它能够学习句子中单词之间的长距离依赖关系，这对于许多自然语言处理（NLP）任务至关重要，因为它允许模型理解单词在句子中的上下文。Transformer 利用自注意力机制来实现这一点，该机制使得模型在解码输出标记时能够聚焦于句子中最相关的单词。</p>
					<p>Transformer 对 NLP 领域产生了重大影响。它现在被广泛应用于许多 NLP 任务，并且不断进行改进。未来，Transformer 很可能被用于解决更广泛的 NLP 任务，并且它们将变得更加高效和强大。</p>
					<p>有关神经网络 Transformer 历史上的一些关键发展事件，我们可参考如下所示：</p>
					<li>1、1990年：Jürgen Schmidhuber 提出了第一个 Transformer 模型，即"快速权重控制器"。</li>
					<li>2、2017年：Vaswani 等人发表了论文《Attention is All You Need》，介绍了 Transformer 模型的核心思想。</li>
					<li>3、2018年：Transformer 模型在各种 NLP 任务中取得了最先进的结果，包括机器翻译、文本摘要和问答等。</li>
					<li>4、2019年：Transformer 被用于创建大型语言模型（LLM），例如 BERT 和 GPT-2，这些模型在各种 NLP 任务中取得了重要突破。</li>
					<li> 5、2020年：Transformer 继续被用于创建更强大的模型，例如 GPT-3，它在自然语言生成和理解方面取得了惊人的成果。</li>
					<p>总的来说，Transformer 模型的引入对于 NLP 领域产生了革命性的影响。它的能力在于学习长距离依赖关系并理解上下文，使得它成为众多 NLP 任务的首选方法，并为未来的发展提供了广阔的可能性。</p>
					<div class="educationSection">Transformer 模型通用架构设计</div>
					<p>Transformer 架构是从 RNN（循环神经网络）的编码器-解码器架构中汲取灵感而来，其引入了注意力机制。它被广泛应用于序列到序列（seq2seq）任务，并且相比于 RNN， Transformer 摒弃了顺序处理的方式。</p>
					<p>不同于 RNN，Transformer 以并行化的方式处理数据，从而实现更大规模的并行计算和更快速的训练。这得益于 Transformer 架构中的自注意力机制，它使得模型能够同时考虑输入序列中的所有位置，而无需按顺序逐步处理。自注意力机制允许模型根据输入序列中的不同位置之间的关系，对每个位置进行加权处理，从而捕捉全局上下文信息。</p>
					<image class="educationImage" src="resources/educationimages/transformer_1.png"  alt="transformer_1" ></image>
					<p>基于如上的 Transformer 深度学习模型的整体架构参考模型图，我们可以看到：它由两个主要组件组成：</p>
					<li><strong> 1、编码器堆栈 </strong></li>
					<p>这是由 Nx 个相同的编码器层组成的堆栈（在原始论文中，Nx=6）。每个编码器层都由两个子层组成：多头自注意力机制和前馈神经网络。多头自注意力机制用于对输入序列中的不同位置之间的关系进行建模，而前馈神经网络则用于对每个位置进行非线性转换。编码器堆栈的作用是将输入序列转换为一系列高级特征表示。</p>
					<li><strong> 2、解码器堆栈 </strong></li>
					<p>这也是由 Nx 个相同的解码器层组成的堆栈（在原始论文中，Nx=6）。每个解码器层除了包含编码器层的两个子层外，还包含一个额外的多头自注意力机制子层。这个额外的自注意力机制用于对编码器堆栈的输出进行关注，并帮助解码器对输入序列中的信息进行解码和生成输出序列。</p>
					<p>在编码器和解码器堆栈之间，还有一个位置编码层。这个位置编码层的作用是利用序列的顺序信息，为输入序列中的每个位置提供一个固定的编码表示。这样，模型可以在没有递归或卷积操作的情况下，利用位置编码层来处理序列的顺序信息。</p>
					<div class="educationSection">什么是 Transformer 神经网络？</div>
					<p>众所周知，Transformer 在处理文本序列、基因组序列、声音和时间序列数据等神经网络设计中起着关键作用。其中，自然语言处理是 Transformer 神经网络最常见的应用领域。</p>
					<p>当给定一个向量序列时，Transformer 神经网络会对这些向量进行编码，并将其解码回原始形式。而 Transformer 的注意力机制则是其不可或缺的核心组成部分。注意力机制表明了在输入序列中，对于给定标记的编码，其周围其他标记的上下文信息的重要性。</p>
				    <P>打个比方，在机器翻译模型中，注意力机制使得 Transformer 能够根据所有相关单词的上下文，将英语中的"it"正确翻译为法语或西班牙语中的性别对应的词汇。 Transformers 能够利用注意力机制来确定如何翻译当前单词，同时考虑其周围单词的影响。</P>
					<p>然而，需要注意的是，Transformer 神经网络取代了早期的循环神经网络（RNN）、长短期记忆（LSTM）和门控循环单元（GRU）等模型，成为了更为先进和有效的选择。</p>
					<p>通常而言，Transformer 神经网络接受输入句子并将其编码为两个不同的序列：</p>
					<li><strong>1、词向量嵌入序列</strong></li>
					<p>词向量嵌入是文本的数字表示形式。在这种情况下，神经网络只能处理转换为嵌入表示的单词。字典中的单词在嵌入表示中表示为向量。</p>
					<li><strong>2、位置编码器序列</strong></li>
					<p>位置编码器将原始文本中单词的位置表示为向量。Transformer 将词向量嵌入和位置编码结合起来。然后，它将组合结果发送到各个编码器，然后是解码器。</p>
					<p>与 RNN 和 LSTM 按顺序提供输入不同，Transformer 同时提供输入。每个编码器将其输入转换为另一个向量序列，称为编码。</p>
					<p>解码器以相反的顺序工作。它将编码转换回概率，并根据概率生成输出单词。通过使用 softmax 函数，Transformer 可以根据输出概率生成句子。</p>
					<p>每个解码器和编码器中都有一个称为注意力机制的组件。它允许一个输入单词使用其他单词的相关信息进行处理，同时屏蔽不包含相关信息的单词。</p>
					<p>为了充分利用 GPU 提供的并行计算能力，Transformer 使用多头注意力机制进行并行实现。多头注意力机制允许同时处理多个注意力机制，从而提高计算效率。</p>
					<p>相比于 LSTM 和 RNN，Transformer 深度学习模型的优势之一是能够同时处理多个单词。这得益于 Transformer 的并行计算能力，使得它能够更高效地处理序列数据。</p>
                </div>
			</div>
			
			


			<div style="height:100px;"> </div>


		</div>

		<div id = 'loadingDataTab' style="display: none">
			<div id='loadingMNIST'>
				加载中 <span id="datasetLoadingName">MNIST</span> 数据集
			</div>
		</div>

		<!-- Error popup -->
		<div id = 'error' style="display: none">
			<svg id = 'x' xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
			<div id = 'errorMessage'> </div>
		</div>

	</div>


	<!-- The right panel -->
	<div id = 'paramshell'>
		<div class = 'trainbox' id = 'trainbox'>
			<div id = 'train' class = 'train' data-actionType = 'json'> 训练 </div>
		</div>

		<div class = 'category' id = 'kerasinfo'>
			<div class = 'categoryTitle' data-expanded = 'true'>
				<div class='expander'>
					<svg height="24px" width="24px">
						<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
					</svg>
				</div>
				<div class='categoryTitleText'>
					模型状态
				</div>
			</div>
			<div class = 'parambox'>
				<div id = 'ti_training' class = 'paramline'>
					<div class = 'paramname'>训练中</div>
					<div class = 'paramvalue'>否</div>
				</div>
				<div id = 'ti_acc' class = 'paramline'>
					<div class = 'paramname'>准确率：</div>
					<div class = 'paramvalue'>N/A</div>
				</div>
				<div id = 'ti_loss' class = 'paramline'>
					<div class = 'paramname'>损失率:</div>
					<div class = 'paramvalue'>N/A</div>
				</div>
				<div id = 'ti_vacc' class = 'paramline'>
					<div class = 'paramname'>验证集准确率:</div>
					<div class = 'paramvalue'>N/A</div>
				</div>
				<div id = 'ti_vloss' class = 'paramline'>
					<div class = 'paramname'>验证集损失率:</div>
					<div class = 'paramvalue'>N/A</div>
				</div>
			</div>
		</div>
		<div class="category">
			<div class = 'categoryTitle' data-expanded = 'true'>
				<div class='expander'>
					<svg height="24px" width="24px">
						<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
					</svg>
				</div>
				<div class='categoryTitleText'>
					导出代码
				</div>
			</div>
			<div id="exportPython" class="select-option right-option">导出 Python</div>
			<div id="exportJulia" class="select-option right-option">导出 Julia</div>
			<div id="copyModel" class="select-option right-option">模型链接</div>
			<div class="option-dropdown">
				<div style="float:left">导出训练数据</div>
				<div style="float:right">〉</div>
				<div class="dropdown-content right">
					<div id="exportTrainingHistoryJson" class="option select-option">导出 JSON</div>
					<div id="exportTrainingHistoryCsv" class="option select-option last-dropdown">导出 CSV</div>
				</div>
			</div>
			<div id="exportTrainingCharts" class="select-option right-option">导出训练图表</div>
		</div>
		<div id = 'networkParamshell'>

			<div class = 'category' id='paramtruck'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						参数
					</div>
				</div>
				<div id='defaultparambox' class = 'parambox'>点击一个层以查看和更改其参数。</div>
			</div>
		</div>

		<div id = 'progressParamshell' style="display: none">
			<div class = 'category' id='paramtruck'>
				<div class = 'categoryTitle' data-expanded = 'true'>
					<div class='expander'>
						<svg height="24px" width="24px">
							<path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z" style="fill:#FFFFFF;"></path>
						</svg>
					</div>
					<div class='categoryTitleText'>
						超参数
					</div>
				</div>
				<div class = 'parambox'>
					<div class = 'paramline'>
						<div class="paramname" data-name="lr">Learning Rate: </div>
						<input id="learningRate" class="paramvalue hyperparamvalue" value="0.01">
					</div>
					<div class = 'paramline'>
						<div class="paramname" data-name="epochs">Epochs: </div>
						<input id="epochs" class="paramvalue hyperparamvalue" value="6">
					</div>
					<div class = 'paramline'>
						<div class="paramname" data-name="lr">Batch Size: </div>
						<input id="batchSize" class="paramvalue hyperparamvalue" value="64">
					</div>
				</div>
			</div>
		</div>

		<div id = 'visualizationParamshell' style="display: none">
		</div>

		<div id = 'educationParamshell' style="display: none">
		</div>

	</div>

</div>
	<script>
		// 临时添加事件监听器来处理卡片式练习按钮
		document.addEventListener('DOMContentLoaded', function() {
			document.addEventListener('click', function(e) {
				const target = e.target;

				// 处理开始练习按钮
				if (target.classList.contains('start-exercise-btn') || target.closest('.start-exercise-btn')) {
					e.preventDefault();
					const btn = target.classList.contains('start-exercise-btn') ? target : target.closest('.start-exercise-btn');
					const card = btn.closest('.exercise-card');
					const questions = card.querySelector('.card-questions');
					const content = card.querySelector('.card-content');

					if (questions && content) {
						content.style.display = 'none';
						questions.style.display = 'block';
						questions.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
					}
				}

				// 处理收起练习按钮
				if (target.classList.contains('close-exercise-btn') || target.closest('.close-exercise-btn')) {
					e.preventDefault();
					const btn = target.classList.contains('close-exercise-btn') ? target : target.closest('.close-exercise-btn');
					const card = btn.closest('.exercise-card');
					const questions = card.querySelector('.card-questions');
					const content = card.querySelector('.card-content');

					if (questions && content) {
						questions.style.display = 'none';
						content.style.display = 'block';
					}
				}

				// 处理提交答案按钮
				if (target.classList.contains('submit-btn') || target.closest('.submit-btn')) {
					e.preventDefault();
					const btn = target.classList.contains('submit-btn') ? target : target.closest('.submit-btn');
					const category = btn.getAttribute('data-category');
					if (category) {
						submitAnswers(category, btn.closest('.card-questions') || btn.closest('.questions-content'));
					}
				}
			});

			// 提交答案函数
			function submitAnswers(category, container) {
				if (!container) return;

				const questions = container.querySelectorAll('.question');
				let score = 0;
				const totalQuestions = questions.length;

				// 定义正确答案
				const correctAnswers = getCorrectAnswers(category);

				questions.forEach((question, index) => {
					const questionNumber = index + 1;
					const selectedOption = question.querySelector('input[type="radio"]:checked');

					// 移除之前的反馈
					const existingFeedback = question.querySelector('.answer-feedback');
					if (existingFeedback) {
						existingFeedback.remove();
					}

					const feedback = document.createElement('div');

					if (selectedOption) {
						const userAnswer = selectedOption.value;
						const correctAnswer = correctAnswers[questionNumber];

						if (userAnswer === correctAnswer) {
							score++;
							feedback.className = 'answer-feedback correct';
							feedback.textContent = `✓ 正确！正确答案是 ${correctAnswer}`;
						} else {
							feedback.className = 'answer-feedback incorrect';
							feedback.textContent = `✗ 错误。正确答案是 ${correctAnswer}`;
						}
					} else {
						feedback.className = 'answer-feedback incorrect';
						feedback.textContent = `⚠ 请选择答案。正确答案是 ${correctAnswers[questionNumber]}`;
					}

					question.appendChild(feedback);
					feedback.style.display = 'block';
				});

				// 显示分数
				showScore(container, score, totalQuestions, category);
			}

			function showScore(container, score, total, category) {
				// 移除之前的分数显示
				const existingScore = container.querySelector('.score-display');
				if (existingScore) {
					existingScore.remove();
				}

				const scoreDisplay = document.createElement('div');
				scoreDisplay.className = 'score-display';
				const percentage = Math.round((score / total) * 100);

				scoreDisplay.innerHTML = `
					<div>得分: ${score}/${total} (${percentage}%)</div>
					<div>${getScoreMessage(percentage)}</div>
				`;

				// 查找正确的插入位置
				const submitBtn = container.querySelector('.submit-btn');
				const cardActions = container.querySelector('.card-actions');

				if (cardActions) {
					// 卡片布局：在操作按钮前插入
					cardActions.insertBefore(scoreDisplay, cardActions.firstChild);
				} else if (submitBtn) {
					// 传统布局：在提交按钮前插入
					container.insertBefore(scoreDisplay, submitBtn);
				}

				// 更新卡片状态和进度
				updateCardProgress(category, percentage);

				// 如果得分超过80%，标记为已完成
				if (percentage >= 80) {
					markExerciseAsCompleted(category);
				}
			}

			function updateCardProgress(category, percentage) {
				const card = document.querySelector(`.exercise-card[data-exercise="${category}"]`);
				if (!card) return;

				const progressText = card.querySelector('.progress-text');
				const progressFill = card.querySelector('.progress-fill');

				if (progressText && progressFill) {
					if (percentage >= 80) {
						progressText.textContent = '已完成';
						progressText.style.color = '#28a745';
						card.classList.add('completed');
					} else {
						progressText.textContent = `${percentage}%`;
						progressText.style.color = '#ffc107';
					}

					progressFill.style.width = `${percentage}%`;

					if (percentage >= 80) {
						progressFill.style.background = '#28a745';
					} else if (percentage >= 60) {
						progressFill.style.background = '#ffc107';
					} else {
						progressFill.style.background = '#dc3545';
					}
				}
			}

			function markExerciseAsCompleted(exerciseId) {
				const exerciseLink = document.querySelector(`.exercise-link[data-exercise="${exerciseId}"]`);
				if (exerciseLink) {
					exerciseLink.classList.add('completed');
					exerciseLink.innerHTML = exerciseLink.textContent + ' ✓';
				}

				// 保存到本地存储
				let progress = JSON.parse(localStorage.getItem('userExerciseProgress') || '{}');
				progress[exerciseId] = true;
				localStorage.setItem('userExerciseProgress', JSON.stringify(progress));

				updateProgressDisplay();
			}

			function updateProgressDisplay() {
				const progress = JSON.parse(localStorage.getItem('userExerciseProgress') || '{}');
				const completedCount = Object.keys(progress).length;
				const totalCount = document.querySelectorAll('.exercise-link').length;

				// 可以在页面某个位置显示总体进度
				const progressElement = document.getElementById('overallProgress');
				if (!progressElement) {
					// 创建进度显示元素
					const progressElement = document.createElement('div');
					progressElement.id = 'overallProgress';
					progressElement.className = 'exercise-progress';
					progressElement.innerHTML = `学习进度: ${completedCount}/${totalCount}`;

					// 插入到教育页面顶部
					const educationTab = document.getElementById('educationTab');
					if (educationTab) {
						educationTab.insertBefore(progressElement, educationTab.firstChild);
					}
				} else {
					progressElement.innerHTML = `学习进度: ${completedCount}/${totalCount}`;
				}
			}

			function getScoreMessage(percentage) {
				if (percentage >= 90) return '优秀！';
				if (percentage >= 80) return '很好！';
				if (percentage >= 70) return '不错！';
				if (percentage >= 60) return '及格';
				return '需要继续努力';
			}

			// 获取正确答案
			function getCorrectAnswers(category) {
				const answers = {
					// 概述模块答案
					'overview_quiz': {
						1: 'B', 2: 'D', 3: 'B', 4: 'C', 5: 'A'
					},
					'basic_concepts': {
						1: 'A', 2: 'C', 3: 'B', 4: 'D', 5: 'B'
					},
					'dl_fundamentals': {
						1: 'B', 2: 'B', 3: 'C', 4: 'B', 5: 'B'
					},
					// 卷积网络模块答案
					'convolution_quiz': {
						1: 'B', 2: 'B', 3: 'C', 4: 'B', 5: 'C'
					},
					'kernel_calculation': {
						1: 'B', 2: 'A', 3: 'B', 4: 'B', 5: 'D'
					},
					'feature_extraction': {
						1: 'B', 2: 'B', 3: 'C', 4: 'B', 5: 'B'
					},
					// 残差网络模块答案
					'resnet_quiz': {
						1: 'A', 2: 'B', 3: 'B', 4: 'B', 5: 'B'
					},
					'skip_connection': {
						1: 'B', 2: 'B', 3: 'B', 4: 'B', 5: 'B'
					},
					'gradient_flow': {
						1: 'B', 2: 'A', 3: 'A', 4: 'B', 5: 'B'
					},
					// 展平层模块答案
					'flatten_quiz': {
						1: 'C', 2: 'B', 3: 'A', 4: 'B', 5: 'B'
					},
					'dimension_calculation': {
						1: 'A', 2: 'C', 3: 'B', 4: 'A', 5: 'B'
					},
					'tensor_operations': {
						1: 'D', 2: 'D', 3: 'B', 4: 'A', 5: 'A'
					},
					// Dropout模块答案
					'dropout_quiz': {
						1: 'B', 2: 'A', 3: 'B', 4: 'C', 5: 'B'
					},
					'overfitting_prevention': {
						1: 'A,B,C', 2: 'A', 3: 'A', 4: 'A', 5: 'D'
					},
					'regularization_techniques': {
						1: 'A', 2: 'A', 3: 'B', 4: 'A', 5: 'B'
					},
					// 过拟合模块答案
					'overfitting_quiz': {
						1: 'B', 2: 'B', 3: 'B', 4: 'B', 5: 'C'
					},
					'bias_variance': {
						1: 'B', 2: 'B', 3: 'B', 4: 'C', 5: 'C'
					},
					'regularization_methods': {
						1: 'B', 2: 'B', 3: 'B', 4: 'B', 5: 'A'
					},
					'model_selection': {
						1: 'A', 2: 'B', 3: 'B', 4: 'B', 5: 'B'
					},
					// 多层感知机模块答案
					'mlp_quiz': {
						1: 'A', 2: 'B', 3: 'A', 4: 'B', 5: 'B'
					},
					'activation_functions': {
						1: 'B', 2: 'C', 3: 'C', 4: 'B', 5: 'B'
					},
					'forward_propagation': {
						1: 'B', 2: 'C', 3: 'A', 4: 'B', 5: 'C'
					}
				};

				return answers[category] || {};
			}
		});
	</script>
</body>
</html>

